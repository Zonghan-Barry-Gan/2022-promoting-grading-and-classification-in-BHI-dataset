{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport warnings\nwarnings.filterwarnings('ignore')\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Extraction using Neural Networks\n\n# Classification using standard Classifiers\n\n## Neural Networks used:\n\n### 1.VGG-16\n### 2.VGG-19\n### 3.Resnet50\n### 4.Resnet101\n### 5.MobileNetv2\n### 6.MobileNet\n### 7.InceptionV3\n### 8.InceptionResntV2\n### 9.DenseNet169\n### 10.DenseNet121\n### 11.XceptionNet\n\n## Classifiers used:\n\n### 1.ANN ( Custom Architecture)\n### 2.SVM ==> SVC\n### 3.RandomForest\n### 4.AdaBoost\n### 5.Xgboost\n### 6.KNN\n#Note:Rerun Notebbok after finishing with one neural Network\n"},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\nfrom PIL import Image\nimport scipy\n\nimport tensorflow as tf\nfrom tensorflow.keras.applications import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.losses import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras.preprocessing.image import *\nfrom tensorflow.keras.utils import *\n# import pydot\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import *\nfrom sklearn.model_selection import *\nimport tensorflow.keras.backend as K\n\nfrom tqdm import tqdm, tqdm_notebook\nfrom colorama import Fore\nimport json\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom glob import glob\nfrom skimage.io import *\n%config Completer.use_jedi = False\nimport time\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nimport lightgbm as lgb\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier\n\nprint(\"All modules have been imported\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"info=pd.read_csv(\"../input/mias-mammography/Info.txt\",sep=\" \")\ninfo=info.drop('Unnamed: 7',axis=1)\ninfo.SEVERITY.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"from PIL import Image\nimport glob\nx= []\nfor filename in sorted(glob.glob(\"../input/mias-mammography/all-mias/*.pgm\")): \n    img=cv2.imread(filename)\n    img =cv2.resize(img,(224, 224))\n    x.append(img)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"fig=plt.figure(figsize=(15,20))\ncolumns = 3\nrows = 4\nfor i in range(1, columns*rows +1):\n    img = np.random.randint(10)\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(x[i])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"# Image Augmentation\nno_angles = 10\nurl = '/kaggle/input/mias-mammography/all-mias/'\n\ndef save_dictionary(path,data):\n        print('saving catalog...')\n        #open('u.item', encoding=\"utf-8\")\n        import json\n        with open(path,'w') as outfile:\n            json.dump(str(data), fp=outfile)\n        # save to file:\n        print(' catalog saved')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"# train_test_split_datagen=ImageDataGenerator(\"augmentations such as flip,brightness range,etc....\")\n# val_datagen=ImageDataGenerator(\"augmentations such as flip,brightness range,etc....\")\n# test_datagen=ImageDataGenerator(\"augmentations such as flip,brightness range,etc....\")\ndef read_image():\n        print(\"Reading images\")\n        import cv2\n        info = {}\n        for i in range(322):\n            if i<9:\n                image_name='mdb00'+str(i+1)\n            elif i<99:\n                image_name='mdb0'+str(i+1)\n            else:\n                image_name = 'mdb' + str(i+1)\n            image_address= url+image_name+'.pgm'\n            img = cv2.imread(image_address,1)\n            img = cv2.resize(img, (224,224))\n            rows, cols,channel = img.shape\n            info[image_name]={}\n            for angle in range(0,no_angles,8):\n                M = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1) \n                img_rotated = cv2.warpAffine(img, M, (cols, rows))\n                info[image_name][angle]=img_rotated\n        return (info)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"import os #Operating System\nimport sys #System\n# train_generator = train_datagen.flow(x_train, y_train, batch_size =)\n# val_generator = val_datagen.flow(x_val, y_val, batch_size = 64)\n# test_generator=test_datagen.flow(x_test,y_test,batch_size = 64)\n\ndef get_script_path():\n    return os.path.dirname(os.path.realpath(sys.argv[0]))    \n\ndef read_lable():\n    filename = url+'Info.txt'\n    text_all = open(filename).read()\n    #print(text_all)\n    lines=text_all.split('\\n')\n    info={}\n    for line in lines:\n        words=line.split(' ')\n        if len(words)>1:\n            if (words[1] == 'G'):\n                info[words[0]] = {}\n                for angle in range(no_angles):\n                    info[words[0]][angle] = 2\n            if (words[1] == 'D'):\n                info[words[0]] = {}\n                for  angle in range(no_angles):\n                    info[words[0]][angle] = 1\n            if (words[1] == 'F'):\n                info[words[0]] = {}\n                for  angle in range(no_angles):\n                    info[words[0]][angle] = 0\n            \n    return (info)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"import numpy as np\nlable_info=read_lable()\nimage_info=read_image()\nids=lable_info.keys() \n#del lable_info['Truth-Data:']\nX=[]\nY=[]\nfor id in ids:\n    for angle in range(0,no_angles,8):\n        X.append(image_info[id][angle])\n        Y.append(lable_info[id][angle])\nX=np.array(X)\nY=np.array(Y)\n#Y=to_categorical(Y,3)\nx_train, x_test1, y_train, y_test1 = train_test_split(X, Y, test_size=0.3, random_state=42)\nx_val, x_test, y_val, y_test = train_test_split(x_test1, y_test1, test_size=0.3, random_state=42)\nprint(len(x_train),len(x_val),len(x_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ANN Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Defining our ANN Model\nann_model=Sequential()\nann_model.add(Dense(8, input_dim=3, kernel_initializer = 'uniform', activation = 'relu'))\nann_model.add(BatchNormalization())\nann_model.add(Dropout( 0.2))\nann_model.add(Dense(16, kernel_initializer = 'HeUniform', activation = 'relu'))\nann_model.add(BatchNormalization())\nann_model.add(Dropout( 0.2))\nann_model.add(Dense(32, kernel_initializer = 'uniform', activation = 'relu' ))\nann_model.add(BatchNormalization())\nann_model.add(Dropout( 0.2))\nann_model.add(Dense(64, kernel_initializer = 'uniform', activation = 'relu' ))\nann_model.add(BatchNormalization())\nann_model.add(Dropout( 0.2))\nann_model.add(Dense(32, kernel_initializer = 'uniform', activation = 'relu' ))\nann_model.add(BatchNormalization())\nann_model.add(Dropout( 0.2))\nann_model.add(Dense(16, kernel_initializer = 'uniform', activation = 'relu' ))\nann_model.add(BatchNormalization())\nann_model.add(Dropout( 0.2))\nann_model.add(Dense(3,activation='softmax'))\nann_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #LEARNING_RATE = 1e-4\n# #OPTIMIZER = RMSprop(lr=LEARNING_RATE,decay=1e-2)\n# LOSS = 'binary_crossentropy'\n# METRICS = [\n#     'accuracy', \n#     'AUC'\n# ] ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating Classification Pipeline"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\nnames = [\n        \"K Nearest Neighbour Classifier\",\n        'SVM',\n        \"Random Forest Classifier\",\n        \"AdaBoost Classifier\", \n        \"XGB Classifier\",\n         ]\nclassifiers = [\n    KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30),\n    SVC(),\n    RandomForestClassifier(max_depth=9,criterion = 'entropy'),\n    AdaBoostClassifier(),\n    XGBClassifier(),\n        ]\nzipped_clf = zip(names,classifiers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n    sentiment_fit = pipeline.fit(X_train, y_train)\n    \n    y_pred_train= sentiment_fit.predict(X_train)\n    y_pred_val = sentiment_fit.predict(X_val)\n    y_pred_test = sentiment_fit.predict(X_test)\n    \n    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n    \n    \n    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n   \n    \n    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2) \n  \n    \n    \n    print()\n    print('------------------------ Train Set Metrics------------------------')\n    print()\n    print(\"Accuracy core : {}%\".format(train_accuracy))\n    \n    print('------------------------ Validation Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(val_accuracy))\n    print('------------------------ Test Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(test_accuracy))\n    print(\"F1_score : {}\".format(test_F1))\n    print(\"Kappa Score : {} \".format(test_kappa))\n    print(\"Recall score: {}\".format(test_recall))\n    print(\"Precision score : {}\".format(test_precision))\n    \n    print(\"-\"*80)\n    print()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n    result = []\n    for n,c in classifier:\n        checker_pipeline = Pipeline([('Classifier', c)])\n        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n        #print(c)\n        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ResNet-50"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"base_model= ResNet50(input_shape=(224,224,3), weights='imagenet', include_top=False)\nx = base_model.output\nx = Dropout(0.5)(x)\nx = Flatten()(x)\nx = BatchNormalization()(x)\nx = Dense(16,kernel_initializer='he_uniform')(x)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nx = Dropout(0.5)(x)\npredictions = Dense(3, activation='softmax')(x)\n\nmodel_feat = Model(inputs=base_model.input,outputs=predictions)\n\ntrain_features = model_feat.predict(x_train)\nval_features=model_feat.predict(x_val)\ntest_features=model_feat.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\nnames = [\n        \"K Nearest Neighbour Classifier\",\n        'SVM',\n        \"Random Forest Classifier\",\n        \"AdaBoost Classifier\", \n        \"XGB Classifier\",\n         ]\nclassifiers = [\n    KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30),\n    SVC(),\n    RandomForestClassifier(max_depth=9,criterion = 'entropy'),\n    AdaBoostClassifier(),\n    XGBClassifier(),\n        ]\nzipped_clf = zip(names,classifiers)\ndef classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n    sentiment_fit = pipeline.fit(X_train, y_train)\n    \n    y_pred_train= sentiment_fit.predict(X_train)\n    y_pred_val = sentiment_fit.predict(X_val)\n    y_pred_test = sentiment_fit.predict(X_test)\n    \n    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n    \n    \n    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n   \n    \n    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2) \n  \n    \n    \n    print()\n    print('------------------------ Train Set Metrics------------------------')\n    print()\n    print(\"Accuracy core : {}%\".format(train_accuracy))\n    \n    print('------------------------ Validation Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(val_accuracy))\n    print('------------------------ Test Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(test_accuracy))\n    print(\"F1_score : {}\".format(test_F1))\n    print(\"Kappa Score : {} \".format(test_kappa))\n    print(\"Recall score: {}\".format(test_recall))\n    print(\"Precision score : {}\".format(test_precision))\n    \n    print(\"-\"*80)\n    print()\n    \ndef classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n    result = []\n    for n,c in classifier:\n        checker_pipeline = Pipeline([('Classifier', c)])\n        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n        #print(c)\n        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"train_y=to_categorical(y_train,3)\nval_y=to_categorical(y_val,3)\ntest_y=to_categorical(y_test,3)\nann_model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = ann_model.fit(train_features, train_y,validation_data=(val_features,val_y), epochs=10)\nloss_value , accuracy = ann_model.evaluate(train_features, train_y)\nprint('Train_accuracy is:' + str(accuracy))\nloss_value , accuracy = ann_model.evaluate(val_features, val_y)\nprint('Validation_accuracy is := ' + str(accuracy))\nloss_value , accuracy = ann_model.evaluate(test_features, test_y)\nprint('test_accuracy is : = ' + str(accuracy))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"print(\"Performance Report:\")\ny_pred1=ann_model.predict_classes(test_features)\ny_test1=[np.argmax(x) for x in test_y]\ny_pred_prb1=ann_model.predict_proba(test_features)\ntarget=[\"G\",\"F\",\"D\"]\nfrom sklearn import metrics\nprint('Accuracy score is :', np.round(metrics.accuracy_score(y_test1, y_pred1),4))\nprint('Precision score is :', np.round(metrics.precision_score(y_test1, y_pred1, average='weighted'),4))\nprint('Recall score is :', np.round(metrics.recall_score(y_test1,y_pred1, average='weighted'),4))\nprint('F1 Score is :', np.round(metrics.f1_score(y_test1, y_pred1, average='weighted'),4))\nprint('ROC AUC Score is :', np.round(metrics.roc_auc_score(y_test1, y_pred_prb1,multi_class='ovo', average='weighted'),4))\nprint('Cohen Kappa Score:', np.round(metrics.cohen_kappa_score(y_test1, y_pred1),4))\nprint('\\t\\tClassification Report:\\n', metrics.classification_report(y_test1, y_pred1,target_names=target))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let us use pycaret now\n#!pip install ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# VGG-16"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"base_model= VGG16(input_shape=(224,224,3), weights='imagenet', include_top=False)\n# x = base_model.output\n# x = Dropout(0.2)(x)\n# x = Flatten()(x)\n# x = BatchNormalization()(x)\n# x = Dense(16,kernel_initializer='he_uniform')(x)\n# x = BatchNormalization()(x)\n# x = Activation('relu')(x)\n# predictions = Dense(3, activation='softmax')(x)\n\nx = base_model.output\nx = Flatten()(x)\nx = Dropout(0.5)(x)\nx = BatchNormalization()(x)\nx = Dense(16,kernel_initializer='he_uniform')(x)\nx = BatchNormalization()(x)\nx = Activation('softmax')(x)\npredictions = Dense(3, activation='softmax')(x)\n\nmodel_feat = Model(inputs=base_model.input,outputs=predictions)\n\ntrain_features = model_feat.predict(x_train)\nval_features=model_feat.predict(x_val)\ntest_features=model_feat.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\nnames = [\n        \"K Nearest Neighbour Classifier\",\n        'SVM',\n        \"Random Forest Classifier\",\n        \"AdaBoost Classifier\", \n        \"XGB Classifier\",\n         ]\nclassifiers = [\n    KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30),\n    SVC(),\n    RandomForestClassifier(max_depth=9,criterion = 'entropy'),\n    AdaBoostClassifier(),\n    XGBClassifier(),\n        ]\nzipped_clf = zip(names,classifiers)\ndef classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n    sentiment_fit = pipeline.fit(X_train, y_train)\n    \n    y_pred_train= sentiment_fit.predict(X_train)\n    y_pred_val = sentiment_fit.predict(X_val)\n    y_pred_test = sentiment_fit.predict(X_test)\n    \n    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n    \n    \n    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n   \n    \n    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2) \n  \n    \n    \n    print()\n    print('------------------------ Train Set Metrics------------------------')\n    print()\n    print(\"Accuracy core : {}%\".format(train_accuracy))\n    \n    print('------------------------ Validation Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(val_accuracy))\n    print('------------------------ Test Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(test_accuracy))\n    print(\"F1_score : {}\".format(test_F1))\n    print(\"Kappa Score : {} \".format(test_kappa))\n    print(\"Recall score: {}\".format(test_recall))\n    print(\"Precision score : {}\".format(test_precision))\n    \n    print(\"-\"*80)\n    print()\n    \ndef classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n    result = []\n    for n,c in classifier:\n        checker_pipeline = Pipeline([('Classifier', c)])\n        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n        #print(c)\n        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"train_y=to_categorical(y_train,3)\nval_y=to_categorical(y_val,3)\ntest_y=to_categorical(y_test,3)\nann_model.compile(optimizer='sgd',loss='categorical_crossentropy', metrics=['accuracy'],)\nhistory = ann_model.fit(train_features, train_y,validation_data=(val_features,val_y), epochs=10)\nloss_value , accuracy = ann_model.evaluate(train_features, train_y)\nprint('Train_accuracy is:' + str(accuracy))\nloss_value , accuracy = ann_model.evaluate(val_features, val_y)\nprint('Validation_accuracy is := ' + str(accuracy))\nloss_value , accuracy = ann_model.evaluate(test_features, test_y)\nprint('test_accuracy is : = ' + str(accuracy))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"print(\"Performance Report:\")\ny_pred2=ann_model.predict_classes(test_features)\ny_test2=[np.argmax(x) for x in test_y]\ny_pred_prb2=ann_model.predict_proba(test_features)\ntarget=[\"G\",\"F\",\"D\"]\nfrom sklearn import metrics\nprint('Accuracy score is :', np.round(metrics.accuracy_score(y_test2, y_pred2),4))\nprint('Precision score is :', np.round(metrics.precision_score(y_test2, y_pred2, average='weighted'),4))\nprint('Recall score is :', np.round(metrics.recall_score(y_test2,y_pred2, average='weighted'),4))\nprint('F1 Score is :', np.round(metrics.f1_score(y_test2, y_pred2, average='weighted'),4))\nprint('ROC AUC Score is :', np.round(metrics.roc_auc_score(y_test2, y_pred_prb2,multi_class='ovo', average='weighted'),4))\nprint('Cohen Kappa Score:', np.round(metrics.cohen_kappa_score(y_test2, y_pred2),4))\nprint('\\t\\tClassification Report:\\n', metrics.classification_report(y_test2, y_pred2,target_names=target))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# VGG-19"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"base_model= VGG19(input_shape=(224,224,3), weights='imagenet', include_top=False)\nx = base_model.output\n\nx = Flatten()(x)\nx = BatchNormalization()(x)\nx = Dense(16,kernel_initializer='he_uniform')(x)\nx = BatchNormalization()(x)\nx = Activation('softmax')(x)\n\npredictions = Dense(3, activation='softmax')(x)\n\nmodel_feat = Model(inputs=base_model.input,outputs=predictions)\n\ntrain_features = model_feat.predict(x_train)\nval_features=model_feat.predict(x_val)\ntest_features=model_feat.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\nnames = [\n        \"K Nearest Neighbour Classifier\",\n        'SVM',\n        \"Random Forest Classifier\",\n        \"AdaBoost Classifier\", \n        \"XGB Classifier\",\n         ]\nclassifiers = [\n    KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30),\n    SVC(),\n    RandomForestClassifier(max_depth=9,criterion = 'entropy'),\n    AdaBoostClassifier(),\n    XGBClassifier(),\n        ]\nzipped_clf = zip(names,classifiers)\ndef classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n    sentiment_fit = pipeline.fit(X_train, y_train)\n    \n    y_pred_train= sentiment_fit.predict(X_train)\n    y_pred_val = sentiment_fit.predict(X_val)\n    y_pred_test = sentiment_fit.predict(X_test)\n    \n    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n    \n    \n    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n   \n    \n    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2) \n  \n    \n    \n    print()\n    print('------------------------ Train Set Metrics------------------------')\n    print()\n    print(\"Accuracy core : {}%\".format(train_accuracy))\n    \n    print('------------------------ Validation Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(val_accuracy))\n    print('------------------------ Test Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(test_accuracy))\n    print(\"F1_score : {}\".format(test_F1))\n    print(\"Kappa Score : {} \".format(test_kappa))\n    print(\"Recall score: {}\".format(test_recall))\n    print(\"Precision score : {}\".format(test_precision))\n    \n    print(\"-\"*80)\n    print()\n    \ndef classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n    result = []\n    for n,c in classifier:\n        checker_pipeline = Pipeline([('Classifier', c)])\n        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n        #print(c)\n        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"train_y=to_categorical(y_train,3)\nval_y=to_categorical(y_val,3)\ntest_y=to_categorical(y_test,3)\nann_model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = ann_model.fit(train_features, train_y,validation_data=(val_features,val_y), epochs=10)\nloss_value , accuracy = ann_model.evaluate(train_features, train_y)\nprint('Train_accuracy is:' + str(accuracy))\nloss_value , accuracy = ann_model.evaluate(val_features, val_y)\nprint('Validation_accuracy is := ' + str(accuracy))\nloss_value , accuracy = ann_model.evaluate(test_features, test_y)\nprint('test_accuracy is : = ' + str(accuracy))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"print(\"Performance Report:\")\ny_pred1=ann_model.predict_classes(test_features)\ny_test1=[np.argmax(x) for x in test_y]\ny_pred_prb1=ann_model.predict_proba(test_features)\ntarget=[\"G\",\"F\",\"D\"]\nfrom sklearn import metrics\nprint('Accuracy score is :', np.round(metrics.accuracy_score(y_test1, y_pred1),4))\nprint('Precision score is :', np.round(metrics.precision_score(y_test1, y_pred1, average='weighted'),4))\nprint('Recall score is :', np.round(metrics.recall_score(y_test1,y_pred1, average='weighted'),4))\nprint('F1 Score is :', np.round(metrics.f1_score(y_test1, y_pred1, average='weighted'),4))\nprint('ROC AUC Score is :', np.round(metrics.roc_auc_score(y_test1, y_pred_prb1,multi_class='ovo', average='weighted'),4))\nprint('Cohen Kappa Score:', np.round(metrics.cohen_kappa_score(y_test1, y_pred1),4))\nprint('\\t\\tClassification Report:\\n', metrics.classification_report(y_test1, y_pred1,target_names=target))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ResNet-101"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"base_model= ResNet101(input_shape=(224,224,3), weights='imagenet', include_top=False)\nx = base_model.output\nx = Flatten()(x)\nx = BatchNormalization()(x)\nx = Dense(16,kernel_initializer='he_uniform')(x)\nx = BatchNormalization()(x)\nx = Activation('softmax')(x)\nx = Dropout(0.5)(x)\npredictions = Dense(3, activation='softmax')(x)\n\nmodel_feat = Model(inputs=base_model.input,outputs=predictions)\n\ntrain_features = model_feat.predict(x_train)\nval_features=model_feat.predict(x_val)\ntest_features=model_feat.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\nnames = [\n        \"K Nearest Neighbour Classifier\",\n        'SVM',\n        \"Random Forest Classifier\",\n        \"AdaBoost Classifier\", \n        \"XGB Classifier\",\n         ]\nclassifiers = [\n    KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30),\n    SVC(),\n    RandomForestClassifier(max_depth=9,criterion = 'entropy'),\n    AdaBoostClassifier(),\n    XGBClassifier(),\n        ]\nzipped_clf = zip(names,classifiers)\ndef classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n    sentiment_fit = pipeline.fit(X_train, y_train)\n    \n    y_pred_train= sentiment_fit.predict(X_train)\n    y_pred_val = sentiment_fit.predict(X_val)\n    y_pred_test = sentiment_fit.predict(X_test)\n    \n    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n    \n    \n    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n   \n    \n    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2) \n  \n    \n    \n    print()\n    print('------------------------ Train Set Metrics------------------------')\n    print()\n    print(\"Accuracy core : {}%\".format(train_accuracy))\n    \n    print('------------------------ Validation Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(val_accuracy))\n    print('------------------------ Test Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(test_accuracy))\n    print(\"F1_score : {}\".format(test_F1))\n    print(\"Kappa Score : {} \".format(test_kappa))\n    print(\"Recall score: {}\".format(test_recall))\n    print(\"Precision score : {}\".format(test_precision))\n    \n    print(\"-\"*80)\n    print()\n    \ndef classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n    result = []\n    for n,c in classifier:\n        checker_pipeline = Pipeline([('Classifier', c)])\n        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n        #print(c)\n        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"train_y=to_categorical(y_train,3)\nval_y=to_categorical(y_val,3)\ntest_y=to_categorical(y_test,3)\nann_model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = ann_model.fit(train_features, train_y,validation_data=(val_features,val_y), epochs=10)\nloss_value , accuracy = ann_model.evaluate(train_features, train_y)\nprint('Train_accuracy is:' + str(accuracy))\nloss_value , accuracy = ann_model.evaluate(val_features, val_y)\nprint('Validation_accuracy is := ' + str(accuracy))\nloss_value , accuracy = ann_model.evaluate(test_features, test_y)\nprint('test_accuracy is : = ' + str(accuracy))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"print(\"Performance Report:\")\ny_pred3=ann_model.predict_classes(test_features)\ny_test3=[np.argmax(x) for x in test_y]\ny_pred_prb3=ann_model.predict_proba(test_features)\ntarget=[\"G\",\"F\",\"D\"]\nfrom sklearn import metrics\nprint('Accuracy score is :', np.round(metrics.accuracy_score(y_test3, y_pred3),4))\nprint('Precision score is :', np.round(metrics.precision_score(y_test3, y_pred3, average='weighted'),4))\nprint('Recall score is :', np.round(metrics.recall_score(y_test3,y_pred3, average='weighted'),4))\nprint('F1 Score is :', np.round(metrics.f1_score(y_test3, y_pred3, average='weighted'),4))\nprint('ROC AUC Score is :', np.round(metrics.roc_auc_score(y_test3, y_pred_prb3,multi_class='ovo', average='weighted'),4))\nprint('Cohen Kappa Score:', np.round(metrics.cohen_kappa_score(y_test3, y_pred3),4))\nprint('\\t\\tClassification Report:\\n', metrics.classification_report(y_test3, y_pred3,target_names=target))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MobileNetV2"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"base_model= MobileNetV2(input_shape=(224,224,3), weights='imagenet', include_top=False)\nx = base_model.output\nx = Flatten()(x)\nx = BatchNormalization()(x)\nx = Dense(16,kernel_initializer='he_uniform')(x)\nx = Dense(8,activation='softmax')(x)\npredictions = Dense(3, activation='softmax')(x)\n\nmodel_feat = Model(inputs=base_model.input,outputs=predictions)\n\ntrain_features = model_feat.predict(x_train)\nval_features=model_feat.predict(x_val)\ntest_features=model_feat.predict(x_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\nnames = [\n        \"K Nearest Neighbour Classifier\",\n        'SVM',\n        \"Random Forest Classifier\",\n        \"AdaBoost Classifier\", \n        \"XGB Classifier\",\n         ]\nclassifiers = [\n    KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30),\n    SVC(),\n    RandomForestClassifier(max_depth=9,criterion = 'entropy'),\n    AdaBoostClassifier(),\n    XGBClassifier(),\n        ]\nzipped_clf = zip(names,classifiers)\ndef classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n    sentiment_fit = pipeline.fit(X_train, y_train)\n    \n    y_pred_train= sentiment_fit.predict(X_train)\n    y_pred_val = sentiment_fit.predict(X_val)\n    y_pred_test = sentiment_fit.predict(X_test)\n    \n    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n    \n    \n    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n   \n    \n    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2) \n  \n    \n    \n    print()\n    print('------------------------ Train Set Metrics------------------------')\n    print()\n    print(\"Accuracy core : {}%\".format(train_accuracy))\n    \n    print('------------------------ Validation Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(val_accuracy))\n    print('------------------------ Test Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(test_accuracy))\n    print(\"F1_score : {}\".format(test_F1))\n    print(\"Kappa Score : {} \".format(test_kappa))\n    print(\"Recall score: {}\".format(test_recall))\n    print(\"Precision score : {}\".format(test_precision))\n    \n    print(\"-\"*80)\n    print()\n    \ndef classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n    result = []\n    for n,c in classifier:\n        checker_pipeline = Pipeline([('Classifier', c)])\n        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n        #print(c)\n        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"train_y=to_categorical(y_train,3)\nval_y=to_categorical(y_val,3)\ntest_y=to_categorical(y_test,3)\nann_model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = ann_model.fit(train_features, train_y,validation_data=(val_features,val_y), epochs=10)\nloss_value , accuracy = ann_model.evaluate(train_features, train_y)\nprint('Train_accuracy is:' + str(accuracy))\nloss_value , accuracy = ann_model.evaluate(val_features, val_y)\nprint('Validation_accuracy is := ' + str(accuracy))\nloss_value , accuracy = ann_model.evaluate(test_features, test_y)\nprint('test_accuracy is : = ' + str(accuracy))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"print(\"Performance Report:\")\ny_pred4=ann_model.predict_classes(test_features)\ny_test4=[np.argmax(x) for x in test_y]\ny_pred_prb4=ann_model.predict_proba(test_features)\ntarget=[\"G\",\"F\",\"D\"]\nfrom sklearn import metrics\nprint('Accuracy score is :', np.round(metrics.accuracy_score(y_test4, y_pred4),4))\nprint('Precision score is :', np.round(metrics.precision_score(y_test4, y_pred4, average='weighted'),4))\nprint('Recall score is :', np.round(metrics.recall_score(y_test4,y_pred4, average='weighted'),4))\nprint('F1 Score is :', np.round(metrics.f1_score(y_test4, y_pred4, average='weighted'),4))\nprint('ROC AUC Score is :', np.round(metrics.roc_auc_score(y_test4, y_pred_prb4,multi_class='ovo', average='weighted'),4))\nprint('Cohen Kappa Score:', np.round(metrics.cohen_kappa_score(y_test4, y_pred4),4))\nprint('\\t\\tClassification Report:\\n', metrics.classification_report(y_test4, y_pred4,target_names=target))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MobileNet"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model= MobileNet(input_shape=(224,224,3), weights='imagenet', include_top=False)\nx = base_model.output\nx = Flatten()(x)\nx = BatchNormalization()(x)\nx = Dense(64,kernel_initializer='he_uniform')(x)\nx = BatchNormalization()(x)\nx = Activation('softmax')(x)\n\npredictions = Dense(3, activation='softmax')(x)\n\nmodel_feat = Model(inputs=base_model.input,outputs=predictions)\n\ntrain_features = model_feat.predict(x_train)\nval_features=model_feat.predict(x_val)\ntest_features=model_feat.predict(x_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\nnames = [\n        \"K Nearest Neighbour Classifier\",\n        'SVM',\n        \"Random Forest Classifier\",\n        \"AdaBoost Classifier\", \n        \"XGB Classifier\",\n         ]\nclassifiers = [\n    KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30),\n    SVC(),\n    RandomForestClassifier(max_depth=9,criterion = 'entropy'),\n    AdaBoostClassifier(),\n    XGBClassifier(),\n        ]\nzipped_clf = zip(names,classifiers)\ndef classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n    sentiment_fit = pipeline.fit(X_train, y_train)\n    \n    y_pred_train= sentiment_fit.predict(X_train)\n    y_pred_val = sentiment_fit.predict(X_val)\n    y_pred_test = sentiment_fit.predict(X_test)\n    \n    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n    \n    \n    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n   \n    \n    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2) \n  \n    \n    \n    print()\n    print('------------------------ Train Set Metrics------------------------')\n    print()\n    print(\"Accuracy core : {}%\".format(train_accuracy))\n    \n    print('------------------------ Validation Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(val_accuracy))\n    print('------------------------ Test Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(test_accuracy))\n    print(\"F1_score : {}\".format(test_F1))\n    print(\"Kappa Score : {} \".format(test_kappa))\n    print(\"Recall score: {}\".format(test_recall))\n    print(\"Precision score : {}\".format(test_precision))\n    \n    print(\"-\"*80)\n    print()\n    \ndef classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n    result = []\n    for n,c in classifier:\n        checker_pipeline = Pipeline([('Classifier', c)])\n        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n        #print(c)\n        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_y=to_categorical(y_train,3)\nval_y=to_categorical(y_val,3)\ntest_y=to_categorical(y_test,3)\nann_model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = ann_model.fit(train_features, train_y,validation_data=(val_features,val_y), epochs=10)\nloss_value , accuracy = ann_model.evaluate(train_features, train_y)\nprint('Train_accuracy is:' + str(accuracy))\nloss_value , accuracy = ann_model.evaluate(val_features, val_y)\nprint('Validation_accuracy is := ' + str(accuracy))\nloss_value , accuracy = ann_model.evaluate(test_features, test_y)\nprint('test_accuracy is : = ' + str(accuracy))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Performance Report:\")\ny_pred5=ann_model.predict_classes(test_features)\ny_test5=[np.argmax(x) for x in test_y]\ny_pred_prb5=ann_model.predict_proba(test_features)\ntarget=[\"G\",\"F\",\"D\"]\nfrom sklearn import metrics\nprint('Accuracy score is :', np.round(metrics.accuracy_score(y_test5, y_pred5),4))\nprint('Precision score is :', np.round(metrics.precision_score(y_test5, y_pred5, average='weighted'),4))\nprint('Recall score is :', np.round(metrics.recall_score(y_test5,y_pred5, average='weighted'),4))\nprint('F1 Score is :', np.round(metrics.f1_score(y_test5, y_pred5, average='weighted'),4))\nprint('ROC AUC Score is :', np.round(metrics.roc_auc_score(y_test5, y_pred_prb5,multi_class='ovo', average='weighted'),4))\nprint('Cohen Kappa Score:', np.round(metrics.cohen_kappa_score(y_test5, y_pred5),4))\nprint('\\t\\tClassification Report:\\n', metrics.classification_report(y_test5, y_pred5,target_names=target))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# InceptionV3"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model= InceptionV3(input_shape=(224,224,3), weights='imagenet', include_top=False)\nx = base_model.output\nx = Flatten()(x)\nx = Dropout(0.1)(x)\nx = BatchNormalization()(x)\nx = Dense(64,kernel_initializer='he_uniform')(x)\nx = BatchNormalization()(x)\nx = Activation('softmax')(x)\npredictions = Dense(3, activation='softmax')(x)\n\nmodel_feat = Model(inputs=base_model.input,outputs=predictions)\n\ntrain_features = model_feat.predict(x_train)\nval_features=model_feat.predict(x_val)\ntest_features=model_feat.predict(x_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\nnames = [\n        \"K Nearest Neighbour Classifier\",\n        'SVM',\n        \"Random Forest Classifier\",\n        \"AdaBoost Classifier\", \n        \"XGB Classifier\",\n         ]\nclassifiers = [\n    KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30),\n    SVC(),\n    RandomForestClassifier(max_depth=9,criterion = 'entropy'),\n    AdaBoostClassifier(),\n    XGBClassifier(),\n        ]\nzipped_clf = zip(names,classifiers)\ndef classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n    sentiment_fit = pipeline.fit(X_train, y_train)\n    \n    y_pred_train= sentiment_fit.predict(X_train)\n    y_pred_val = sentiment_fit.predict(X_val)\n    y_pred_test = sentiment_fit.predict(X_test)\n    \n    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n    \n    \n    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n   \n    \n    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2) \n  \n    \n    \n    print()\n    print('------------------------ Train Set Metrics------------------------')\n    print()\n    print(\"Accuracy core : {}%\".format(train_accuracy))\n    \n    print('------------------------ Validation Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(val_accuracy))\n    print('------------------------ Test Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(test_accuracy))\n    print(\"F1_score : {}\".format(test_F1))\n    print(\"Kappa Score : {} \".format(test_kappa))\n    print(\"Recall score: {}\".format(test_recall))\n    print(\"Precision score : {}\".format(test_precision))\n    \n    print(\"-\"*80)\n    print()\n    \ndef classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n    result = []\n    for n,c in classifier:\n        checker_pipeline = Pipeline([('Classifier', c)])\n        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n        #print(c)\n        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_y=to_categorical(y_train,3)\nval_y=to_categorical(y_val,3)\ntest_y=to_categorical(y_test,3)\nann_model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = ann_model.fit(train_features, train_y,validation_data=(val_features,val_y), epochs=10)\nloss_value , accuracy = ann_model.evaluate(train_features, train_y)\nprint('Train_accuracy is:' + str(accuracy))\nloss_value , accuracy = ann_model.evaluate(val_features, val_y)\nprint('Validation_accuracy is := ' + str(accuracy))\nloss_value , accuracy = ann_model.evaluate(test_features, test_y)\nprint('test_accuracy is : = ' + str(accuracy))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Performance Report:\")\ny_pred6=ann_model.predict_classes(test_features)\ny_test6=[np.argmax(x) for x in test_y]\ny_pred_prb6=ann_model.predict_proba(test_features)\ntarget=[\"G\",\"F\",\"D\"]\nfrom sklearn import metrics\nprint('Accuracy score is :', np.round(metrics.accuracy_score(y_test6, y_pred6),4))\nprint('Precision score is :', np.round(metrics.precision_score(y_test6, y_pred6, average='weighted'),4))\nprint('Recall score is :', np.round(metrics.recall_score(y_test6,y_pred6, average='weighted'),4))\nprint('F1 Score is :', np.round(metrics.f1_score(y_test6, y_pred6, average='weighted'),4))\nprint('ROC AUC Score is :', np.round(metrics.roc_auc_score(y_test6, y_pred_prb6,multi_class='ovo', average='weighted'),4))\nprint('Cohen Kappa Score:', np.round(metrics.cohen_kappa_score(y_test6, y_pred6),4))\nprint('\\t\\tClassification Report:\\n', metrics.classification_report(y_test6, y_pred6,target_names=target))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# InceptionResNetV2"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model= InceptionResNetV2(input_shape=(224,224,3), weights='imagenet', include_top=False)\nx = base_model.output\nx = Flatten()(x)\nx = Dropout(0.1)(x)\nx = BatchNormalization()(x)\nx = Dense(16,kernel_initializer='he_uniform')(x)\nx = BatchNormalization()(x)\nx = Activation('softmax')(x)\npredictions = Dense(3, activation='softmax')(x)\n\nmodel_feat = Model(inputs=base_model.input,outputs=predictions)\n\ntrain_features = model_feat.predict(x_train)\nval_features=model_feat.predict(x_val)\ntest_features=model_feat.predict(x_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\nnames = [\n        \"K Nearest Neighbour Classifier\",\n        'SVM',\n        \"Random Forest Classifier\",\n        \"AdaBoost Classifier\", \n        \"XGB Classifier\",\n         ]\nclassifiers = [\n    KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30),\n    SVC(),\n    RandomForestClassifier(max_depth=9,criterion = 'entropy'),\n    AdaBoostClassifier(),\n    XGBClassifier(),\n        ]\nzipped_clf = zip(names,classifiers)\ndef classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n    sentiment_fit = pipeline.fit(X_train, y_train)\n    \n    y_pred_train= sentiment_fit.predict(X_train)\n    y_pred_val = sentiment_fit.predict(X_val)\n    y_pred_test = sentiment_fit.predict(X_test)\n    \n    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n    \n    \n    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n   \n    \n    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2) \n  \n    \n    \n    print()\n    print('------------------------ Train Set Metrics------------------------')\n    print()\n    print(\"Accuracy core : {}%\".format(train_accuracy))\n    \n    print('------------------------ Validation Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(val_accuracy))\n    print('------------------------ Test Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(test_accuracy))\n    print(\"F1_score : {}\".format(test_F1))\n    print(\"Kappa Score : {} \".format(test_kappa))\n    print(\"Recall score: {}\".format(test_recall))\n    print(\"Precision score : {}\".format(test_precision))\n    \n    print(\"-\"*80)\n    print()\n    \ndef classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n    result = []\n    for n,c in classifier:\n        checker_pipeline = Pipeline([('Classifier', c)])\n        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n        #print(c)\n        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_y=to_categorical(y_train,3)\nval_y=to_categorical(y_val,3)\ntest_y=to_categorical(y_test,3)\nann_model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = ann_model.fit(train_features, train_y,validation_data=(val_features,val_y), epochs=10)\nloss_value , accuracy = ann_model.evaluate(train_features, train_y)\nprint('Train_accuracy is:' + str(accuracy))\nloss_value , accuracy = ann_model.evaluate(val_features, val_y)\nprint('Validation_accuracy is := ' + str(accuracy))\nloss_value , accuracy = ann_model.evaluate(test_features, test_y)\nprint('test_accuracy is : = ' + str(accuracy))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Performance Report:\")\ny_pred7=ann_model.predict_classes(test_features)\ny_test7=[np.argmax(x) for x in test_y]\ny_pred_prb7=ann_model.predict_proba(test_features)\ntarget=[\"G\",\"F\",\"D\"]\nfrom sklearn import metrics\nprint('Accuracy score is :', np.round(metrics.accuracy_score(y_test7, y_pred7),4))\nprint('Precision score is :', np.round(metrics.precision_score(y_test7, y_pred7, average='weighted'),4))\nprint('Recall score is :', np.round(metrics.recall_score(y_test7,y_pred7, average='weighted'),4))\nprint('F1 Score is :', np.round(metrics.f1_score(y_test7, y_pred7, average='weighted'),4))\nprint('ROC AUC Score is :', np.round(metrics.roc_auc_score(y_test7, y_pred_prb7,multi_class='ovo', average='weighted'),4))\nprint('Cohen Kappa Score:', np.round(metrics.cohen_kappa_score(y_test7, y_pred7),4))\nprint('\\t\\tClassification Report:\\n', metrics.classification_report(y_test7, y_pred7,target_names=target))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DenseNet169"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model= DenseNet169(input_shape=(224,224,3), weights='imagenet', include_top=False)\nx = base_model.output\nx = Flatten()(x)\nx = Dropout(0.2)(x)\nx = BatchNormalization()(x)\nx = Dense(64,kernel_initializer='he_uniform')(x)\nx = BatchNormalization()(x)\nx = Activation('softmax')(x)\npredictions = Dense(3, activation='softmax')(x)\n\nmodel_feat = Model(inputs=base_model.input,outputs=predictions)\n\ntrain_features = model_feat.predict(x_train)\nval_features=model_feat.predict(x_val)\ntest_features=model_feat.predict(x_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\nnames = [\n        \"K Nearest Neighbour Classifier\",\n        'SVM',\n        \"Random Forest Classifier\",\n        \"AdaBoost Classifier\", \n        \"XGB Classifier\",\n         ]\nclassifiers = [\n    KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30),\n    SVC(),\n    RandomForestClassifier(max_depth=9,criterion = 'entropy'),\n    AdaBoostClassifier(),\n    XGBClassifier(),\n        ]\nzipped_clf = zip(names,classifiers)\ndef classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n    sentiment_fit = pipeline.fit(X_train, y_train)\n    \n    y_pred_train= sentiment_fit.predict(X_train)\n    y_pred_val = sentiment_fit.predict(X_val)\n    y_pred_test = sentiment_fit.predict(X_test)\n    \n    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n    \n    \n    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n   \n    \n    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2) \n  \n    \n    \n    print()\n    print('------------------------ Train Set Metrics------------------------')\n    print()\n    print(\"Accuracy core : {}%\".format(train_accuracy))\n    \n    print('------------------------ Validation Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(val_accuracy))\n    print('------------------------ Test Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(test_accuracy))\n    print(\"F1_score : {}\".format(test_F1))\n    print(\"Kappa Score : {} \".format(test_kappa))\n    print(\"Recall score: {}\".format(test_recall))\n    print(\"Precision score : {}\".format(test_precision))\n    \n    print(\"-\"*80)\n    print()\n    \ndef classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n    result = []\n    for n,c in classifier:\n        checker_pipeline = Pipeline([('Classifier', c)])\n        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n        #print(c)\n        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_y=to_categorical(y_train,3)\nval_y=to_categorical(y_val,3)\ntest_y=to_categorical(y_test,3)\nann_model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = ann_model.fit(train_features, train_y,validation_data=(val_features,val_y), epochs=10)\nloss_value , accuracy = ann_model.evaluate(train_features, train_y)\nprint('Train_accuracy is:' + str(accuracy))\nloss_value , accuracy = ann_model.evaluate(val_features, val_y)\nprint('Validation_accuracy is := ' + str(accuracy))\nloss_value , accuracy = ann_model.evaluate(test_features, test_y)\nprint('test_accuracy is : = ' + str(accuracy))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Performance Report:\")\ny_pred8=ann_model.predict_classes(test_features)\ny_test8=[np.argmax(x) for x in test_y]\ny_pred_prb8=ann_model.predict_proba(test_features)\ntarget=[\"G\",\"F\",\"D\"]\nfrom sklearn import metrics\nprint('Accuracy score is :', np.round(metrics.accuracy_score(y_test8, y_pred8),4))\nprint('Precision score is :', np.round(metrics.precision_score(y_test8, y_pred8, average='weighted'),4))\nprint('Recall score is :', np.round(metrics.recall_score(y_test8,y_pred8, average='weighted'),4))\nprint('F1 Score is :', np.round(metrics.f1_score(y_test8, y_pred8, average='weighted'),4))\nprint('ROC AUC Score is :', np.round(metrics.roc_auc_score(y_test8, y_pred_prb8,multi_class='ovo', average='weighted'),4))\nprint('Cohen Kappa Score:', np.round(metrics.cohen_kappa_score(y_test8, y_pred8),4))\nprint('\\t\\tClassification Report:\\n', metrics.classification_report(y_test8, y_pred8,target_names=target))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DenseNet121"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model= DenseNet121(input_shape=(224,224,3), weights='imagenet', include_top=False)\nx = base_model.output\nx = Flatten()(x)\nx = Dropout(0.2)(x)\nx = BatchNormalization()(x)\nx = Dense(16,kernel_initializer='he_uniform')(x)\nx = BatchNormalization()(x)\nx = Activation('softmax')(x)\npredictions = Dense(3, activation='softmax')(x)\n\nmodel_feat = Model(inputs=base_model.input,outputs=predictions)\n\ntrain_features = model_feat.predict(x_train)\nval_features=model_feat.predict(x_val)\ntest_features=model_feat.predict(x_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\nnames = [\n        \"K Nearest Neighbour Classifier\",\n        'SVM',\n        \"Random Forest Classifier\",\n        \"AdaBoost Classifier\", \n        \"XGB Classifier\",\n         ]\nclassifiers = [\n    KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30),\n    SVC(),\n    RandomForestClassifier(max_depth=9,criterion = 'entropy'),\n    AdaBoostClassifier(),\n    XGBClassifier(),\n        ]\nzipped_clf = zip(names,classifiers)\ndef classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n    sentiment_fit = pipeline.fit(X_train, y_train)\n    \n    y_pred_train= sentiment_fit.predict(X_train)\n    y_pred_val = sentiment_fit.predict(X_val)\n    y_pred_test = sentiment_fit.predict(X_test)\n    \n    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n    \n    \n    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n   \n    \n    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2) \n  \n    \n    \n    print()\n    print('------------------------ Train Set Metrics------------------------')\n    print()\n    print(\"Accuracy core : {}%\".format(train_accuracy))\n    \n    print('------------------------ Validation Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(val_accuracy))\n    print('------------------------ Test Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(test_accuracy))\n    print(\"F1_score : {}\".format(test_F1))\n    print(\"Kappa Score : {} \".format(test_kappa))\n    print(\"Recall score: {}\".format(test_recall))\n    print(\"Precision score : {}\".format(test_precision))\n    \n    print(\"-\"*80)\n    print()\n    \ndef classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n    result = []\n    for n,c in classifier:\n        checker_pipeline = Pipeline([('Classifier', c)])\n        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n        #print(c)\n        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_y=to_categorical(y_train,3)\nval_y=to_categorical(y_val,3)\ntest_y=to_categorical(y_test,3)\nann_model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = ann_model.fit(train_features, train_y,validation_data=(val_features,val_y), epochs=10)\nloss_value , accuracy = ann_model.evaluate(train_features, train_y)\nprint('Train_accuracy is:' + str(accuracy))\nloss_value , accuracy = ann_model.evaluate(val_features, val_y)\nprint('Validation_accuracy is := ' + str(accuracy))\nloss_value , accuracy = ann_model.evaluate(test_features, test_y)\nprint('test_accuracy is : = ' + str(accuracy))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Performance Report:\")\ny_pred9=ann_model.predict_classes(test_features)\ny_test9=[np.argmax(x) for x in test_y]\ny_pred_prb9=ann_model.predict_proba(test_features)\ntarget=[\"G\",\"F\",\"D\"]\nfrom sklearn import metrics\nprint('Accuracy score is :', np.round(metrics.accuracy_score(y_test9, y_pred9),4))\nprint('Precision score is :', np.round(metrics.precision_score(y_test9, y_pred9, average='weighted'),4))\nprint('Recall score is :', np.round(metrics.recall_score(y_test9,y_pred9, average='weighted'),4))\nprint('F1 Score is :', np.round(metrics.f1_score(y_test9, y_pred9, average='weighted'),4))\nprint('ROC AUC Score is :', np.round(metrics.roc_auc_score(y_test9, y_pred_prb9,multi_class='ovo', average='weighted'),4))\nprint('Cohen Kappa Score:', np.round(metrics.cohen_kappa_score(y_test9, y_pred9),4))\nprint('\\t\\tClassification Report:\\n', metrics.classification_report(y_test9, y_pred9,target_names=target))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# XceptionNet"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"base_model= Xception(input_shape=(224,224,3), weights='imagenet', include_top=False)\nx = base_model.output\nx = Flatten()(x)\nx = Dropout(0.2)(x)\nx = BatchNormalization()(x)\nx = Dense(64,kernel_initializer='he_uniform')(x)\nx = BatchNormalization()(x)\nx = Activation('softmax')(x)\npredictions = Dense(3, activation='softmax')(x)\n\nmodel_feat = Model(inputs=base_model.input,outputs=predictions)\n\ntrain_features = model_feat.predict(x_train)\nval_features=model_feat.predict(x_val)\ntest_features=model_feat.predict(x_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\nnames = [\n        \"K Nearest Neighbour Classifier\",\n        'SVM',\n        \"Random Forest Classifier\",\n        \"AdaBoost Classifier\", \n        \"XGB Classifier\",\n         ]\nclassifiers = [\n    KNeighborsClassifier(n_neighbors = 5, algorithm='ball_tree', leaf_size=30),\n    SVC(),\n    RandomForestClassifier(max_depth=9,criterion = 'entropy'),\n    AdaBoostClassifier(),\n    XGBClassifier(),\n        ]\nzipped_clf = zip(names,classifiers)\ndef classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n    sentiment_fit = pipeline.fit(X_train, y_train)\n    \n    y_pred_train= sentiment_fit.predict(X_train)\n    y_pred_val = sentiment_fit.predict(X_val)\n    y_pred_test = sentiment_fit.predict(X_test)\n    \n    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n    \n    \n    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n   \n    \n    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2) \n  \n    \n    \n    print()\n    print('------------------------ Train Set Metrics------------------------')\n    print()\n    print(\"Accuracy core : {}%\".format(train_accuracy))\n    \n    print('------------------------ Validation Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(val_accuracy))\n    print('------------------------ Test Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(test_accuracy))\n    print(\"F1_score : {}\".format(test_F1))\n    print(\"Kappa Score : {} \".format(test_kappa))\n    print(\"Recall score: {}\".format(test_recall))\n    print(\"Precision score : {}\".format(test_precision))\n    \n    print(\"-\"*80)\n    print()\n    \ndef classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n    result = []\n    for n,c in classifier:\n        checker_pipeline = Pipeline([('Classifier', c)])\n        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n        #print(c)\n        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_y=to_categorical(y_train,3)\nval_y=to_categorical(y_val,3)\ntest_y=to_categorical(y_test,3)\nann_model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = ann_model.fit(train_features, train_y,validation_data=(val_features,val_y), epochs=10)\nloss_value , accuracy = ann_model.evaluate(train_features, train_y)\nprint('Train_accuracy is:' + str(accuracy))\nloss_value , accuracy = ann_model.evaluate(val_features, val_y)\nprint('Validation_accuracy is := ' + str(accuracy))\nloss_value , accuracy = ann_model.evaluate(test_features, test_y)\nprint('test_accuracy is : = ' + str(accuracy))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Performance Report:\")\ny_pred10=ann_model.predict_classes(test_features)\ny_test10=[np.argmax(x) for x in test_y]\ny_pred_prb10=ann_model.predict_proba(test_features)\ntarget=[\"G\",\"F\",\"D\"]\nfrom sklearn import metrics\nprint('Accuracy score is :', np.round(metrics.accuracy_score(y_test10, y_pred10),4))\nprint('Precision score is :', np.round(metrics.precision_score(y_test10, y_pred10, average='weighted'),4))\nprint('Recall score is :', np.round(metrics.recall_score(y_test10,y_pred10, average='weighted'),4))\nprint('F1 Score is :', np.round(metrics.f1_score(y_test10, y_pred10, average='weighted'),4))\nprint('ROC AUC Score is :', np.round(metrics.roc_auc_score(y_test10, y_pred_prb10,multi_class='ovo', average='weighted'),4))\nprint('Cohen Kappa Score:', np.round(metrics.cohen_kappa_score(y_test10, y_pred10),4))\nprint('\\t\\tClassification Report:\\n', metrics.classification_report(y_test10, y_pred10,target_names=target))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}