{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tensorflow==1.14\n!pip install keras==2.2.5 \n!pip install 'h5py<3.0.0'","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:17:15.124086Z","iopub.execute_input":"2022-05-11T21:17:15.124841Z","iopub.status.idle":"2022-05-11T21:18:20.206717Z","shell.execute_reply.started":"2022-05-11T21:17:15.124729Z","shell.execute_reply":"2022-05-11T21:18:20.205929Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting tensorflow==1.14\n  Downloading tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.3/109.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (1.1.0)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (1.16.0)\nRequirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (3.19.4)\nRequirement already satisfied: gast>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (0.4.0)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (1.1.2)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (0.37.1)\nCollecting keras-applications>=1.0.6\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 KB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.5/488.5 KB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting astor>=0.6.0\n  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\nRequirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (1.0.0)\nRequirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (0.2.0)\nRequirement already satisfied: numpy<2.0,>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (1.21.6)\nRequirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (1.14.0)\nRequirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (1.43.0)\nCollecting tensorboard<1.15.0,>=1.14.0\n  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0mm\n\u001b[?25hRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow==1.14) (3.1.0)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (59.8.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.3.6)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (2.0.3)\nRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (4.11.3)\nRequirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.14) (1.5.2)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (4.2.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.7.0)\nInstalling collected packages: tensorflow-estimator, astor, keras-applications, tensorboard, tensorflow\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.6.0\n    Uninstalling tensorflow-estimator-2.6.0:\n      Successfully uninstalled tensorflow-estimator-2.6.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.6.0\n    Uninstalling tensorboard-2.6.0:\n      Successfully uninstalled tensorboard-2.6.0\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.6.3\n    Uninstalling tensorflow-2.6.3:\n      Successfully uninstalled tensorflow-2.6.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\ntfx-bsl 1.7.0 requires pyarrow<6,>=1, but you have pyarrow 7.0.0 which is incompatible.\ntfx-bsl 1.7.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3,>=1.15.5, but you have tensorflow 1.14.0 which is incompatible.\ntensorflow-transform 1.7.0 requires pyarrow<6,>=1, but you have pyarrow 7.0.0 which is incompatible.\ntensorflow-transform 1.7.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5, but you have tensorflow 1.14.0 which is incompatible.\ntensorflow-serving-api 2.8.0 requires tensorflow<3,>=2.8.0, but you have tensorflow 1.14.0 which is incompatible.\ntensorflow-io 0.21.0 requires tensorflow<2.7.0,>=2.6.0, but you have tensorflow 1.14.0 which is incompatible.\ntensorflow-cloud 0.1.14 requires tensorboard>=2.3.0, but you have tensorboard 1.14.0 which is incompatible.\ntensorflow-cloud 0.1.14 requires tensorflow<3.0,>=1.15.0, but you have tensorflow 1.14.0 which is incompatible.\npytorch-lightning 1.6.1 requires tensorboard>=2.2.0, but you have tensorboard 1.14.0 which is incompatible.\nexplainable-ai-sdk 1.3.3 requires tensorflow>=1.15.0, but you have tensorflow 1.14.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed astor-0.8.1 keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting keras==2.2.5\n  Downloading Keras-2.2.5-py2.py3-none-any.whl (336 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.2/336.2 KB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras==2.2.5) (1.21.6)\nRequirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from keras==2.2.5) (1.7.3)\nRequirement already satisfied: keras-preprocessing>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from keras==2.2.5) (1.1.2)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from keras==2.2.5) (6.0)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras==2.2.5) (3.1.0)\nRequirement already satisfied: keras-applications>=1.0.8 in /opt/conda/lib/python3.7/site-packages (from keras==2.2.5) (1.0.8)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from keras==2.2.5) (1.16.0)\nRequirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py->keras==2.2.5) (1.5.2)\nInstalling collected packages: keras\n  Attempting uninstall: keras\n    Found existing installation: keras 2.6.0\n    Uninstalling keras-2.6.0:\n      Successfully uninstalled keras-2.6.0\nSuccessfully installed keras-2.2.5\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting h5py<3.0.0\n  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.7 in /opt/conda/lib/python3.7/site-packages (from h5py<3.0.0) (1.21.6)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py<3.0.0) (1.16.0)\nInstalling collected packages: h5py\n  Attempting uninstall: h5py\n    Found existing installation: h5py 3.1.0\n    Uninstalling h5py-3.1.0:\n      Successfully uninstalled h5py-3.1.0\nSuccessfully installed h5py-2.10.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import keras\nfrom keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, multiply, Permute, Concatenate, Add, Activation, Lambda\nfrom tensorflow.keras.layers import Conv2D\nfrom keras import backend as K\nfrom keras.activations import sigmoid\n\nfrom keras import optimizers\nfrom keras.optimizers import Adam\nimport keras.backend.tensorflow_backend as KTF\n#import keras.backend as KTF\nimport glob\nfrom keras.layers import Input,Dense,Dropout,BatchNormalization,Conv2D,MaxPooling2D,AveragePooling2D,concatenate,Activation,ZeroPadding2D\n#import tensorflow as tf\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport keras\nfrom keras.models import load_model\nfrom keras.layers import Activation, Dense\nfrom matplotlib import pyplot as plt\nfrom skimage import io,data\nimport time\nfrom keras import layers\nfrom keras.callbacks import ModelCheckpoint, TensorBoard\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import regularizers\n\nfrom keras.preprocessing import image\nfrom sklearn import svm\nfrom sklearn.ensemble import RandomForestClassifier\nnow = time.strftime(\"%Y-%m-%d_%H-%M-%S\", time.localtime())\n\nimport os,sys\nos.getcwd()\n#os.chdir(\"/home/cjd/31_CNN_Attention\")\n#import os\n# \nos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,5\"\n\n\n\n\n#import tensorflow as tf        \ndef focal_loss(gamma=2.):            \n    def focal_loss_fixed(y_true, y_pred):\n        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n        return -K.sum( K.pow(1. - pt_1, gamma) * K.log(pt_1)) \n    return focal_loss_fixed\n\n\ndef Conv2d_BN(x, nb_filter,kernel_size, strides=(1,1), padding='same',name=None):  \n    if name is not None:  \n        bn_name = name + '_bn'  \n        conv_name = name + '_conv'  \n    else:  \n        bn_name = None  \n        conv_name = None  \n  \n    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,activation='relu',name=conv_name)(x)  \n    x = BatchNormalization(axis=3,name=bn_name)(x)  \n    return x  \n\ndef Conv_Block(inpt,nb_filter,kernel_size,strides=(1,1), with_conv_shortcut=False):  \n    x = Conv2d_BN(inpt,nb_filter=nb_filter[0],kernel_size=(1,1),strides=strides,padding='same')  \n    x = Conv2d_BN(x, nb_filter=nb_filter[1], kernel_size=(3,3), padding='same')  \n    x = Conv2d_BN(x, nb_filter=nb_filter[2], kernel_size=(1,1), padding='same')  \n    if with_conv_shortcut:  \n        shortcut = Conv2d_BN(inpt,nb_filter=nb_filter[2],strides=strides,kernel_size=kernel_size)  \n        x = add([x,shortcut])  \n        return x  \n    else:  \n        x = add([x,inpt])  \n        return x  \n\n\ndef channel_attention(input_feature, ratio=8):\n\t\n\tchannel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n\tchannel = input_feature._keras_shape[channel_axis]\n\t\n\tshared_layer_one = Dense(channel//ratio,\n\t\t\t\t\t\t\t kernel_initializer='he_normal',\n\t\t\t\t\t\t\t activation = 'relu',\n\t\t\t\t\t\t\t use_bias=True,\n\t\t\t\t\t\t\t bias_initializer='zeros')\n\n\tshared_layer_two = Dense(channel,\n\t\t\t\t\t\t\t kernel_initializer='he_normal',\n\t\t\t\t\t\t\t use_bias=True,\n\t\t\t\t\t\t\t bias_initializer='zeros')\n\t\n\tavg_pool = GlobalAveragePooling2D()(input_feature)    \n\tavg_pool = Reshape((1,1,channel))(avg_pool)\n\tassert avg_pool._keras_shape[1:] == (1,1,channel)\n\tavg_pool = shared_layer_one(avg_pool)\n\tassert avg_pool._keras_shape[1:] == (1,1,channel//ratio)\n\tavg_pool = shared_layer_two(avg_pool)\n\tassert avg_pool._keras_shape[1:] == (1,1,channel)\n\t\n\tmax_pool = GlobalMaxPooling2D()(input_feature)\n\tmax_pool = Reshape((1,1,channel))(max_pool)\n\tassert max_pool._keras_shape[1:] == (1,1,channel)\n\tmax_pool = shared_layer_one(max_pool)\n\tassert max_pool._keras_shape[1:] == (1,1,channel//ratio)\n\tmax_pool = shared_layer_two(max_pool)\n\tassert max_pool._keras_shape[1:] == (1,1,channel)\n\t\n\tcbam_feature = Add()([avg_pool,max_pool])\n\tcbam_feature = Activation('hard_sigmoid')(cbam_feature)\n\t\n\tif K.image_data_format() == \"channels_first\":\n\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n\t\n\treturn multiply([input_feature, cbam_feature])\n\n\ndef spatial_attention(input_feature):\n\tkernel_size = 7\n\tif K.image_data_format() == \"channels_first\":\n\t\tchannel = input_feature._keras_shape[1]\n\t\tcbam_feature = Permute((2,3,1))(input_feature)\n\telse:\n\t\tchannel = input_feature._keras_shape[-1]\n\t\tcbam_feature = input_feature\n\t\n\tavg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n\tassert avg_pool._keras_shape[-1] == 1\n\tmax_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n\tassert max_pool._keras_shape[-1] == 1\n\tconcat = Concatenate(axis=3)([avg_pool, max_pool])\n\tassert concat._keras_shape[-1] == 2\n\tcbam_feature = Conv2D(filters = 1,\n\t\t\t\t\tkernel_size=kernel_size,\n\t\t\t\t\tactivation = 'hard_sigmoid',\n\t\t\t\t\tstrides=1,\n\t\t\t\t\tpadding='same',\n\t\t\t\t\tkernel_initializer='he_normal',\n\t\t\t\t\tuse_bias=False)(concat)\n\tassert cbam_feature._keras_shape[-1] == 1\n\t\n\tif K.image_data_format() == \"channels_first\":\n\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n\t\t\n\treturn multiply([input_feature, cbam_feature])\n\n\ndef cbam_block(cbam_feature,ratio=8):\n\tcbam_feature = channel_attention(cbam_feature, ratio)\n\tcbam_feature = spatial_attention(cbam_feature, )\n\treturn cbam_feature\n\n\nIMG_SHAPE=(224, 224, 3)\n\nbase_model = keras.applications.MobileNetV2(input_shape=IMG_SHAPE,include_top=False, weights='imagenet')\n\n#weights='../working/cjd/01_rice_dete/obj_reco/checkpoint/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5'\nbase_model_layers_count=0\nfor layer in base_model.layers:\n    layer.trainable = False\n    base_model_layers_count=base_model_layers_count+1\nprint(\"MobileNetV2_base_model summary:\")\nprint(\"Number of layers in base_model:\")\nprint(base_model_layers_count)\nbase_model.summary()\n    \nbase_out = base_model.output\n\n#--------------------Soft attention module-------------------------------------------------------------- \nipts = base_out\nresidual = layers.Conv2D(1280, kernel_size = (1, 1), strides = (1, 1), padding = 'same')(ipts)\nresidual = layers.BatchNormalization(axis = -1)(residual)\ncbam = cbam_block(residual)\nbase_out = layers.add([base_out, residual, cbam])\n#------------------------------------------------------------------------------------------------------------ \nx = GlobalAveragePooling2D()(base_out)\n'''\nx = Dropout(0.2)(x)\nx = Dense(4096,activation=\"relu\")(x)\nx = Dense(4096,activation=\"relu\")(x)\nx = Dropout(0.2)(x)\nx = Dense(2096,activation=\"relu\")(x)\n'''\n\n# softmax\n#predictions = Dense(len(ont_hot_labels[0]), activation='softmax', kernel_regularizer =regularizers.l2(0.01) )(x)  #l1_reg\nclasses=['idc-','idc+']\n#predictions = Dense(len(classes), activation='softmax', kernel_regularizer =regularizers.l2(0.01) )(x)  #l1_reg\npredictions = Dense(len(classes), activation='sigmoid', kernel_regularizer =regularizers.l2(0.01) )(x)  #l1_reg\n\nfrom keras.models import Model\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\nprint(\"Whole model summary:\")\nmodel.summary()\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy',  metrics = ['accuracy'])  #rmsprop\n#model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adadelta(), metrics=['accuracy'])\n#model.compile(optimizer=optimizers.SGD(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy']) #loss='categorical_crossentropy',\n#model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adadelta(), metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:18:20.209688Z","iopub.execute_input":"2022-05-11T21:18:20.209968Z","iopub.status.idle":"2022-05-11T21:18:31.614941Z","shell.execute_reply.started":"2022-05-11T21:18:20.209932Z","shell.execute_reply":"2022-05-11T21:18:31.614259Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"Using TensorFlow backend.\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n2022-05-11 21:18:23.788343: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n2022-05-11 21:18:23.792142: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000194999 Hz\n2022-05-11 21:18:23.792477: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558afdbdfc70 executing computations on platform Host. Devices:\n2022-05-11 21:18:23.792504: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n2022-05-11 21:18:23.811937: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n9412608/9406464 [==============================] - 0s 0us/step\nMobileNetV2_base_model summary:\nNumber of layers in base_model:\n155\nModel: \"mobilenetv2_1.00_224\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n__________________________________________________________________________________________________\nConv1_pad (ZeroPadding2D)       (None, 225, 225, 3)  0           input_1[0][0]                    \n__________________________________________________________________________________________________\nConv1 (Conv2D)                  (None, 112, 112, 32) 864         Conv1_pad[0][0]                  \n__________________________________________________________________________________________________\nbn_Conv1 (BatchNormalization)   (None, 112, 112, 32) 128         Conv1[0][0]                      \n__________________________________________________________________________________________________\nConv1_relu (ReLU)               (None, 112, 112, 32) 0           bn_Conv1[0][0]                   \n__________________________________________________________________________________________________\nexpanded_conv_depthwise (Depthw (None, 112, 112, 32) 288         Conv1_relu[0][0]                 \n__________________________________________________________________________________________________\nexpanded_conv_depthwise_BN (Bat (None, 112, 112, 32) 128         expanded_conv_depthwise[0][0]    \n__________________________________________________________________________________________________\nexpanded_conv_depthwise_relu (R (None, 112, 112, 32) 0           expanded_conv_depthwise_BN[0][0] \n__________________________________________________________________________________________________\nexpanded_conv_project (Conv2D)  (None, 112, 112, 16) 512         expanded_conv_depthwise_relu[0][0\n__________________________________________________________________________________________________\nexpanded_conv_project_BN (Batch (None, 112, 112, 16) 64          expanded_conv_project[0][0]      \n__________________________________________________________________________________________________\nblock_1_expand (Conv2D)         (None, 112, 112, 96) 1536        expanded_conv_project_BN[0][0]   \n__________________________________________________________________________________________________\nblock_1_expand_BN (BatchNormali (None, 112, 112, 96) 384         block_1_expand[0][0]             \n__________________________________________________________________________________________________\nblock_1_expand_relu (ReLU)      (None, 112, 112, 96) 0           block_1_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_1_pad (ZeroPadding2D)     (None, 113, 113, 96) 0           block_1_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_1_depthwise (DepthwiseCon (None, 56, 56, 96)   864         block_1_pad[0][0]                \n__________________________________________________________________________________________________\nblock_1_depthwise_BN (BatchNorm (None, 56, 56, 96)   384         block_1_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_1_depthwise_relu (ReLU)   (None, 56, 56, 96)   0           block_1_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_1_project (Conv2D)        (None, 56, 56, 24)   2304        block_1_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_1_project_BN (BatchNormal (None, 56, 56, 24)   96          block_1_project[0][0]            \n__________________________________________________________________________________________________\nblock_2_expand (Conv2D)         (None, 56, 56, 144)  3456        block_1_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_2_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_2_expand[0][0]             \n__________________________________________________________________________________________________\nblock_2_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_2_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_2_depthwise (DepthwiseCon (None, 56, 56, 144)  1296        block_2_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_2_depthwise_BN (BatchNorm (None, 56, 56, 144)  576         block_2_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_2_depthwise_relu (ReLU)   (None, 56, 56, 144)  0           block_2_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_2_project (Conv2D)        (None, 56, 56, 24)   3456        block_2_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_2_project_BN (BatchNormal (None, 56, 56, 24)   96          block_2_project[0][0]            \n__________________________________________________________________________________________________\nblock_2_add (Add)               (None, 56, 56, 24)   0           block_1_project_BN[0][0]         \n                                                                 block_2_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_3_expand (Conv2D)         (None, 56, 56, 144)  3456        block_2_add[0][0]                \n__________________________________________________________________________________________________\nblock_3_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_3_expand[0][0]             \n__________________________________________________________________________________________________\nblock_3_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_3_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_3_pad (ZeroPadding2D)     (None, 57, 57, 144)  0           block_3_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_3_depthwise (DepthwiseCon (None, 28, 28, 144)  1296        block_3_pad[0][0]                \n__________________________________________________________________________________________________\nblock_3_depthwise_BN (BatchNorm (None, 28, 28, 144)  576         block_3_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_3_depthwise_relu (ReLU)   (None, 28, 28, 144)  0           block_3_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_3_project (Conv2D)        (None, 28, 28, 32)   4608        block_3_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_3_project_BN (BatchNormal (None, 28, 28, 32)   128         block_3_project[0][0]            \n__________________________________________________________________________________________________\nblock_4_expand (Conv2D)         (None, 28, 28, 192)  6144        block_3_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_4_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_4_expand[0][0]             \n__________________________________________________________________________________________________\nblock_4_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_4_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_4_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_4_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_4_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_4_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_4_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_4_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_4_project (Conv2D)        (None, 28, 28, 32)   6144        block_4_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_4_project_BN (BatchNormal (None, 28, 28, 32)   128         block_4_project[0][0]            \n__________________________________________________________________________________________________\nblock_4_add (Add)               (None, 28, 28, 32)   0           block_3_project_BN[0][0]         \n                                                                 block_4_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_5_expand (Conv2D)         (None, 28, 28, 192)  6144        block_4_add[0][0]                \n__________________________________________________________________________________________________\nblock_5_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_5_expand[0][0]             \n__________________________________________________________________________________________________\nblock_5_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_5_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_5_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_5_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_5_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_5_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_5_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_5_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_5_project (Conv2D)        (None, 28, 28, 32)   6144        block_5_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_5_project_BN (BatchNormal (None, 28, 28, 32)   128         block_5_project[0][0]            \n__________________________________________________________________________________________________\nblock_5_add (Add)               (None, 28, 28, 32)   0           block_4_add[0][0]                \n                                                                 block_5_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_6_expand (Conv2D)         (None, 28, 28, 192)  6144        block_5_add[0][0]                \n__________________________________________________________________________________________________\nblock_6_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_6_expand[0][0]             \n__________________________________________________________________________________________________\nblock_6_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_6_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_6_pad (ZeroPadding2D)     (None, 29, 29, 192)  0           block_6_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_6_depthwise (DepthwiseCon (None, 14, 14, 192)  1728        block_6_pad[0][0]                \n__________________________________________________________________________________________________\nblock_6_depthwise_BN (BatchNorm (None, 14, 14, 192)  768         block_6_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_6_depthwise_relu (ReLU)   (None, 14, 14, 192)  0           block_6_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_6_project (Conv2D)        (None, 14, 14, 64)   12288       block_6_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_6_project_BN (BatchNormal (None, 14, 14, 64)   256         block_6_project[0][0]            \n__________________________________________________________________________________________________\nblock_7_expand (Conv2D)         (None, 14, 14, 384)  24576       block_6_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_7_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_7_expand[0][0]             \n__________________________________________________________________________________________________\nblock_7_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_7_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_7_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_7_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_7_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_7_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_7_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_7_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_7_project (Conv2D)        (None, 14, 14, 64)   24576       block_7_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_7_project_BN (BatchNormal (None, 14, 14, 64)   256         block_7_project[0][0]            \n__________________________________________________________________________________________________\nblock_7_add (Add)               (None, 14, 14, 64)   0           block_6_project_BN[0][0]         \n                                                                 block_7_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_8_expand (Conv2D)         (None, 14, 14, 384)  24576       block_7_add[0][0]                \n__________________________________________________________________________________________________\nblock_8_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_8_expand[0][0]             \n__________________________________________________________________________________________________\nblock_8_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_8_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_8_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_8_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_8_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_8_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_8_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_8_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_8_project (Conv2D)        (None, 14, 14, 64)   24576       block_8_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_8_project_BN (BatchNormal (None, 14, 14, 64)   256         block_8_project[0][0]            \n__________________________________________________________________________________________________\nblock_8_add (Add)               (None, 14, 14, 64)   0           block_7_add[0][0]                \n                                                                 block_8_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_9_expand (Conv2D)         (None, 14, 14, 384)  24576       block_8_add[0][0]                \n__________________________________________________________________________________________________\nblock_9_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_9_expand[0][0]             \n__________________________________________________________________________________________________\nblock_9_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_9_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_9_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_9_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_9_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_9_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_9_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_9_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_9_project (Conv2D)        (None, 14, 14, 64)   24576       block_9_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_9_project_BN (BatchNormal (None, 14, 14, 64)   256         block_9_project[0][0]            \n__________________________________________________________________________________________________\nblock_9_add (Add)               (None, 14, 14, 64)   0           block_8_add[0][0]                \n                                                                 block_9_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_10_expand (Conv2D)        (None, 14, 14, 384)  24576       block_9_add[0][0]                \n__________________________________________________________________________________________________\nblock_10_expand_BN (BatchNormal (None, 14, 14, 384)  1536        block_10_expand[0][0]            \n__________________________________________________________________________________________________\nblock_10_expand_relu (ReLU)     (None, 14, 14, 384)  0           block_10_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_10_depthwise (DepthwiseCo (None, 14, 14, 384)  3456        block_10_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_10_depthwise_BN (BatchNor (None, 14, 14, 384)  1536        block_10_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           block_10_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_10_project (Conv2D)       (None, 14, 14, 96)   36864       block_10_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_10_project_BN (BatchNorma (None, 14, 14, 96)   384         block_10_project[0][0]           \n__________________________________________________________________________________________________\nblock_11_expand (Conv2D)        (None, 14, 14, 576)  55296       block_10_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_11_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_11_expand[0][0]            \n__________________________________________________________________________________________________\nblock_11_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_11_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_11_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_11_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_11_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_11_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_11_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_11_project (Conv2D)       (None, 14, 14, 96)   55296       block_11_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_11_project_BN (BatchNorma (None, 14, 14, 96)   384         block_11_project[0][0]           \n__________________________________________________________________________________________________\nblock_11_add (Add)              (None, 14, 14, 96)   0           block_10_project_BN[0][0]        \n                                                                 block_11_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_12_expand (Conv2D)        (None, 14, 14, 576)  55296       block_11_add[0][0]               \n__________________________________________________________________________________________________\nblock_12_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_12_expand[0][0]            \n__________________________________________________________________________________________________\nblock_12_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_12_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_12_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_12_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_12_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_12_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_12_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_12_project (Conv2D)       (None, 14, 14, 96)   55296       block_12_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_12_project_BN (BatchNorma (None, 14, 14, 96)   384         block_12_project[0][0]           \n__________________________________________________________________________________________________\nblock_12_add (Add)              (None, 14, 14, 96)   0           block_11_add[0][0]               \n                                                                 block_12_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_13_expand (Conv2D)        (None, 14, 14, 576)  55296       block_12_add[0][0]               \n__________________________________________________________________________________________________\nblock_13_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_13_expand[0][0]            \n__________________________________________________________________________________________________\nblock_13_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_13_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_13_pad (ZeroPadding2D)    (None, 15, 15, 576)  0           block_13_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_13_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_13_pad[0][0]               \n__________________________________________________________________________________________________\nblock_13_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_13_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_13_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_13_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_13_project (Conv2D)       (None, 7, 7, 160)    92160       block_13_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_13_project_BN (BatchNorma (None, 7, 7, 160)    640         block_13_project[0][0]           \n__________________________________________________________________________________________________\nblock_14_expand (Conv2D)        (None, 7, 7, 960)    153600      block_13_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_14_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_14_expand[0][0]            \n__________________________________________________________________________________________________\nblock_14_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_14_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_14_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_14_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_14_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_14_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_14_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_14_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_14_project (Conv2D)       (None, 7, 7, 160)    153600      block_14_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_14_project_BN (BatchNorma (None, 7, 7, 160)    640         block_14_project[0][0]           \n__________________________________________________________________________________________________\nblock_14_add (Add)              (None, 7, 7, 160)    0           block_13_project_BN[0][0]        \n                                                                 block_14_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_15_expand (Conv2D)        (None, 7, 7, 960)    153600      block_14_add[0][0]               \n__________________________________________________________________________________________________\nblock_15_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_15_expand[0][0]            \n__________________________________________________________________________________________________\nblock_15_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_15_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_15_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_15_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_15_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_15_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_15_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_15_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_15_project (Conv2D)       (None, 7, 7, 160)    153600      block_15_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_15_project_BN (BatchNorma (None, 7, 7, 160)    640         block_15_project[0][0]           \n__________________________________________________________________________________________________\nblock_15_add (Add)              (None, 7, 7, 160)    0           block_14_add[0][0]               \n                                                                 block_15_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_16_expand (Conv2D)        (None, 7, 7, 960)    153600      block_15_add[0][0]               \n__________________________________________________________________________________________________\nblock_16_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_16_expand[0][0]            \n__________________________________________________________________________________________________\nblock_16_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_16_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_16_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_16_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_16_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_16_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_16_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_16_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_16_project (Conv2D)       (None, 7, 7, 320)    307200      block_16_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_16_project_BN (BatchNorma (None, 7, 7, 320)    1280        block_16_project[0][0]           \n__________________________________________________________________________________________________\nConv_1 (Conv2D)                 (None, 7, 7, 1280)   409600      block_16_project_BN[0][0]        \n__________________________________________________________________________________________________\nConv_1_bn (BatchNormalization)  (None, 7, 7, 1280)   5120        Conv_1[0][0]                     \n__________________________________________________________________________________________________\nout_relu (ReLU)                 (None, 7, 7, 1280)   0           Conv_1_bn[0][0]                  \n==================================================================================================\nTotal params: 2,257,984\nTrainable params: 0\nNon-trainable params: 2,257,984\n__________________________________________________________________________________________________\nWhole model summary:\nModel: \"model_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n__________________________________________________________________________________________________\nConv1_pad (ZeroPadding2D)       (None, 225, 225, 3)  0           input_1[0][0]                    \n__________________________________________________________________________________________________\nConv1 (Conv2D)                  (None, 112, 112, 32) 864         Conv1_pad[0][0]                  \n__________________________________________________________________________________________________\nbn_Conv1 (BatchNormalization)   (None, 112, 112, 32) 128         Conv1[0][0]                      \n__________________________________________________________________________________________________\nConv1_relu (ReLU)               (None, 112, 112, 32) 0           bn_Conv1[0][0]                   \n__________________________________________________________________________________________________\nexpanded_conv_depthwise (Depthw (None, 112, 112, 32) 288         Conv1_relu[0][0]                 \n__________________________________________________________________________________________________\nexpanded_conv_depthwise_BN (Bat (None, 112, 112, 32) 128         expanded_conv_depthwise[0][0]    \n__________________________________________________________________________________________________\nexpanded_conv_depthwise_relu (R (None, 112, 112, 32) 0           expanded_conv_depthwise_BN[0][0] \n__________________________________________________________________________________________________\nexpanded_conv_project (Conv2D)  (None, 112, 112, 16) 512         expanded_conv_depthwise_relu[0][0\n__________________________________________________________________________________________________\nexpanded_conv_project_BN (Batch (None, 112, 112, 16) 64          expanded_conv_project[0][0]      \n__________________________________________________________________________________________________\nblock_1_expand (Conv2D)         (None, 112, 112, 96) 1536        expanded_conv_project_BN[0][0]   \n__________________________________________________________________________________________________\nblock_1_expand_BN (BatchNormali (None, 112, 112, 96) 384         block_1_expand[0][0]             \n__________________________________________________________________________________________________\nblock_1_expand_relu (ReLU)      (None, 112, 112, 96) 0           block_1_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_1_pad (ZeroPadding2D)     (None, 113, 113, 96) 0           block_1_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_1_depthwise (DepthwiseCon (None, 56, 56, 96)   864         block_1_pad[0][0]                \n__________________________________________________________________________________________________\nblock_1_depthwise_BN (BatchNorm (None, 56, 56, 96)   384         block_1_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_1_depthwise_relu (ReLU)   (None, 56, 56, 96)   0           block_1_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_1_project (Conv2D)        (None, 56, 56, 24)   2304        block_1_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_1_project_BN (BatchNormal (None, 56, 56, 24)   96          block_1_project[0][0]            \n__________________________________________________________________________________________________\nblock_2_expand (Conv2D)         (None, 56, 56, 144)  3456        block_1_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_2_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_2_expand[0][0]             \n__________________________________________________________________________________________________\nblock_2_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_2_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_2_depthwise (DepthwiseCon (None, 56, 56, 144)  1296        block_2_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_2_depthwise_BN (BatchNorm (None, 56, 56, 144)  576         block_2_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_2_depthwise_relu (ReLU)   (None, 56, 56, 144)  0           block_2_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_2_project (Conv2D)        (None, 56, 56, 24)   3456        block_2_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_2_project_BN (BatchNormal (None, 56, 56, 24)   96          block_2_project[0][0]            \n__________________________________________________________________________________________________\nblock_2_add (Add)               (None, 56, 56, 24)   0           block_1_project_BN[0][0]         \n                                                                 block_2_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_3_expand (Conv2D)         (None, 56, 56, 144)  3456        block_2_add[0][0]                \n__________________________________________________________________________________________________\nblock_3_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_3_expand[0][0]             \n__________________________________________________________________________________________________\nblock_3_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_3_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_3_pad (ZeroPadding2D)     (None, 57, 57, 144)  0           block_3_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_3_depthwise (DepthwiseCon (None, 28, 28, 144)  1296        block_3_pad[0][0]                \n__________________________________________________________________________________________________\nblock_3_depthwise_BN (BatchNorm (None, 28, 28, 144)  576         block_3_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_3_depthwise_relu (ReLU)   (None, 28, 28, 144)  0           block_3_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_3_project (Conv2D)        (None, 28, 28, 32)   4608        block_3_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_3_project_BN (BatchNormal (None, 28, 28, 32)   128         block_3_project[0][0]            \n__________________________________________________________________________________________________\nblock_4_expand (Conv2D)         (None, 28, 28, 192)  6144        block_3_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_4_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_4_expand[0][0]             \n__________________________________________________________________________________________________\nblock_4_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_4_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_4_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_4_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_4_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_4_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_4_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_4_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_4_project (Conv2D)        (None, 28, 28, 32)   6144        block_4_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_4_project_BN (BatchNormal (None, 28, 28, 32)   128         block_4_project[0][0]            \n__________________________________________________________________________________________________\nblock_4_add (Add)               (None, 28, 28, 32)   0           block_3_project_BN[0][0]         \n                                                                 block_4_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_5_expand (Conv2D)         (None, 28, 28, 192)  6144        block_4_add[0][0]                \n__________________________________________________________________________________________________\nblock_5_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_5_expand[0][0]             \n__________________________________________________________________________________________________\nblock_5_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_5_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_5_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_5_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_5_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_5_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_5_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_5_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_5_project (Conv2D)        (None, 28, 28, 32)   6144        block_5_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_5_project_BN (BatchNormal (None, 28, 28, 32)   128         block_5_project[0][0]            \n__________________________________________________________________________________________________\nblock_5_add (Add)               (None, 28, 28, 32)   0           block_4_add[0][0]                \n                                                                 block_5_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_6_expand (Conv2D)         (None, 28, 28, 192)  6144        block_5_add[0][0]                \n__________________________________________________________________________________________________\nblock_6_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_6_expand[0][0]             \n__________________________________________________________________________________________________\nblock_6_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_6_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_6_pad (ZeroPadding2D)     (None, 29, 29, 192)  0           block_6_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_6_depthwise (DepthwiseCon (None, 14, 14, 192)  1728        block_6_pad[0][0]                \n__________________________________________________________________________________________________\nblock_6_depthwise_BN (BatchNorm (None, 14, 14, 192)  768         block_6_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_6_depthwise_relu (ReLU)   (None, 14, 14, 192)  0           block_6_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_6_project (Conv2D)        (None, 14, 14, 64)   12288       block_6_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_6_project_BN (BatchNormal (None, 14, 14, 64)   256         block_6_project[0][0]            \n__________________________________________________________________________________________________\nblock_7_expand (Conv2D)         (None, 14, 14, 384)  24576       block_6_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_7_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_7_expand[0][0]             \n__________________________________________________________________________________________________\nblock_7_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_7_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_7_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_7_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_7_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_7_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_7_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_7_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_7_project (Conv2D)        (None, 14, 14, 64)   24576       block_7_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_7_project_BN (BatchNormal (None, 14, 14, 64)   256         block_7_project[0][0]            \n__________________________________________________________________________________________________\nblock_7_add (Add)               (None, 14, 14, 64)   0           block_6_project_BN[0][0]         \n                                                                 block_7_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_8_expand (Conv2D)         (None, 14, 14, 384)  24576       block_7_add[0][0]                \n__________________________________________________________________________________________________\nblock_8_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_8_expand[0][0]             \n__________________________________________________________________________________________________\nblock_8_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_8_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_8_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_8_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_8_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_8_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_8_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_8_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_8_project (Conv2D)        (None, 14, 14, 64)   24576       block_8_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_8_project_BN (BatchNormal (None, 14, 14, 64)   256         block_8_project[0][0]            \n__________________________________________________________________________________________________\nblock_8_add (Add)               (None, 14, 14, 64)   0           block_7_add[0][0]                \n                                                                 block_8_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_9_expand (Conv2D)         (None, 14, 14, 384)  24576       block_8_add[0][0]                \n__________________________________________________________________________________________________\nblock_9_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_9_expand[0][0]             \n__________________________________________________________________________________________________\nblock_9_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_9_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_9_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_9_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_9_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_9_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_9_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_9_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_9_project (Conv2D)        (None, 14, 14, 64)   24576       block_9_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_9_project_BN (BatchNormal (None, 14, 14, 64)   256         block_9_project[0][0]            \n__________________________________________________________________________________________________\nblock_9_add (Add)               (None, 14, 14, 64)   0           block_8_add[0][0]                \n                                                                 block_9_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_10_expand (Conv2D)        (None, 14, 14, 384)  24576       block_9_add[0][0]                \n__________________________________________________________________________________________________\nblock_10_expand_BN (BatchNormal (None, 14, 14, 384)  1536        block_10_expand[0][0]            \n__________________________________________________________________________________________________\nblock_10_expand_relu (ReLU)     (None, 14, 14, 384)  0           block_10_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_10_depthwise (DepthwiseCo (None, 14, 14, 384)  3456        block_10_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_10_depthwise_BN (BatchNor (None, 14, 14, 384)  1536        block_10_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           block_10_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_10_project (Conv2D)       (None, 14, 14, 96)   36864       block_10_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_10_project_BN (BatchNorma (None, 14, 14, 96)   384         block_10_project[0][0]           \n__________________________________________________________________________________________________\nblock_11_expand (Conv2D)        (None, 14, 14, 576)  55296       block_10_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_11_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_11_expand[0][0]            \n__________________________________________________________________________________________________\nblock_11_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_11_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_11_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_11_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_11_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_11_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_11_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_11_project (Conv2D)       (None, 14, 14, 96)   55296       block_11_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_11_project_BN (BatchNorma (None, 14, 14, 96)   384         block_11_project[0][0]           \n__________________________________________________________________________________________________\nblock_11_add (Add)              (None, 14, 14, 96)   0           block_10_project_BN[0][0]        \n                                                                 block_11_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_12_expand (Conv2D)        (None, 14, 14, 576)  55296       block_11_add[0][0]               \n__________________________________________________________________________________________________\nblock_12_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_12_expand[0][0]            \n__________________________________________________________________________________________________\nblock_12_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_12_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_12_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_12_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_12_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_12_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_12_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_12_project (Conv2D)       (None, 14, 14, 96)   55296       block_12_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_12_project_BN (BatchNorma (None, 14, 14, 96)   384         block_12_project[0][0]           \n__________________________________________________________________________________________________\nblock_12_add (Add)              (None, 14, 14, 96)   0           block_11_add[0][0]               \n                                                                 block_12_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_13_expand (Conv2D)        (None, 14, 14, 576)  55296       block_12_add[0][0]               \n__________________________________________________________________________________________________\nblock_13_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_13_expand[0][0]            \n__________________________________________________________________________________________________\nblock_13_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_13_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_13_pad (ZeroPadding2D)    (None, 15, 15, 576)  0           block_13_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_13_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_13_pad[0][0]               \n__________________________________________________________________________________________________\nblock_13_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_13_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_13_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_13_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_13_project (Conv2D)       (None, 7, 7, 160)    92160       block_13_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_13_project_BN (BatchNorma (None, 7, 7, 160)    640         block_13_project[0][0]           \n__________________________________________________________________________________________________\nblock_14_expand (Conv2D)        (None, 7, 7, 960)    153600      block_13_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_14_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_14_expand[0][0]            \n__________________________________________________________________________________________________\nblock_14_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_14_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_14_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_14_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_14_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_14_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_14_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_14_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_14_project (Conv2D)       (None, 7, 7, 160)    153600      block_14_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_14_project_BN (BatchNorma (None, 7, 7, 160)    640         block_14_project[0][0]           \n__________________________________________________________________________________________________\nblock_14_add (Add)              (None, 7, 7, 160)    0           block_13_project_BN[0][0]        \n                                                                 block_14_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_15_expand (Conv2D)        (None, 7, 7, 960)    153600      block_14_add[0][0]               \n__________________________________________________________________________________________________\nblock_15_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_15_expand[0][0]            \n__________________________________________________________________________________________________\nblock_15_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_15_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_15_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_15_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_15_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_15_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_15_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_15_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_15_project (Conv2D)       (None, 7, 7, 160)    153600      block_15_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_15_project_BN (BatchNorma (None, 7, 7, 160)    640         block_15_project[0][0]           \n__________________________________________________________________________________________________\nblock_15_add (Add)              (None, 7, 7, 160)    0           block_14_add[0][0]               \n                                                                 block_15_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_16_expand (Conv2D)        (None, 7, 7, 960)    153600      block_15_add[0][0]               \n__________________________________________________________________________________________________\nblock_16_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_16_expand[0][0]            \n__________________________________________________________________________________________________\nblock_16_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_16_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_16_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_16_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_16_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_16_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_16_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_16_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_16_project (Conv2D)       (None, 7, 7, 320)    307200      block_16_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_16_project_BN (BatchNorma (None, 7, 7, 320)    1280        block_16_project[0][0]           \n__________________________________________________________________________________________________\nConv_1 (Conv2D)                 (None, 7, 7, 1280)   409600      block_16_project_BN[0][0]        \n__________________________________________________________________________________________________\nConv_1_bn (BatchNormalization)  (None, 7, 7, 1280)   5120        Conv_1[0][0]                     \n__________________________________________________________________________________________________\nout_relu (ReLU)                 (None, 7, 7, 1280)   0           Conv_1_bn[0][0]                  \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 7, 7, 1280)   1639680     out_relu[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 7, 7, 1280)   5120        conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nglobal_average_pooling2d_1 (Glo (None, 1280)         0           batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\nglobal_max_pooling2d_1 (GlobalM (None, 1280)         0           batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\nreshape_1 (Reshape)             (None, 1, 1, 1280)   0           global_average_pooling2d_1[0][0] \n__________________________________________________________________________________________________\nreshape_2 (Reshape)             (None, 1, 1, 1280)   0           global_max_pooling2d_1[0][0]     \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 1, 1, 160)    204960      reshape_1[0][0]                  \n                                                                 reshape_2[0][0]                  \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 1, 1, 1280)   206080      dense_1[0][0]                    \n                                                                 dense_1[1][0]                    \n__________________________________________________________________________________________________\nadd_1 (Add)                     (None, 1, 1, 1280)   0           dense_2[0][0]                    \n                                                                 dense_2[1][0]                    \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, 1, 1, 1280)   0           add_1[0][0]                      \n__________________________________________________________________________________________________\nmultiply_1 (Multiply)           (None, 7, 7, 1280)   0           batch_normalization_1[0][0]      \n                                                                 activation_1[0][0]               \n__________________________________________________________________________________________________\nlambda_1 (Lambda)               (None, 7, 7, 1)      0           multiply_1[0][0]                 \n__________________________________________________________________________________________________\nlambda_2 (Lambda)               (None, 7, 7, 1)      0           multiply_1[0][0]                 \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 7, 7, 2)      0           lambda_1[0][0]                   \n                                                                 lambda_2[0][0]                   \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 7, 7, 1)      98          concatenate_1[0][0]              \n__________________________________________________________________________________________________\nmultiply_2 (Multiply)           (None, 7, 7, 1280)   0           multiply_1[0][0]                 \n                                                                 conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nadd_2 (Add)                     (None, 7, 7, 1280)   0           out_relu[0][0]                   \n                                                                 batch_normalization_1[0][0]      \n                                                                 multiply_2[0][0]                 \n__________________________________________________________________________________________________\nglobal_average_pooling2d_2 (Glo (None, 1280)         0           add_2[0][0]                      \n__________________________________________________________________________________________________\ndense_3 (Dense)                 (None, 2)            2562        global_average_pooling2d_2[0][0] \n==================================================================================================\nTotal params: 4,316,484\nTrainable params: 2,055,940\nNon-trainable params: 2,260,544\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport keras\nprint(keras.__version__)\nimport tensorflow\nprint(keras.__version__)\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n!pip install Livelossplot\nfrom livelossplot import PlotLossesKeras\n\nfrom glob import glob\nimport os\nimport shutil\n\nimport numpy as np\nimport pandas as pd\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:18:31.616194Z","iopub.execute_input":"2022-05-11T21:18:31.616458Z","iopub.status.idle":"2022-05-11T21:18:41.024373Z","shell.execute_reply.started":"2022-05-11T21:18:31.616422Z","shell.execute_reply":"2022-05-11T21:18:41.023570Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"2.2.5\n2.2.5\nCollecting Livelossplot\n  Downloading livelossplot-0.5.5-py3-none-any.whl (22 kB)\nRequirement already satisfied: bokeh in /opt/conda/lib/python3.7/site-packages (from Livelossplot) (2.4.2)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from Livelossplot) (3.5.1)\nRequirement already satisfied: ipython==7.* in /opt/conda/lib/python3.7/site-packages (from Livelossplot) (7.32.0)\nRequirement already satisfied: numpy<1.22 in /opt/conda/lib/python3.7/site-packages (from Livelossplot) (1.21.6)\nRequirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython==7.*->Livelossplot) (0.2.0)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython==7.*->Livelossplot) (5.1.1)\nRequirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython==7.*->Livelossplot) (59.8.0)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython==7.*->Livelossplot) (0.18.1)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython==7.*->Livelossplot) (3.0.27)\nRequirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython==7.*->Livelossplot) (0.7.5)\nRequirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipython==7.*->Livelossplot) (5.1.1)\nRequirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.7/site-packages (from ipython==7.*->Livelossplot) (0.1.3)\nRequirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython==7.*->Livelossplot) (2.11.2)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython==7.*->Livelossplot) (4.8.0)\nRequirement already satisfied: pillow>=7.1.0 in /opt/conda/lib/python3.7/site-packages (from bokeh->Livelossplot) (9.0.1)\nRequirement already satisfied: Jinja2>=2.9 in /opt/conda/lib/python3.7/site-packages (from bokeh->Livelossplot) (3.1.1)\nRequirement already satisfied: PyYAML>=3.10 in /opt/conda/lib/python3.7/site-packages (from bokeh->Livelossplot) (6.0)\nRequirement already satisfied: typing-extensions>=3.10.0 in /opt/conda/lib/python3.7/site-packages (from bokeh->Livelossplot) (4.2.0)\nRequirement already satisfied: tornado>=5.1 in /opt/conda/lib/python3.7/site-packages (from bokeh->Livelossplot) (6.1)\nRequirement already satisfied: packaging>=16.8 in /opt/conda/lib/python3.7/site-packages (from bokeh->Livelossplot) (21.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->Livelossplot) (1.4.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->Livelossplot) (4.30.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->Livelossplot) (0.11.0)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->Livelossplot) (2.8.2)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->Livelossplot) (3.0.7)\nRequirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython==7.*->Livelossplot) (0.8.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from Jinja2>=2.9->bokeh->Livelossplot) (2.0.1)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3->ipython==7.*->Livelossplot) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.*->Livelossplot) (0.2.5)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->Livelossplot) (1.16.0)\nInstalling collected packages: Livelossplot\nSuccessfully installed Livelossplot-0.5.5\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom PIL import Image\nimport scipy\n\n#import tensorflow as tf\nprint(keras.__version__)\n#print(tf.__version__)\nfrom keras.applications import *\nfrom keras.optimizers import *\nfrom keras.losses import *\nfrom keras.layers import *\nfrom keras.models import *\nfrom keras.callbacks import *\nfrom keras.preprocessing.image import *\nfrom keras.utils import *\n# import pydot\n\nfrom sklearn.metrics import *\nfrom sklearn.model_selection import *\nimport tensorflow.keras.backend as K\n\nfrom tqdm import tqdm, tqdm_notebook\nfrom colorama import Fore\nimport json\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom glob import glob\nfrom skimage.io import *\n%config Completer.use_jedi = False\nimport time\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nimport lightgbm as lgb\nimport xgboost as xgb\n\nprint(\"All modules have been imported\")","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:18:41.026945Z","iopub.execute_input":"2022-05-11T21:18:41.027213Z","iopub.status.idle":"2022-05-11T21:18:43.264535Z","shell.execute_reply.started":"2022-05-11T21:18:41.027175Z","shell.execute_reply":"2022-05-11T21:18:43.263828Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"2.2.5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .time    { background: #40CC40; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tbody td { text-align: left; }\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .sp {  opacity: 0.25;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}},{"name":"stdout","text":"All modules have been imported\n","output_type":"stream"}]},{"cell_type":"code","source":"sampling_seed=0\nsize_4_training=100\n#img_size=224\n#training_reshape=(-1, img_size, img_size, 3)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:18:43.265895Z","iopub.execute_input":"2022-05-11T21:18:43.266289Z","iopub.status.idle":"2022-05-11T21:18:43.270017Z","shell.execute_reply.started":"2022-05-11T21:18:43.266251Z","shell.execute_reply":"2022-05-11T21:18:43.269327Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\nos.makedirs('../working/data/train_seg/idc-minus/')     \nos.makedirs('../working/data/train_seg/idc-plus/')  \nos.makedirs('../working/data/test_seg/idc-minus/')     \nos.makedirs('../working/data/test_seg/idc-plus/')  \nos.makedirs('../working/data/val_seg/idc-minus/')     \nos.makedirs('../working/data/val_seg/idc-plus/')  \n","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:18:43.271262Z","iopub.execute_input":"2022-05-11T21:18:43.271694Z","iopub.status.idle":"2022-05-11T21:18:43.281169Z","shell.execute_reply.started":"2022-05-11T21:18:43.271656Z","shell.execute_reply":"2022-05-11T21:18:43.280391Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import random\nimport shutil\nfrom glob import glob \n#make directory for labelling\n\ntrain_dir='../working/data/train_seg/'\nvalidation_dir='../working/data/val_seg/'\n#train_dir='../working/data/train_seg/'  \n#test_dir = '../working/data/test_seg/normal'  \ntest_dir = '../working/data/test_seg/'  \n\nclass0 = [] # 0 = idc+\nclass1 = [] # 1 = idc-\nimagePatches = glob('../input/breast-histopathology-images/IDC_regular_ps50_idx5/**/*.png', recursive=True)\nfor filename in imagePatches:\n    if filename.endswith(\"class0.png\"):\n         class0.append(filename)\n    else:\n        class1.append(filename)\n\nprint(class0[0:10])\n\n#sampling 10000 images from class 0 and class 1 to train the model\n\nrandom.seed(sampling_seed)\nclass0sample=random.sample(class0,size_4_training)\nclass0label=np.zeros(size_4_training)\nclass1sample=random.sample(class1,size_4_training)\nclass1label=np.ones(size_4_training)\n\nclass0sample_train, class0sample_test1, class0label_train, class0label_test1 = train_test_split(class0sample, class0label, test_size=0.3, random_state=42)\nclass0sample_test,class0sample_val,  class0label_test, class0label_val = train_test_split(class0sample_test1, class0label_test1, test_size=0.3, random_state=42)\nprint(len(class0sample_train))\nprint(len(class0sample_test))\nprint(len(class0sample_val))\nclass1sample_train, class1sample_test1, class1label_train, class1label_test1 = train_test_split(class1sample, class1label, test_size=0.3, random_state=42)\nclass1sample_test, class1sample_val, class1label_test, class1label_val = train_test_split(class1sample_test1, class1label_test1, test_size=0.3, random_state=42)\nprint(len(class1sample_train))\nprint(len(class1sample_test))\nprint(len(class1sample_val))\ndef read_and_save_data(path, file_name_array):\n    j=0\n    for i in file_name_array:\n        if i.endswith('.png'):\n          \n            \n            #second copy method\n            head, tail = os.path.split(i)\n            outputname=str(path+tail)\n            #outputname=str(path+str(j)+'.png')\n            print(outputname)\n            shutil.copy(i, outputname)\n   \n            #print(status2)\n            \n            j=j+1\n            if j==120000:\n                break\n            \n   \nclass0train_path='../working/data/train_seg/idc-minus/'\nclass1train_path='../working/data/train_seg/idc-plus/'\nclass0test_path='../working/data/test_seg/idc-minus/'\nclass1test_path='../working/data/test_seg/idc-plus/'\nclass0val_path='../working/data/val_seg/idc-minus/'\nclass1val_path='../working/data/val_seg/idc-plus/'\n\nread_and_save_data(class0train_path,class0sample_train)\nread_and_save_data(class1train_path,class1sample_train)\n\n\nread_and_save_data(class0test_path,class0sample_test)\nread_and_save_data(class1test_path,class1sample_test)\n\n\nread_and_save_data(class0val_path,class0sample_val)\nread_and_save_data(class1val_path,class1sample_val)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:18:43.282486Z","iopub.execute_input":"2022-05-11T21:18:43.283140Z","iopub.status.idle":"2022-05-11T21:21:09.367959Z","shell.execute_reply.started":"2022-05-11T21:18:43.283089Z","shell.execute_reply":"2022-05-11T21:21:09.367250Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"['../input/breast-histopathology-images/IDC_regular_ps50_idx5/10295/0/10295_idx5_x1351_y1101_class0.png', '../input/breast-histopathology-images/IDC_regular_ps50_idx5/10295/0/10295_idx5_x1501_y501_class0.png', '../input/breast-histopathology-images/IDC_regular_ps50_idx5/10295/0/10295_idx5_x1501_y1101_class0.png', '../input/breast-histopathology-images/IDC_regular_ps50_idx5/10295/0/10295_idx5_x451_y901_class0.png', '../input/breast-histopathology-images/IDC_regular_ps50_idx5/10295/0/10295_idx5_x801_y451_class0.png', '../input/breast-histopathology-images/IDC_regular_ps50_idx5/10295/0/10295_idx5_x151_y1051_class0.png', '../input/breast-histopathology-images/IDC_regular_ps50_idx5/10295/0/10295_idx5_x1351_y901_class0.png', '../input/breast-histopathology-images/IDC_regular_ps50_idx5/10295/0/10295_idx5_x701_y651_class0.png', '../input/breast-histopathology-images/IDC_regular_ps50_idx5/10295/0/10295_idx5_x951_y1401_class0.png', '../input/breast-histopathology-images/IDC_regular_ps50_idx5/10295/0/10295_idx5_x601_y501_class0.png']\n70\n21\n9\n70\n21\n9\n../working/data/train_seg/idc-minus/12890_idx5_x1351_y2401_class0.png\n../working/data/train_seg/idc-minus/14190_idx5_x601_y1501_class0.png\n../working/data/train_seg/idc-minus/16531_idx5_x1051_y551_class0.png\n../working/data/train_seg/idc-minus/12910_idx5_x2151_y801_class0.png\n../working/data/train_seg/idc-minus/14154_idx5_x3451_y1251_class0.png\n../working/data/train_seg/idc-minus/12750_idx5_x951_y1451_class0.png\n../working/data/train_seg/idc-minus/8867_idx5_x3001_y1701_class0.png\n../working/data/train_seg/idc-minus/8864_idx5_x951_y1801_class0.png\n../working/data/train_seg/idc-minus/9322_idx5_x1751_y651_class0.png\n../working/data/train_seg/idc-minus/12911_idx5_x2251_y151_class0.png\n../working/data/train_seg/idc-minus/10303_idx5_x1001_y2001_class0.png\n../working/data/train_seg/idc-minus/9023_idx5_x2101_y1251_class0.png\n../working/data/train_seg/idc-minus/13400_idx5_x1601_y1851_class0.png\n../working/data/train_seg/idc-minus/8867_idx5_x1301_y701_class0.png\n../working/data/train_seg/idc-minus/9254_idx5_x1151_y851_class0.png\n../working/data/train_seg/idc-minus/9382_idx5_x501_y1551_class0.png\n../working/data/train_seg/idc-minus/9250_idx5_x2301_y551_class0.png\n../working/data/train_seg/idc-minus/9226_idx5_x1001_y651_class0.png\n../working/data/train_seg/idc-minus/10262_idx5_x2551_y1001_class0.png\n../working/data/train_seg/idc-minus/10264_idx5_x1201_y501_class0.png\n../working/data/train_seg/idc-minus/10254_idx5_x2351_y751_class0.png\n../working/data/train_seg/idc-minus/10299_idx5_x901_y501_class0.png\n../working/data/train_seg/idc-minus/9037_idx5_x51_y1151_class0.png\n../working/data/train_seg/idc-minus/15510_idx5_x2501_y2001_class0.png\n../working/data/train_seg/idc-minus/9123_idx5_x1951_y2251_class0.png\n../working/data/train_seg/idc-minus/14156_idx5_x2801_y1901_class0.png\n../working/data/train_seg/idc-minus/16085_idx5_x1651_y1351_class0.png\n../working/data/train_seg/idc-minus/12905_idx5_x1401_y751_class0.png\n../working/data/train_seg/idc-minus/14154_idx5_x3501_y1401_class0.png\n../working/data/train_seg/idc-minus/10286_idx5_x951_y151_class0.png\n../working/data/train_seg/idc-minus/13691_idx5_x2901_y101_class0.png\n../working/data/train_seg/idc-minus/9075_idx5_x2001_y1051_class0.png\n../working/data/train_seg/idc-minus/10295_idx5_x1501_y551_class0.png\n../working/data/train_seg/idc-minus/10278_idx5_x1701_y1051_class0.png\n../working/data/train_seg/idc-minus/10269_idx5_x701_y701_class0.png\n../working/data/train_seg/idc-minus/12911_idx5_x1001_y1401_class0.png\n../working/data/train_seg/idc-minus/15515_idx5_x2751_y451_class0.png\n../working/data/train_seg/idc-minus/12626_idx5_x1851_y1551_class0.png\n../working/data/train_seg/idc-minus/12951_idx5_x1701_y501_class0.png\n../working/data/train_seg/idc-minus/8975_idx5_x2601_y2501_class0.png\n../working/data/train_seg/idc-minus/12898_idx5_x351_y651_class0.png\n../working/data/train_seg/idc-minus/13613_idx5_x1851_y351_class0.png\n../working/data/train_seg/idc-minus/16166_idx5_x2751_y1201_class0.png\n../working/data/train_seg/idc-minus/10259_idx5_x1801_y1201_class0.png\n../working/data/train_seg/idc-minus/9075_idx5_x2401_y1351_class0.png\n../working/data/train_seg/idc-minus/14191_idx5_x1701_y501_class0.png\n../working/data/train_seg/idc-minus/9261_idx5_x1001_y2551_class0.png\n../working/data/train_seg/idc-minus/12897_idx5_x3501_y851_class0.png\n../working/data/train_seg/idc-minus/12934_idx5_x2751_y2701_class0.png\n../working/data/train_seg/idc-minus/9254_idx5_x1701_y351_class0.png\n../working/data/train_seg/idc-minus/13025_idx5_x751_y501_class0.png\n../working/data/train_seg/idc-minus/13692_idx5_x2601_y2551_class0.png\n../working/data/train_seg/idc-minus/10272_idx5_x851_y1551_class0.png\n../working/data/train_seg/idc-minus/8950_idx5_x851_y551_class0.png\n../working/data/train_seg/idc-minus/12873_idx5_x1451_y151_class0.png\n../working/data/train_seg/idc-minus/14157_idx5_x2651_y1101_class0.png\n../working/data/train_seg/idc-minus/9029_idx5_x2501_y1351_class0.png\n../working/data/train_seg/idc-minus/9177_idx5_x3001_y2001_class0.png\n../working/data/train_seg/idc-minus/14153_idx5_x2651_y2201_class0.png\n../working/data/train_seg/idc-minus/10305_idx5_x1551_y1101_class0.png\n../working/data/train_seg/idc-minus/12883_idx5_x2301_y401_class0.png\n../working/data/train_seg/idc-minus/14212_idx5_x3851_y2451_class0.png\n../working/data/train_seg/idc-minus/9250_idx5_x1951_y1301_class0.png\n../working/data/train_seg/idc-minus/14191_idx5_x1851_y801_class0.png\n../working/data/train_seg/idc-minus/10290_idx5_x951_y1101_class0.png\n../working/data/train_seg/idc-minus/15903_idx5_x2101_y1151_class0.png\n../working/data/train_seg/idc-minus/10300_idx5_x1901_y601_class0.png\n../working/data/train_seg/idc-minus/12911_idx5_x1301_y1651_class0.png\n../working/data/train_seg/idc-minus/14210_idx5_x551_y1601_class0.png\n../working/data/train_seg/idc-minus/9178_idx5_x601_y1601_class0.png\n../working/data/train_seg/idc-plus/13694_idx5_x1901_y2401_class1.png\n../working/data/train_seg/idc-plus/12906_idx5_x1601_y1501_class1.png\n../working/data/train_seg/idc-plus/16165_idx5_x2251_y2251_class1.png\n../working/data/train_seg/idc-plus/12751_idx5_x1501_y1801_class1.png\n../working/data/train_seg/idc-plus/10286_idx5_x1401_y301_class1.png\n../working/data/train_seg/idc-plus/9043_idx5_x3101_y301_class1.png\n../working/data/train_seg/idc-plus/14211_idx5_x2501_y1551_class1.png\n../working/data/train_seg/idc-plus/12898_idx5_x1601_y301_class1.png\n../working/data/train_seg/idc-plus/13613_idx5_x2301_y1701_class1.png\n../working/data/train_seg/idc-plus/9077_idx5_x1751_y1051_class1.png\n../working/data/train_seg/idc-plus/10290_idx5_x1301_y1051_class1.png\n../working/data/train_seg/idc-plus/10306_idx5_x901_y851_class1.png\n../working/data/train_seg/idc-plus/10299_idx5_x701_y1351_class1.png\n../working/data/train_seg/idc-plus/15903_idx5_x1051_y451_class1.png\n../working/data/train_seg/idc-plus/9077_idx5_x1151_y701_class1.png\n../working/data/train_seg/idc-plus/9023_idx5_x1551_y1951_class1.png\n../working/data/train_seg/idc-plus/9260_idx5_x701_y201_class1.png\n../working/data/train_seg/idc-plus/9135_idx5_x1101_y1801_class1.png\n../working/data/train_seg/idc-plus/13693_idx5_x1051_y851_class1.png\n../working/data/train_seg/idc-plus/10282_idx5_x1851_y1351_class1.png\n../working/data/train_seg/idc-plus/12900_idx5_x2601_y1051_class1.png\n../working/data/train_seg/idc-plus/10262_idx5_x1751_y1801_class1.png\n../working/data/train_seg/idc-plus/9029_idx5_x2051_y851_class1.png\n../working/data/train_seg/idc-plus/12626_idx5_x601_y1751_class1.png\n../working/data/train_seg/idc-plus/12891_idx5_x651_y851_class1.png\n../working/data/train_seg/idc-plus/12820_idx5_x1851_y851_class1.png\n../working/data/train_seg/idc-plus/13688_idx5_x1401_y1101_class1.png\n../working/data/train_seg/idc-plus/12906_idx5_x1751_y1651_class1.png\n../working/data/train_seg/idc-plus/8917_idx5_x1351_y851_class1.png\n../working/data/train_seg/idc-plus/12880_idx5_x1901_y701_class1.png\n../working/data/train_seg/idc-plus/10299_idx5_x1101_y1951_class1.png\n../working/data/train_seg/idc-plus/13022_idx5_x2251_y2051_class1.png\n../working/data/train_seg/idc-plus/16551_idx5_x2201_y2601_class1.png\n../working/data/train_seg/idc-plus/9344_idx5_x2451_y1001_class1.png\n../working/data/train_seg/idc-plus/14155_idx5_x3551_y551_class1.png\n../working/data/train_seg/idc-plus/8957_idx5_x1651_y701_class1.png\n../working/data/train_seg/idc-plus/16896_idx5_x651_y1351_class1.png\n../working/data/train_seg/idc-plus/14191_idx5_x2851_y2401_class1.png\n../working/data/train_seg/idc-plus/13462_idx5_x1551_y1051_class1.png\n../working/data/train_seg/idc-plus/10292_idx5_x1501_y1151_class1.png\n../working/data/train_seg/idc-plus/10299_idx5_x2251_y851_class1.png\n../working/data/train_seg/idc-plus/13021_idx5_x1901_y801_class1.png\n../working/data/train_seg/idc-plus/12907_idx5_x1901_y1501_class1.png\n../working/data/train_seg/idc-plus/14078_idx5_x1101_y1251_class1.png\n../working/data/train_seg/idc-plus/12895_idx5_x2301_y2101_class1.png\n../working/data/train_seg/idc-plus/12906_idx5_x2551_y601_class1.png\n../working/data/train_seg/idc-plus/14189_idx5_x1451_y1101_class1.png\n../working/data/train_seg/idc-plus/8956_idx5_x1301_y451_class1.png\n../working/data/train_seg/idc-plus/13694_idx5_x501_y2101_class1.png\n../working/data/train_seg/idc-plus/16166_idx5_x1701_y1301_class1.png\n../working/data/train_seg/idc-plus/9346_idx5_x1851_y1801_class1.png\n../working/data/train_seg/idc-plus/14191_idx5_x2851_y1701_class1.png\n../working/data/train_seg/idc-plus/12751_idx5_x2101_y1751_class1.png\n../working/data/train_seg/idc-plus/9083_idx5_x1851_y651_class1.png\n../working/data/train_seg/idc-plus/14191_idx5_x1501_y2251_class1.png\n../working/data/train_seg/idc-plus/10264_idx5_x1451_y801_class1.png\n../working/data/train_seg/idc-plus/15510_idx5_x2101_y1301_class1.png\n../working/data/train_seg/idc-plus/16014_idx5_x1001_y851_class1.png\n../working/data/train_seg/idc-plus/9124_idx5_x1101_y1001_class1.png\n../working/data/train_seg/idc-plus/10301_idx5_x1301_y1351_class1.png\n../working/data/train_seg/idc-plus/15514_idx5_x1051_y1551_class1.png\n../working/data/train_seg/idc-plus/9250_idx5_x1401_y1101_class1.png\n../working/data/train_seg/idc-plus/9382_idx5_x1601_y951_class1.png\n../working/data/train_seg/idc-plus/10264_idx5_x351_y1251_class1.png\n../working/data/train_seg/idc-plus/12882_idx5_x1351_y701_class1.png\n../working/data/train_seg/idc-plus/14209_idx5_x901_y951_class1.png\n../working/data/train_seg/idc-plus/8980_idx5_x1001_y851_class1.png\n../working/data/train_seg/idc-plus/9226_idx5_x801_y1801_class1.png\n../working/data/train_seg/idc-plus/9325_idx5_x2151_y451_class1.png\n../working/data/train_seg/idc-plus/9320_idx5_x1101_y1451_class1.png\n../working/data/test_seg/idc-minus/12626_idx5_x801_y1851_class0.png\n../working/data/test_seg/idc-minus/12880_idx5_x2351_y1351_class0.png\n../working/data/test_seg/idc-minus/9123_idx5_x2751_y1501_class0.png\n../working/data/test_seg/idc-minus/12879_idx5_x1151_y751_class0.png\n../working/data/test_seg/idc-minus/16550_idx5_x3351_y2201_class0.png\n../working/data/test_seg/idc-minus/13020_idx5_x1751_y1651_class0.png\n../working/data/test_seg/idc-minus/16550_idx5_x1851_y1851_class0.png\n../working/data/test_seg/idc-minus/16014_idx5_x1501_y851_class0.png\n../working/data/test_seg/idc-minus/10259_idx5_x1101_y1551_class0.png\n../working/data/test_seg/idc-minus/14192_idx5_x301_y751_class0.png\n../working/data/test_seg/idc-minus/10262_idx5_x701_y751_class0.png\n../working/data/test_seg/idc-minus/10306_idx5_x2151_y651_class0.png\n../working/data/test_seg/idc-minus/9173_idx5_x1451_y2051_class0.png\n../working/data/test_seg/idc-minus/12810_idx5_x3351_y1351_class0.png\n../working/data/test_seg/idc-minus/15472_idx5_x2451_y351_class0.png\n../working/data/test_seg/idc-minus/10272_idx5_x701_y851_class0.png\n../working/data/test_seg/idc-minus/10268_idx5_x2851_y1301_class0.png\n../working/data/test_seg/idc-minus/13402_idx5_x1151_y1201_class0.png\n../working/data/test_seg/idc-minus/10259_idx5_x1851_y2001_class0.png\n../working/data/test_seg/idc-minus/16551_idx5_x2851_y2151_class0.png\n../working/data/test_seg/idc-minus/12951_idx5_x1601_y1001_class0.png\n../working/data/test_seg/idc-plus/12880_idx5_x1251_y1301_class1.png\n../working/data/test_seg/idc-plus/9259_idx5_x1101_y1651_class1.png\n../working/data/test_seg/idc-plus/9346_idx5_x1051_y1901_class1.png\n../working/data/test_seg/idc-plus/9346_idx5_x1251_y1651_class1.png\n../working/data/test_seg/idc-plus/10257_idx5_x1501_y1401_class1.png\n../working/data/test_seg/idc-plus/14154_idx5_x2501_y1101_class1.png\n../working/data/test_seg/idc-plus/12817_idx5_x1001_y1401_class1.png\n../working/data/test_seg/idc-plus/9261_idx5_x2301_y1101_class1.png\n../working/data/test_seg/idc-plus/10306_idx5_x551_y1101_class1.png\n../working/data/test_seg/idc-plus/14192_idx5_x801_y1151_class1.png\n../working/data/test_seg/idc-plus/9022_idx5_x2501_y1151_class1.png\n../working/data/test_seg/idc-plus/8917_idx5_x751_y901_class1.png\n../working/data/test_seg/idc-plus/9260_idx5_x1101_y401_class1.png\n../working/data/test_seg/idc-plus/9023_idx5_x1651_y1551_class1.png\n../working/data/test_seg/idc-plus/10302_idx5_x2351_y1001_class1.png\n../working/data/test_seg/idc-plus/10257_idx5_x1701_y1501_class1.png\n../working/data/test_seg/idc-plus/10292_idx5_x2201_y1551_class1.png\n../working/data/test_seg/idc-plus/14155_idx5_x3051_y1501_class1.png\n../working/data/test_seg/idc-plus/12909_idx5_x1051_y751_class1.png\n../working/data/test_seg/idc-plus/14190_idx5_x1901_y1601_class1.png\n../working/data/test_seg/idc-plus/16165_idx5_x1401_y1251_class1.png\n../working/data/val_seg/idc-minus/9345_idx5_x2601_y1751_class0.png\n../working/data/val_seg/idc-minus/12880_idx5_x1051_y351_class0.png\n../working/data/val_seg/idc-minus/15634_idx5_x2351_y651_class0.png\n../working/data/val_seg/idc-minus/15515_idx5_x1151_y1201_class0.png\n../working/data/val_seg/idc-minus/16532_idx5_x2301_y701_class0.png\n../working/data/val_seg/idc-minus/14210_idx5_x1601_y1251_class0.png\n../working/data/val_seg/idc-minus/13613_idx5_x3201_y751_class0.png\n../working/data/val_seg/idc-minus/9256_idx5_x1701_y651_class0.png\n../working/data/val_seg/idc-minus/12884_idx5_x1501_y1401_class0.png\n../working/data/val_seg/idc-plus/10257_idx5_x1901_y1551_class1.png\n../working/data/val_seg/idc-plus/16550_idx5_x3001_y1751_class1.png\n../working/data/val_seg/idc-plus/12949_idx5_x1701_y1051_class1.png\n../working/data/val_seg/idc-plus/9324_idx5_x951_y851_class1.png\n../working/data/val_seg/idc-plus/10264_idx5_x801_y1101_class1.png\n../working/data/val_seg/idc-plus/10299_idx5_x1951_y1801_class1.png\n../working/data/val_seg/idc-plus/12821_idx5_x1551_y1551_class1.png\n../working/data/val_seg/idc-plus/10262_idx5_x1501_y1901_class1.png\n../working/data/val_seg/idc-plus/10308_idx5_x1051_y1551_class1.png\n","output_type":"stream"}]},{"cell_type":"code","source":"#shutil.rmtree('./working/data')","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:21:09.369472Z","iopub.execute_input":"2022-05-11T21:21:09.369728Z","iopub.status.idle":"2022-05-11T21:21:09.375386Z","shell.execute_reply.started":"2022-05-11T21:21:09.369694Z","shell.execute_reply":"2022-05-11T21:21:09.374693Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**load gen**","metadata":{}},{"cell_type":"code","source":"\n'''\nclass0train_path='../working/data/train_seg/idc-minus/'\nclass1train_path='../working/data/train_seg/idc-plus/'\nread_and_save_data(class0train_path,class0sample_train)\nread_and_save_data(class1train_path,class1sample_train)\n\nclass0test_path='../working/data/test_seg/idc-minus/'\nclass1test_path='../working/data/test_seg/idc-plus/'\nread_and_save_data(class0test_path,class0sample_test)\nread_and_save_data(class1test_path,class1sample_test)\n\nclass0val_path='../working/data/val_seg/idc-minus/'\nclass1val_path='../working/data/val_seg/idc-plus/'\nread_and_save_data(class0val_path,class0sample_val)\nread_and_save_data(class1val_path,class1sample_val)\n'''","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:21:09.376510Z","iopub.execute_input":"2022-05-11T21:21:09.376766Z","iopub.status.idle":"2022-05-11T21:21:09.385915Z","shell.execute_reply.started":"2022-05-11T21:21:09.376729Z","shell.execute_reply":"2022-05-11T21:21:09.385243Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"\"\\nclass0train_path='../working/data/train_seg/idc-minus/'\\nclass1train_path='../working/data/train_seg/idc-plus/'\\nread_and_save_data(class0train_path,class0sample_train)\\nread_and_save_data(class1train_path,class1sample_train)\\n\\nclass0test_path='../working/data/test_seg/idc-minus/'\\nclass1test_path='../working/data/test_seg/idc-plus/'\\nread_and_save_data(class0test_path,class0sample_test)\\nread_and_save_data(class1test_path,class1sample_test)\\n\\nclass0val_path='../working/data/val_seg/idc-minus/'\\nclass1val_path='../working/data/val_seg/idc-plus/'\\nread_and_save_data(class0val_path,class0sample_val)\\nread_and_save_data(class1val_path,class1sample_val)\\n\""},"metadata":{}}]},{"cell_type":"code","source":"import os\nimport cv2\ndef readImage(path, tag):\n    j=0\n    image_data = []\n    label=[]\n    for i in os.listdir(path):\n        imgname=path+i\n        #print(imgname)\n        img = cv2.imread(imgname, cv2.IMREAD_COLOR)\n        img_resized = cv2.resize(img, (224,224), interpolation=cv2.INTER_LINEAR)\n        image_data.append(img_resized)\n        label.append(tag)\n        #print(img[1])\n        j=j+1\n        #if j==10:\n        #    break\n        \n    return image_data, label\n\nimport numpy as np\nfrom tensorflow.keras.utils import *\nfrom sklearn.utils import shuffle\n\nclass0_train, train0_label = readImage(class0train_path, 0)\nclass1_train, train1_label  = readImage(class1train_path, 1)\nclass0_test, test0_label = readImage(class0test_path, 0)\nclass1_test, test1_label = readImage(class1test_path, 1)\nclass0_val, val0_label = readImage(class0val_path, 0)\nclass1_val, val1_label = readImage(class1val_path, 1)\n\ndef Image_array_process(class0array,label0, class1array, label1):\n    class0_array=np.array(class0array)\n    class1_array=np.array(class1array)\n    combined_data = np.concatenate((class0_array, class1_array))\n    combined_label= np.concatenate((label0,label1))\n    assert len(combined_data) == len(combined_label)\n    combined_data, combined_label = shuffle(combined_data, combined_label, random_state=0)\n    print(combined_data.shape)\n    length=len(combined_data)\n    combined_label=to_categorical(combined_label)\n    i=0\n    for i in range(length):\n        print(combined_label[i])\n\n    print\n\n    #print(class0_array.shape)\n    #print(combined_data.shape)\n    '''\n    training_reshape=(224,224,3)\n    length=len(combined_data)\n    print(length)\n    x =[None]*length\n    #print(img_data.type)\n    y =np.zeros(length)\n    i=0\n   \n    for features,label in combined_data:\n        x[i]=features\n        #print(x.shape)\n        y[i]=label\n        #print(y[i])\n        i=i+1\n    \n            #x = np.array(x).reshape(training_reshape)\n    x = np.array(x)    \n    #print(x.shape)\n    #y=np.array(y)\n    y=y.astype(int)\n    y = to_categorical(y)\n    print(y)\n    '''  \n    return combined_data, combined_label\n\n\nX_train, y_train=Image_array_process(class0_train, train0_label, class1_train, train1_label)\nX_test, y_test=Image_array_process(class0_test, test0_label, class1_test, test1_label)\nX_val, y_val=Image_array_process(class0_val, val0_label, class1_val, val1_label)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:21:09.388223Z","iopub.execute_input":"2022-05-11T21:21:09.388418Z","iopub.status.idle":"2022-05-11T21:21:09.555487Z","shell.execute_reply.started":"2022-05-11T21:21:09.388390Z","shell.execute_reply":"2022-05-11T21:21:09.554679Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"(140, 224, 224, 3)\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n(42, 224, 224, 3)\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n(18, 224, 224, 3)\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ntrain_dir='../working/data/train_seg/'  \ntest_dir = '../working/data/test_seg/idc-minus'  \nimg_size = (224, 224)  \nepochs = 30\nMODEL_PATH = '../working/log/tst_model.h5'\nboard_name1 = '../working/log/stage1/' + now + '/'\nboard_name2 = '../working/log/stage2/' + now + '/'\n\n#MODEL_PATH = '../working/log/tst_model.h5'\n#model.load_weights(MODEL_PATH)\n# --------------- test ----------------\ndirs = os.listdir(test_dir)\n\nprob_list = []\nfor d in dirs:\n    img = image.load_img(test_dir + os.sep + d, target_size=img_size)\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    y = model.predict(x)\n#    print(y)\n    #print(classes[np.argmax(y)])\n#    print(classes)\n\n    prob_list.append(str(y))   \n    file=open('../working/pred_prob.txt','w') \n    file.write('\\n'.join(prob_list))\n    file.close()\n    \n#import tensorflow as tf\n#config = tf.ConfigProto()\n#config.gpu_options.allow_growth = True\n#keras.backend.set_session(tf.Session(config=config))","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:21:09.557879Z","iopub.execute_input":"2022-05-11T21:21:09.558152Z","iopub.status.idle":"2022-05-11T21:21:12.987591Z","shell.execute_reply.started":"2022-05-11T21:21:09.558115Z","shell.execute_reply":"2022-05-11T21:21:12.986864Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"PLTv3","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Sun Jun 16 22:23:24 2020\n\n@author: HP\n\"\"\"\n'''\n\nfrom keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, multiply, Permute, Concatenate, Conv2D, Add, Activation, Lambda\nfrom keras import backend as K\nfrom keras.activations import sigmoid\n\n\nfrom keras import backend as K\nfrom keras import optimizers\nfrom tensorflow.keras.optimizers import Adam\nimport keras.backend.tensorflow_backend as KTF\n#import tensorflow.python.keras.backend as KTF\nimport glob\nfrom keras.layers import Input,Dense,Dropout,BatchNormalization,Conv2D,MaxPooling2D,AveragePooling2D,concatenate,Activation,ZeroPadding2D\nimport tensorflow as tf\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport keras\nfrom keras.models import load_model\nfrom keras.layers import Activation, Dense\nfrom matplotlib import pyplot as plt\nfrom skimage import io,data\nimport time\nfrom keras import layers\nfrom keras.callbacks import ModelCheckpoint, TensorBoard\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn import svm\nfrom sklearn.ensemble import RandomForestClassifier\nnow = time.strftime(\"%Y-%m-%d_%H-%M-%S\", time.localtime())\n\nimport os,sys\nos.getcwd()\n#os.chdir(\"../working/cjd/31_CNN_Attention\")\n\n#import tensorflow as tf\nfrom keras.preprocessing import image\nfrom keras.models import Model\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras import backend as K\nfrom keras import regularizers\n'''","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:21:12.989692Z","iopub.execute_input":"2022-05-11T21:21:12.989903Z","iopub.status.idle":"2022-05-11T21:21:12.996268Z","shell.execute_reply.started":"2022-05-11T21:21:12.989878Z","shell.execute_reply":"2022-05-11T21:21:12.995610Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"'\\n\\nfrom keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, multiply, Permute, Concatenate, Conv2D, Add, Activation, Lambda\\nfrom keras import backend as K\\nfrom keras.activations import sigmoid\\n\\n\\nfrom keras import backend as K\\nfrom keras import optimizers\\nfrom tensorflow.keras.optimizers import Adam\\nimport keras.backend.tensorflow_backend as KTF\\n#import tensorflow.python.keras.backend as KTF\\nimport glob\\nfrom keras.layers import Input,Dense,Dropout,BatchNormalization,Conv2D,MaxPooling2D,AveragePooling2D,concatenate,Activation,ZeroPadding2D\\nimport tensorflow as tf\\nimport cv2\\nimport numpy as np\\nimport pandas as pd\\nimport keras\\nfrom keras.models import load_model\\nfrom keras.layers import Activation, Dense\\nfrom matplotlib import pyplot as plt\\nfrom skimage import io,data\\nimport time\\nfrom keras import layers\\nfrom keras.callbacks import ModelCheckpoint, TensorBoard\\nfrom keras.preprocessing.image import ImageDataGenerator\\n\\nfrom sklearn import svm\\nfrom sklearn.ensemble import RandomForestClassifier\\nnow = time.strftime(\"%Y-%m-%d_%H-%M-%S\", time.localtime())\\n\\nimport os,sys\\nos.getcwd()\\n#os.chdir(\"../working/cjd/31_CNN_Attention\")\\n\\n#import tensorflow as tf\\nfrom keras.preprocessing import image\\nfrom keras.models import Model\\nfrom keras.layers import Dense, GlobalAveragePooling2D\\nfrom keras import backend as K\\nfrom keras import regularizers\\n'"},"metadata":{}}]},{"cell_type":"code","source":"\n\nprint(os.getcwd())\nprint (sys.version)\n#os.makedirs('../working/log/')    \n\n#import os\n# \nos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,5\"\n\n#import tensorflow as tf   \n#config = tf.ConfigProto()\n#config.gpu_options.allow_growth = True\n#keras.backend.tensorflow_backend.set_session(tf.Session(config=config))\n\n\n     \ndef focal_loss(gamma=2.):            \n    def focal_loss_fixed(y_true, y_pred):\n        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n        return -K.sum( K.pow(1. - pt_1, gamma) * K.log(pt_1)) \n    return focal_loss_fixed\n\n\ndef Conv2d_BN(x, nb_filter,kernel_size, strides=(1,1), padding='same',name=None):  \n    if name is not None:  \n        bn_name = name + '_bn'  \n        conv_name = name + '_conv'  \n    else:  \n        bn_name = None  \n        conv_name = None  \n  \n    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,activation='relu',name=conv_name)(x)  \n    x = BatchNormalization(axis=3,name=bn_name)(x)  \n    return x  \n\ndef Conv_Block(inpt,nb_filter,kernel_size,strides=(1,1), with_conv_shortcut=False):  \n    x = Conv2d_BN(inpt,nb_filter=nb_filter[0],kernel_size=(1,1),strides=strides,padding='same')  \n    x = Conv2d_BN(x, nb_filter=nb_filter[1], kernel_size=(3,3), padding='same')  \n    x = Conv2d_BN(x, nb_filter=nb_filter[2], kernel_size=(1,1), padding='same')  \n    if with_conv_shortcut:  \n        shortcut = Conv2d_BN(inpt,nb_filter=nb_filter[2],strides=strides,kernel_size=kernel_size)  \n        x = add([x,shortcut])  \n        return x  \n    else:  \n        x = add([x,inpt])  \n        return x  \n\n\ndef channel_attention(input_feature, ratio=8):\n\t\n\tchannel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n\tchannel = input_feature.shape[channel_axis]\n\t\n\tshared_layer_one = Dense(channel//ratio,\n\t\t\t\t\t\t\t kernel_initializer='he_normal',\n\t\t\t\t\t\t\t activation = 'relu',\n\t\t\t\t\t\t\t use_bias=True,\n\t\t\t\t\t\t\t bias_initializer='zeros')\n\n\tshared_layer_two = Dense(channel,\n\t\t\t\t\t\t\t kernel_initializer='he_normal',\n\t\t\t\t\t\t\t use_bias=True,\n\t\t\t\t\t\t\t bias_initializer='zeros')\n\t\n\tavg_pool = GlobalAveragePooling2D()(input_feature)    \n\tavg_pool = Reshape((1,1,channel))(avg_pool)\n\tassert avg_pool.shape[1:] == (1,1,channel)\n\tavg_pool = shared_layer_one(avg_pool)\n\tassert avg_pool.shape[1:] == (1,1,channel//ratio)\n\tavg_pool = shared_layer_two(avg_pool)\n\tassert avg_pool.shape[1:] == (1,1,channel)\n\t\n\tmax_pool = GlobalMaxPooling2D()(input_feature)\n\tmax_pool = Reshape((1,1,channel))(max_pool)\n\tassert max_pool.shape[1:] == (1,1,channel)\n\tmax_pool = shared_layer_one(max_pool)\n\tassert max_pool.shape[1:] == (1,1,channel//ratio)\n\tmax_pool = shared_layer_two(max_pool)\n\tassert max_pool.shape[1:] == (1,1,channel)\n\t\n\tcbam_feature = Add()([avg_pool,max_pool])\n\tcbam_feature = Activation('hard_sigmoid')(cbam_feature)\n\t\n\tif K.image_data_format() == \"channels_first\":\n\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n\t\n\treturn multiply([input_feature, cbam_feature])\n\n\ndef spatial_attention(input_feature):\n\tkernel_size = 7\n\tif K.image_data_format() == \"channels_first\":\n\t\tchannel = input_feature.shape[1]\n\t\tcbam_feature = Permute((2,3,1))(input_feature)\n\telse:\n\t\tchannel = input_feature.shape[-1]\n\t\tcbam_feature = input_feature\n\t\n\tavg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n\tassert avg_pool.shape[-1] == 1\n\tmax_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n\tassert max_pool.shape[-1] == 1\n\tconcat = Concatenate(axis=3)([avg_pool, max_pool])\n\tassert concat.shape[-1] == 2\n\tcbam_feature = Conv2D(filters = 1,\n\t\t\t\t\tkernel_size=kernel_size,\n\t\t\t\t\tactivation = 'hard_sigmoid',\n\t\t\t\t\tstrides=1,\n\t\t\t\t\tpadding='same',\n\t\t\t\t\tkernel_initializer='he_normal',\n\t\t\t\t\tuse_bias=False)(concat)\n\tassert cbam_feature.shape[-1] == 1\n\t\n\tif K.image_data_format() == \"channels_first\":\n\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n\t\t\n\treturn multiply([input_feature, cbam_feature])\n\n\ndef cbam_block(cbam_feature,ratio=8):\n\tcbam_feature = channel_attention(cbam_feature, ratio)\n\tcbam_feature = spatial_attention(cbam_feature, )\n\treturn cbam_feature\n\n\nbatch_size = 64 \nepochs = 30\n\nboard_name1 = '../working/log/stage1/' + now + '/'\nboard_name2 = '../working/log/stage2/' + now + '/'\n\nimg_size = (224, 224)  \n#classes=list(range(1,5))\n#classes=['1','2','3','4']\nimport os\nimport glob\nnb_train_samples = len(glob.glob(train_dir + '/*/*.*'))  \nnb_validation_samples = len(glob.glob(validation_dir + '/*/*.*'))  \n\nclasses = sorted([o for o in os.listdir('../working/data/train_seg')])  \nprint(classes)\n\n\n#---------Attention embedded MobileNetV2--------------------------------------------------------------\n\n\nIMG_SHAPE=(224, 224, 3)\n\n#base_model = keras.applications.MobileNetV2(input_shape=IMG_SHAPE,include_top=False, weights='imagenet')\n#weights='../working/cjd/01_rice_dete/obj_reco/checkpoint/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5')\n\n\n\n#for layer in base_model.layers:\n#    layer.trainable = False\n    \n\n#base_out = base_model.output\n\n#--------------------Soft attention module-------------------------------------------------------------- \n#ipts = base_out\n#residual = layers.Conv2D(1280, kernel_size = (1, 1), strides = (1, 1), padding = 'same')(ipts)\n#residual = layers.BatchNormalization(axis = -1)(residual)\n#cbam = cbam_block(residual)\n#base_out = layers.add([base_out, residual, cbam])\n#------------------------------------------------------------------------------------------------------------ \n\n#x = GlobalAveragePooling2D()(base_out)\n# \n\n# softmax\n#predictions = Dense(len(ont_hot_labels[0]), activation='softmax', kernel_regularizer =regularizers.l2(0.01) )(x)  #l1_reg\n#predictions = Dense(len(classes), activation='softmax', kernel_regularizer =regularizers.l2(0.01) )(x)  #l1_reg\n\n#model = Model(inputs=base_model.input, outputs=predictions)\n\n#model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics = ['accuracy'])  #rmsprop\n#model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adadelta(), metrics=['accuracy'])\n\n\n\n#train_datagen = ImageDataGenerator(validation_split=0.2)\ntrain_datagen = ImageDataGenerator()\ntrain_datagen.mean = np.array([103.939, 116.779, 123.68], dtype=np.float32).reshape((3, 1, 1))  # remove imagenet BGR mean value\ntrain_data = train_datagen.flow_from_directory(train_dir, target_size=img_size, classes=classes)\nvalidation_datagen = ImageDataGenerator()\nvalidation_datagen.mean = np.array([103.939, 116.779, 123.68], dtype=np.float32).reshape((3, 1, 1))\ntest_dir = '../working/data/test_seg/'  \nvalidation_data = validation_datagen.flow_from_directory(test_dir, target_size=img_size, classes=classes)\n\n\n#model_checkpoint1 = ModelCheckpoint(filepath=MODEL_INIT, save_best_only=True, monitor='val_accuracy', mode='max')\n#model_checkpoint1 = ModelCheckpoint(filepath=MODEL_INIT, monitor='val_accuracy', save_best_only=True, monitor='val_accuracy', mode='max')\n#model_checkpoint1 = ModelCheckpoint(filepath=MODEL_INIT, monitor='val_accuracy', save_best_only=True, mode='max')\nboard1 = TensorBoard(log_dir=board_name1,\n                     histogram_freq=0,\n                     write_graph=True,\n                     write_images=True)\n#callback_list1 = [model_checkpoint1, board1] \n\n\n#MODEL_INIT = '../working/log/init_model.h5'\n#MODEL_PATH = '../working/log/tst_model.h5'\n#callbacks1 = [ModelCheckpoint('init_model.hdf5', save_best_only=True), TensorBoard(log_dir=board_name1, histogram_freq=0,write_graph=True, write_images=True)]\ncallbacks1 = [ModelCheckpoint('init_model.h5', verbose=1, save_best_only=True, mode='min'), TensorBoard(log_dir=board_name1, histogram_freq=0,write_graph=True, write_images=True)]\nmodel.fit_generator(train_data, steps_per_epoch=nb_train_samples / float(batch_size),\n                           epochs = epochs,\n                           validation_steps=nb_validation_samples / float(batch_size),\n                           validation_data=validation_data,\n                           callbacks=callbacks1, verbose=1)\n'''\n\n                           \nmodel.fit(x=train_data, steps_per_epoch=nb_train_samples / float(batch_size),\n                           epochs = epochs,\n                           validation_steps=nb_validation_samples / float(batch_size),\n                           validation_data=validation_data,\n                           callbacks=[ModelCheckpoint(filepath=MODEL_INIT, monitor='val_accuracy', save_best_only=True, mode='max')], verbose=2)\n\n'''\n","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:37:30.849298Z","iopub.execute_input":"2022-05-11T21:37:30.849558Z","iopub.status.idle":"2022-05-11T21:52:50.833152Z","shell.execute_reply.started":"2022-05-11T21:37:30.849527Z","shell.execute_reply":"2022-05-11T21:52:50.832420Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"/kaggle/working\n3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \n[GCC 9.4.0]\n['idc-minus', 'idc-plus']\nFound 140 images belonging to 2 classes.\nFound 42 images belonging to 2 classes.\nEpoch 1/30\n3/2 [=========================================] - 29s 10s/step - loss: 3.5101 - acc: 0.9667 - val_loss: 24.1977 - val_acc: 0.8750\n\nEpoch 00001: val_loss improved from inf to 24.19772, saving model to init_model.h5\nEpoch 2/30\n3/2 [=========================================] - 33s 11s/step - loss: 1.9900 - acc: 0.9479 - val_loss: 9.7871 - val_acc: 0.9000\n\nEpoch 00002: val_loss improved from 24.19772 to 9.78714, saving model to init_model.h5\nEpoch 3/30\n3/2 [=========================================] - 29s 10s/step - loss: 1.9087 - acc: 0.9426 - val_loss: 16.8605 - val_acc: 0.9688\n\nEpoch 00003: val_loss did not improve from 9.78714\nEpoch 4/30\n3/2 [=========================================] - 33s 11s/step - loss: 3.5107 - acc: 0.9583 - val_loss: 13.8902 - val_acc: 0.8000\n\nEpoch 00004: val_loss did not improve from 9.78714\nEpoch 5/30\n3/2 [=========================================] - 29s 10s/step - loss: 1.4399 - acc: 0.9778 - val_loss: 9.4688 - val_acc: 0.9062\n\nEpoch 00005: val_loss improved from 9.78714 to 9.46878, saving model to init_model.h5\nEpoch 6/30\n3/2 [=========================================] - 26s 9s/step - loss: 7.2744 - acc: 0.9556 - val_loss: 6.1527 - val_acc: 0.9000\n\nEpoch 00006: val_loss improved from 9.46878 to 6.15272, saving model to init_model.h5\nEpoch 7/30\n3/2 [=========================================] - 37s 12s/step - loss: 1.7108 - acc: 0.9583 - val_loss: 55.1734 - val_acc: 0.8125\n\nEpoch 00007: val_loss did not improve from 6.15272\nEpoch 8/30\n3/2 [=========================================] - 26s 9s/step - loss: 0.0310 - acc: 0.9778 - val_loss: 0.0311 - val_acc: 1.0000\n\nEpoch 00008: val_loss improved from 6.15272 to 0.03112, saving model to init_model.h5\nEpoch 9/30\n3/2 [=========================================] - 30s 10s/step - loss: 0.5968 - acc: 0.9778 - val_loss: 40.5194 - val_acc: 0.8438\n\nEpoch 00009: val_loss did not improve from 0.03112\nEpoch 10/30\n3/2 [=========================================] - 33s 11s/step - loss: 0.0329 - acc: 0.9792 - val_loss: 8.2757 - val_acc: 0.9000\n\nEpoch 00010: val_loss did not improve from 0.03112\nEpoch 11/30\n3/2 [=========================================] - 29s 10s/step - loss: 0.0343 - acc: 0.9648 - val_loss: 26.5769 - val_acc: 0.8750\n\nEpoch 00011: val_loss did not improve from 0.03112\nEpoch 12/30\n3/2 [=========================================] - 35s 12s/step - loss: 0.1263 - acc: 0.9896 - val_loss: 22.1350 - val_acc: 0.8000\n\nEpoch 00012: val_loss did not improve from 0.03112\nEpoch 13/30\n3/2 [=========================================] - 29s 10s/step - loss: 0.5360 - acc: 0.9759 - val_loss: 39.8616 - val_acc: 0.8438\n\nEpoch 00013: val_loss did not improve from 0.03112\nEpoch 14/30\n3/2 [=========================================] - 27s 9s/step - loss: 0.9505 - acc: 0.9556 - val_loss: 4.0419 - val_acc: 0.9000\n\nEpoch 00014: val_loss did not improve from 0.03112\nEpoch 15/30\n3/2 [=========================================] - 36s 12s/step - loss: 3.6597 - acc: 0.9792 - val_loss: 41.9381 - val_acc: 0.7812\n\nEpoch 00015: val_loss did not improve from 0.03112\nEpoch 16/30\n3/2 [=========================================] - 34s 11s/step - loss: 0.0310 - acc: 0.9896 - val_loss: 0.3698 - val_acc: 0.9000\n\nEpoch 00016: val_loss did not improve from 0.03112\nEpoch 17/30\n3/2 [=========================================] - 30s 10s/step - loss: 0.3470 - acc: 0.9778 - val_loss: inf - val_acc: 0.8438\n\nEpoch 00017: val_loss did not improve from 0.03112\nEpoch 18/30\n3/2 [=========================================] - 26s 9s/step - loss: 0.2225 - acc: 0.9648 - val_loss: 17.7816 - val_acc: 0.7000\n\nEpoch 00018: val_loss did not improve from 0.03112\nEpoch 19/30\n3/2 [=========================================] - 36s 12s/step - loss: 2.8954 - acc: 0.9583 - val_loss: 15.0653 - val_acc: 0.8750\n\nEpoch 00019: val_loss did not improve from 0.03112\nEpoch 20/30\n3/2 [=========================================] - 27s 9s/step - loss: 0.4953 - acc: 0.9759 - val_loss: 8.3143 - val_acc: 0.9000\n\nEpoch 00020: val_loss did not improve from 0.03112\nEpoch 21/30\n3/2 [=========================================] - 36s 12s/step - loss: 0.0439 - acc: 0.9896 - val_loss: 18.5962 - val_acc: 0.9062\n\nEpoch 00021: val_loss did not improve from 0.03112\nEpoch 22/30\n3/2 [=========================================] - 27s 9s/step - loss: 1.6034 - acc: 0.9426 - val_loss: 1.6583 - val_acc: 0.9000\n\nEpoch 00022: val_loss did not improve from 0.03112\nEpoch 23/30\n3/2 [=========================================] - 30s 10s/step - loss: 0.0311 - acc: 0.9778 - val_loss: 20.0639 - val_acc: 0.8750\n\nEpoch 00023: val_loss did not improve from 0.03112\nEpoch 24/30\n3/2 [=========================================] - 27s 9s/step - loss: 0.0309 - acc: 0.9889 - val_loss: 8.2231 - val_acc: 0.9000\n\nEpoch 00024: val_loss did not improve from 0.03112\nEpoch 25/30\n3/2 [=========================================] - 36s 12s/step - loss: 0.6881 - acc: 0.9792 - val_loss: 29.3874 - val_acc: 0.8438\n\nEpoch 00025: val_loss did not improve from 0.03112\nEpoch 26/30\n3/2 [=========================================] - 27s 9s/step - loss: 3.1031 - acc: 0.9296 - val_loss: 0.0512 - val_acc: 1.0000\n\nEpoch 00026: val_loss did not improve from 0.03112\nEpoch 27/30\n3/2 [=========================================] - 29s 10s/step - loss: 0.2640 - acc: 0.9667 - val_loss: 13.9814 - val_acc: 0.8438\n\nEpoch 00027: val_loss did not improve from 0.03112\nEpoch 28/30\n3/2 [=========================================] - 31s 10s/step - loss: 1.9845 - acc: 0.9792 - val_loss: 13.1331 - val_acc: 0.8000\n\nEpoch 00028: val_loss did not improve from 0.03112\nEpoch 29/30\n3/2 [=========================================] - 34s 11s/step - loss: 0.3145 - acc: 0.9688 - val_loss: 23.3471 - val_acc: 0.8125\n\nEpoch 00029: val_loss did not improve from 0.03112\nEpoch 30/30\n3/2 [=========================================] - 24s 8s/step - loss: 0.0309 - acc: 0.9889 - val_loss: 8.0981 - val_acc: 0.9000\n\nEpoch 00030: val_loss did not improve from 0.03112\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"\"\\n\\n                           \\nmodel.fit(x=train_data, steps_per_epoch=nb_train_samples / float(batch_size),\\n                           epochs = epochs,\\n                           validation_steps=nb_validation_samples / float(batch_size),\\n                           validation_data=validation_data,\\n                           callbacks=[ModelCheckpoint(filepath=MODEL_INIT, monitor='val_accuracy', save_best_only=True, mode='max')], verbose=2)\\n\\n\""},"metadata":{}}]},{"cell_type":"code","source":"model.load_weights('./init_model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:52:59.483094Z","iopub.execute_input":"2022-05-11T21:52:59.483344Z","iopub.status.idle":"2022-05-11T21:52:59.627663Z","shell.execute_reply.started":"2022-05-11T21:52:59.483315Z","shell.execute_reply":"2022-05-11T21:52:59.626930Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"#---------------2-nd stage---------------------------------------------\n#model_checkpoint2 = ModelCheckpoint(filepath=MODEL_PATH,  monitor='val_accuracy')\n#model_checkpoint2 = ModelCheckpoint('tst_model.h5',  monitor='val_accuracy', save_best_only=True, mode='max')\n#board2 = TensorBoard(log_dir=board_name2, histogram_freq=0, write_graph=True, write_images=True)\n#callback_list2 = [model_checkpoint2, board2]\n#callbacks2 = [EarlyStopping(monitor='val_loss', patience=5, verbose=2), ModelCheckpoint('test_model.hdf5', save_best_only=True), TensorBoard(log_dir=board_name2,\n#                     histogram_freq=0,\n#                     write_graph=True,\n#                     write_images=True)]\ncallbacks2 = [ModelCheckpoint('test_model.h5', verbose=1, save_best_only=True, mode='min'), TensorBoard(log_dir=board_name2,\n                     histogram_freq=0,\n                     write_graph=True,\n                     write_images=True)]\n\n#model.load_weights(MODEL_INIT)\nfor model1 in model.layers:\n    model1.trainable = True\n#fine_tune_at = 50\n#for layer in model.layers[:fine_tune_at]:\n#    layer.trainable = False\n\n\n#model.compile(optimizer=optimizers.Adam(), loss =[focal_loss(gamma=2)], metrics=['accuracy']) #loss='categorical_crossentropy',\nmodel.compile(optimizer=optimizers.SGD(lr=0.0001), loss = [focal_loss(gamma=2)], metrics=['accuracy']) #loss='categorical_crossentropy',\n#model.compile(optimizer=optimizers.Adadelta(), loss = [focal_loss(gamma=2)], metrics=['accuracy']) #loss='categorical_crossentropy',\n\nmodel.fit_generator(train_data, steps_per_epoch=nb_train_samples / float(batch_size), epochs=epochs, validation_data=validation_data, validation_steps=nb_validation_samples / float(batch_size), callbacks=callbacks2, verbose=2)\n\n\n\nfrom contextlib import redirect_stdout   \nwith open('./model_summary.txt', 'w') as f:\n    with redirect_stdout(f):\n        model.summary(line_length=200,positions=[0.30,0.60,0.7,1.0])\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:53:10.091637Z","iopub.execute_input":"2022-05-11T21:53:10.092344Z","iopub.status.idle":"2022-05-11T22:07:39.419750Z","shell.execute_reply.started":"2022-05-11T21:53:10.092300Z","shell.execute_reply":"2022-05-11T22:07:39.418991Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Epoch 1/30\n - 31s - loss: 0.0316 - acc: 0.9778 - val_loss: 20.4016 - val_acc: 0.8750\n\nEpoch 00001: val_loss improved from inf to 20.40158, saving model to test_model.h5\nEpoch 2/30\n - 32s - loss: 0.5370 - acc: 0.9688 - val_loss: 0.0315 - val_acc: 1.0000\n\nEpoch 00002: val_loss improved from 20.40158 to 0.03146, saving model to test_model.h5\nEpoch 3/30\n - 34s - loss: 0.1403 - acc: 0.9792 - val_loss: 17.7625 - val_acc: 0.8125\n\nEpoch 00003: val_loss did not improve from 0.03146\nEpoch 4/30\n - 26s - loss: 0.0326 - acc: 0.9889 - val_loss: 0.1447 - val_acc: 1.0000\n\nEpoch 00004: val_loss did not improve from 0.03146\nEpoch 5/30\n - 27s - loss: 0.0315 - acc: 1.0000 - val_loss: 11.7555 - val_acc: 0.9062\n\nEpoch 00005: val_loss did not improve from 0.03146\nEpoch 6/30\n - 25s - loss: 0.0363 - acc: 0.9537 - val_loss: 7.2089 - val_acc: 0.7000\n\nEpoch 00006: val_loss did not improve from 0.03146\nEpoch 7/30\n - 34s - loss: 0.2733 - acc: 0.9792 - val_loss: 17.2429 - val_acc: 0.8750\n\nEpoch 00007: val_loss did not improve from 0.03146\nEpoch 8/30\n - 24s - loss: 0.0310 - acc: 0.9667 - val_loss: 0.3564 - val_acc: 1.0000\n\nEpoch 00008: val_loss did not improve from 0.03146\nEpoch 9/30\n - 27s - loss: 0.0323 - acc: 0.9889 - val_loss: 11.7224 - val_acc: 0.9062\n\nEpoch 00009: val_loss did not improve from 0.03146\nEpoch 10/30\n - 31s - loss: 0.0409 - acc: 0.9688 - val_loss: 6.0747 - val_acc: 0.9000\n\nEpoch 00010: val_loss did not improve from 0.03146\nEpoch 11/30\n - 34s - loss: 0.0310 - acc: 0.9792 - val_loss: 11.7909 - val_acc: 0.9375\n\nEpoch 00011: val_loss did not improve from 0.03146\nEpoch 12/30\n - 24s - loss: 0.0311 - acc: 1.0000 - val_loss: 5.9316 - val_acc: 0.8000\n\nEpoch 00012: val_loss did not improve from 0.03146\nEpoch 13/30\n - 27s - loss: 0.0312 - acc: 0.9778 - val_loss: 5.0414 - val_acc: 0.9688\n\nEpoch 00013: val_loss did not improve from 0.03146\nEpoch 14/30\n - 32s - loss: 0.0336 - acc: 0.9792 - val_loss: 12.5976 - val_acc: 0.7000\n\nEpoch 00014: val_loss did not improve from 0.03146\nEpoch 15/30\n - 26s - loss: 0.1398 - acc: 0.9778 - val_loss: 7.9982 - val_acc: 0.9062\n\nEpoch 00015: val_loss did not improve from 0.03146\nEpoch 16/30\n - 31s - loss: 1.2434 - acc: 0.9583 - val_loss: 9.8260 - val_acc: 0.7000\n\nEpoch 00016: val_loss did not improve from 0.03146\nEpoch 17/30\n - 27s - loss: 2.5774 - acc: 0.9556 - val_loss: 11.9730 - val_acc: 0.7812\n\nEpoch 00017: val_loss did not improve from 0.03146\nEpoch 18/30\n - 25s - loss: 0.8721 - acc: 0.9759 - val_loss: 5.6575 - val_acc: 0.9000\n\nEpoch 00018: val_loss did not improve from 0.03146\nEpoch 19/30\n - 26s - loss: 5.1157 - acc: 0.8813 - val_loss: 15.9521 - val_acc: 0.8125\n\nEpoch 00019: val_loss did not improve from 0.03146\nEpoch 20/30\n - 32s - loss: 9.4060 - acc: 0.9271 - val_loss: 10.3421 - val_acc: 0.7000\n\nEpoch 00020: val_loss did not improve from 0.03146\nEpoch 21/30\n - 33s - loss: 2.1279 - acc: 0.9792 - val_loss: 24.5232 - val_acc: 0.7500\n\nEpoch 00021: val_loss did not improve from 0.03146\nEpoch 22/30\n - 25s - loss: 1.7919 - acc: 0.9537 - val_loss: 10.9229 - val_acc: 0.7000\n\nEpoch 00022: val_loss did not improve from 0.03146\nEpoch 23/30\n - 27s - loss: 0.2719 - acc: 0.9407 - val_loss: 39.8790 - val_acc: 0.7500\n\nEpoch 00023: val_loss did not improve from 0.03146\nEpoch 24/30\n - 25s - loss: 0.0309 - acc: 1.0000 - val_loss: 5.0566 - val_acc: 0.9000\n\nEpoch 00024: val_loss did not improve from 0.03146\nEpoch 25/30\n - 34s - loss: 2.1306 - acc: 0.9479 - val_loss: 23.8310 - val_acc: 0.8438\n\nEpoch 00025: val_loss did not improve from 0.03146\nEpoch 26/30\n - 24s - loss: 0.0310 - acc: 0.9889 - val_loss: 0.6313 - val_acc: 0.9000\n\nEpoch 00026: val_loss did not improve from 0.03146\nEpoch 27/30\n - 34s - loss: 1.8214 - acc: 0.9583 - val_loss: 19.4614 - val_acc: 0.7812\n\nEpoch 00027: val_loss did not improve from 0.03146\nEpoch 28/30\n - 25s - loss: 0.0309 - acc: 0.9759 - val_loss: 4.7105 - val_acc: 0.8000\n\nEpoch 00028: val_loss did not improve from 0.03146\nEpoch 29/30\n - 34s - loss: 0.2727 - acc: 0.9583 - val_loss: 23.7458 - val_acc: 0.7500\n\nEpoch 00029: val_loss did not improve from 0.03146\nEpoch 30/30\n - 24s - loss: 0.0308 - acc: 1.0000 - val_loss: 2.1718 - val_acc: 0.7000\n\nEpoch 00030: val_loss did not improve from 0.03146\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, roc_auc_score, cohen_kappa_score, precision_score, recall_score, accuracy_score, confusion_matrix\ndef get_accuracy_metrics(model, X_train, y_train, X_val, y_val, X_test, y_test):\n    y_train=np.argmax(y_train, axis=1)\n    y_test=np.argmax(y_test, axis=1)\n    y_val=np.argmax(y_val, axis=1)\n    y_train_pred=np.argmax(model.predict(X_train),axis=1)\n    y_test_pred=np.argmax(model.predict(X_test),axis=1)\n    y_val_pred=np.argmax(model.predict(X_val),axis=1)\n    print(\"Train accuracy Score------------>\")\n    print (\"{0:.3f}\".format(accuracy_score(y_train, y_train_pred)*100), \"%\")\n    \n    print(\"Val accuracy Score--------->\")\n    \n    print(\"{0:.3f}\".format(accuracy_score(y_val, y_val_pred)*100), \"%\")\n    \n  \n    print(\"Test accuracy Score--------->\")\n    print(\"{0:.3f}\".format(accuracy_score(y_test, y_test_pred)*100), \"%\")\n    \n    print(\"F1 Score--------------->\")\n    print(\"{0:.3f}\".format(f1_score(y_test, y_test_pred, average = 'weighted')*100), \"%\")\n    \n    print(\"Cohen Kappa Score------------->\")\n    print(\"{0:.3f}\".format(cohen_kappa_score(y_test, y_test_pred)*100), \"%\")\n    \n    print(\"Recall-------------->\")\n    print(\"{0:.3f}\".format(recall_score(y_test, y_test_pred, average = 'weighted')*100), \"%\")\n    \n    print(\"Precision-------------->\")\n    print(\"{0:.3f}\".format(precision_score(y_test, y_test_pred, average = 'weighted')*100), \"%\")\n    \n    cf_matrix_test = confusion_matrix(y_test, y_test_pred)\n    cf_matrix_val = confusion_matrix(y_val, y_val_pred)\n    \n    plt.figure(figsize = (12, 6))\n    plt.subplot(121)\n    sns.heatmap(cf_matrix_val, annot=True, cmap='Blues')\n    plt.title(\"Val Confusion matrix\")\n    \n    plt.subplot(122)\n    sns.heatmap(cf_matrix_test, annot=True, cmap='Blues')\n    plt.title(\"Test Confusion matrix\")\n    \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-11T22:24:42.722627Z","iopub.execute_input":"2022-05-11T22:24:42.722898Z","iopub.status.idle":"2022-05-11T22:24:42.737749Z","shell.execute_reply.started":"2022-05-11T22:24:42.722867Z","shell.execute_reply":"2022-05-11T22:24:42.736905Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"#MODEL_PATH = './test_model.hdf5'\nfrom keras.models import load_model\n#best_model = load_model('./test_model.h5')\nbest_model = load_model(\"./test_model.h5\", custom_objects={'focal_loss_fixed': focal_loss()})","metadata":{"execution":{"iopub.status.busy":"2022-05-11T22:24:46.111556Z","iopub.execute_input":"2022-05-11T22:24:46.111821Z","iopub.status.idle":"2022-05-11T22:25:10.157525Z","shell.execute_reply.started":"2022-05-11T22:24:46.111774Z","shell.execute_reply":"2022-05-11T22:25:10.156801Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"get_accuracy_metrics(best_model,  X_train, y_train, X_val, y_val, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T22:25:27.347074Z","iopub.execute_input":"2022-05-11T22:25:27.347328Z","iopub.status.idle":"2022-05-11T22:25:50.775273Z","shell.execute_reply.started":"2022-05-11T22:25:27.347299Z","shell.execute_reply":"2022-05-11T22:25:50.773841Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Train accuracy Score------------>\n57.143 %\nVal accuracy Score--------->\n66.667 %\nTest accuracy Score--------->\n61.905 %\nF1 Score--------------->\n58.519 %\nCohen Kappa Score------------->\n23.810 %\nRecall-------------->\n61.905 %\nPrecision-------------->\n67.677 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 864x432 with 4 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"#MODEL_PATH = './test_model.hdf5'\nfrom keras.models import load_model\n#best_model = load_model('./test_model.h5')\ninit_model = load_model(\"./init_model.h5\", custom_objects={'focal_loss_fixed': focal_loss()})","metadata":{"execution":{"iopub.status.busy":"2022-05-11T22:25:57.588662Z","iopub.execute_input":"2022-05-11T22:25:57.589278Z","iopub.status.idle":"2022-05-11T22:26:23.831672Z","shell.execute_reply.started":"2022-05-11T22:25:57.589238Z","shell.execute_reply":"2022-05-11T22:26:23.830940Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"get_accuracy_metrics(init_model,  X_train, y_train, X_val, y_val, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T22:26:29.896737Z","iopub.execute_input":"2022-05-11T22:26:29.897353Z","iopub.status.idle":"2022-05-11T22:26:53.838459Z","shell.execute_reply.started":"2022-05-11T22:26:29.897304Z","shell.execute_reply":"2022-05-11T22:26:53.837679Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Train accuracy Score------------>\n67.857 %\nVal accuracy Score--------->\n77.778 %\nTest accuracy Score--------->\n64.286 %\nF1 Score--------------->\n63.772 %\nCohen Kappa Score------------->\n28.571 %\nRecall-------------->\n64.286 %\nPrecision-------------->\n65.144 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 864x432 with 4 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]}]}