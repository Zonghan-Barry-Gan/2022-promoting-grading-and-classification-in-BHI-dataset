{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tensorflow==1.14\n!pip install keras==2.2.5 \n!pip install 'h5py<3.0.0'","metadata":{"execution":{"iopub.status.busy":"2022-05-12T20:57:56.839169Z","iopub.execute_input":"2022-05-12T20:57:56.839494Z","iopub.status.idle":"2022-05-12T20:59:03.665734Z","shell.execute_reply.started":"2022-05-12T20:57:56.839395Z","shell.execute_reply":"2022-05-12T20:59:03.664914Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting tensorflow==1.14\n  Downloading tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.3/109.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (1.21.6)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (0.37.1)\nRequirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (1.43.0)\nRequirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (1.0.0)\nRequirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (0.2.0)\nCollecting astor>=0.6.0\n  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (1.1.2)\nCollecting tensorboard<1.15.0,>=1.14.0\n  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0mm\n\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (1.14.0)\nCollecting keras-applications>=1.0.6\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 KB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (1.16.0)\nCollecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.5/488.5 KB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (1.1.0)\nRequirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (3.19.4)\nRequirement already satisfied: gast>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.14) (0.4.0)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow==1.14) (3.1.0)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (59.8.0)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (2.0.3)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.3.6)\nRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (4.11.3)\nRequirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.14) (1.5.2)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.7.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (4.2.0)\nInstalling collected packages: tensorflow-estimator, astor, keras-applications, tensorboard, tensorflow\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.6.0\n    Uninstalling tensorflow-estimator-2.6.0:\n      Successfully uninstalled tensorflow-estimator-2.6.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.6.0\n    Uninstalling tensorboard-2.6.0:\n      Successfully uninstalled tensorboard-2.6.0\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.6.3\n    Uninstalling tensorflow-2.6.3:\n      Successfully uninstalled tensorflow-2.6.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\ntfx-bsl 1.7.0 requires pyarrow<6,>=1, but you have pyarrow 7.0.0 which is incompatible.\ntfx-bsl 1.7.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3,>=1.15.5, but you have tensorflow 1.14.0 which is incompatible.\ntensorflow-transform 1.7.0 requires pyarrow<6,>=1, but you have pyarrow 7.0.0 which is incompatible.\ntensorflow-transform 1.7.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5, but you have tensorflow 1.14.0 which is incompatible.\ntensorflow-serving-api 2.8.0 requires tensorflow<3,>=2.8.0, but you have tensorflow 1.14.0 which is incompatible.\ntensorflow-io 0.21.0 requires tensorflow<2.7.0,>=2.6.0, but you have tensorflow 1.14.0 which is incompatible.\ntensorflow-cloud 0.1.14 requires tensorboard>=2.3.0, but you have tensorboard 1.14.0 which is incompatible.\ntensorflow-cloud 0.1.14 requires tensorflow<3.0,>=1.15.0, but you have tensorflow 1.14.0 which is incompatible.\npytorch-lightning 1.6.1 requires tensorboard>=2.2.0, but you have tensorboard 1.14.0 which is incompatible.\nexplainable-ai-sdk 1.3.3 requires tensorflow>=1.15.0, but you have tensorflow 1.14.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed astor-0.8.1 keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting keras==2.2.5\n  Downloading Keras-2.2.5-py2.py3-none-any.whl (336 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.2/336.2 KB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras==2.2.5) (1.21.6)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from keras==2.2.5) (1.16.0)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras==2.2.5) (3.1.0)\nRequirement already satisfied: keras-preprocessing>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from keras==2.2.5) (1.1.2)\nRequirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from keras==2.2.5) (1.7.3)\nRequirement already satisfied: keras-applications>=1.0.8 in /opt/conda/lib/python3.7/site-packages (from keras==2.2.5) (1.0.8)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from keras==2.2.5) (6.0)\nRequirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py->keras==2.2.5) (1.5.2)\nInstalling collected packages: keras\n  Attempting uninstall: keras\n    Found existing installation: keras 2.6.0\n    Uninstalling keras-2.6.0:\n      Successfully uninstalled keras-2.6.0\nSuccessfully installed keras-2.2.5\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting h5py<3.0.0\n  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py<3.0.0) (1.16.0)\nRequirement already satisfied: numpy>=1.7 in /opt/conda/lib/python3.7/site-packages (from h5py<3.0.0) (1.21.6)\nInstalling collected packages: h5py\n  Attempting uninstall: h5py\n    Found existing installation: h5py 3.1.0\n    Uninstalling h5py-3.1.0:\n      Successfully uninstalled h5py-3.1.0\nSuccessfully installed h5py-2.10.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"shutil.rmtree('./data')\n","metadata":{"trusted":true},"execution_count":93,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/api/_v1/keras/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    496\u001b[0m                     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m                     \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    494\u001b[0m                 \u001b[0m_rmtree_safe_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                     \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: [Errno 22] Invalid argument: './'"],"ename":"OSError","evalue":"[Errno 22] Invalid argument: './'","output_type":"error"}]},{"cell_type":"code","source":"#import os\n#import glob\n\n#files = glob.glob('./working/')\n#for f in files:\n#    os.remove(f)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T22:47:59.374602Z","iopub.execute_input":"2022-05-12T22:47:59.374856Z","iopub.status.idle":"2022-05-12T22:47:59.379308Z","shell.execute_reply.started":"2022-05-12T22:47:59.374829Z","shell.execute_reply":"2022-05-12T22:47:59.378639Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"os.makedirs('../working/data/train_seg/idc-minus/')     \nos.makedirs('../working/data/train_seg/idc-plus/')  \nos.makedirs('../working/data/test_seg/idc-minus/')     \nos.makedirs('../working/data/test_seg/idc-plus/')  \nos.makedirs('../working/data/val_seg/idc-minus/')     \nos.makedirs('../working/data/val_seg/idc-plus/')  \n","metadata":{"execution":{"iopub.status.busy":"2022-05-12T22:48:50.539950Z","iopub.execute_input":"2022-05-12T22:48:50.540205Z","iopub.status.idle":"2022-05-12T22:48:50.546960Z","shell.execute_reply.started":"2022-05-12T22:48:50.540177Z","shell.execute_reply":"2022-05-12T22:48:50.545118Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"sampling_seed=0\nsize_4_training=200\nimg_x=224\nepoch_4_test=30\n#training_reshape=(-1, img_size, img_size, 3)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T22:50:08.777764Z","iopub.execute_input":"2022-05-12T22:50:08.778323Z","iopub.status.idle":"2022-05-12T22:50:08.783337Z","shell.execute_reply.started":"2022-05-12T22:50:08.778285Z","shell.execute_reply":"2022-05-12T22:50:08.782450Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"import keras\nfrom keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, multiply, Permute, Concatenate, Add, Activation, Lambda\nfrom tensorflow.keras.layers import Conv2D\nfrom keras import backend as K\nfrom keras.activations import sigmoid\n\nfrom keras import optimizers\nfrom keras.optimizers import Adam\nimport keras.backend.tensorflow_backend as KTF\n#import keras.backend as KTF\nimport glob\nfrom keras.layers import Input,Dense,Dropout,BatchNormalization,Conv2D,MaxPooling2D,AveragePooling2D,concatenate,Activation,ZeroPadding2D\n#import tensorflow as tf\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport keras\nfrom keras.models import load_model\nfrom keras.layers import Activation, Dense\nfrom matplotlib import pyplot as plt\nfrom skimage import io,data\nimport time\nfrom keras import layers\nfrom keras.callbacks import ModelCheckpoint, TensorBoard\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import regularizers\n\nfrom keras.preprocessing import image\nfrom sklearn import svm\nfrom sklearn.ensemble import RandomForestClassifier\nnow = time.strftime(\"%Y-%m-%d_%H-%M-%S\", time.localtime())\n\nimport os,sys\nos.getcwd()\n#os.chdir(\"/home/cjd/31_CNN_Attention\")\n#import os\n# \nos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,5\"\n\n\n\n\n#import tensorflow as tf        \ndef focal_loss(gamma=2.):            \n    def focal_loss_fixed(y_true, y_pred):\n        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n        return -K.sum( K.pow(1. - pt_1, gamma) * K.log(pt_1)) \n    return focal_loss_fixed\n\n\ndef Conv2d_BN(x, nb_filter,kernel_size, strides=(1,1), padding='same',name=None):  \n    if name is not None:  \n        bn_name = name + '_bn'  \n        conv_name = name + '_conv'  \n    else:  \n        bn_name = None  \n        conv_name = None  \n  \n    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,activation='relu',name=conv_name)(x)  \n    x = BatchNormalization(axis=3,name=bn_name)(x)  \n    return x  \n\ndef Conv_Block(inpt,nb_filter,kernel_size,strides=(1,1), with_conv_shortcut=False):  \n    x = Conv2d_BN(inpt,nb_filter=nb_filter[0],kernel_size=(1,1),strides=strides,padding='same')  \n    x = Conv2d_BN(x, nb_filter=nb_filter[1], kernel_size=(3,3), padding='same')  \n    x = Conv2d_BN(x, nb_filter=nb_filter[2], kernel_size=(1,1), padding='same')  \n    if with_conv_shortcut:  \n        shortcut = Conv2d_BN(inpt,nb_filter=nb_filter[2],strides=strides,kernel_size=kernel_size)  \n        x = add([x,shortcut])  \n        return x  \n    else:  \n        x = add([x,inpt])  \n        return x  \n\n\ndef channel_attention(input_feature, ratio=8):\n\t\n\tchannel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n\tchannel = input_feature._keras_shape[channel_axis]\n\t\n\tshared_layer_one = Dense(channel//ratio,\n\t\t\t\t\t\t\t kernel_initializer='he_normal',\n\t\t\t\t\t\t\t activation = 'relu',\n\t\t\t\t\t\t\t use_bias=True,\n\t\t\t\t\t\t\t bias_initializer='zeros')\n\n\tshared_layer_two = Dense(channel,\n\t\t\t\t\t\t\t kernel_initializer='he_normal',\n\t\t\t\t\t\t\t use_bias=True,\n\t\t\t\t\t\t\t bias_initializer='zeros')\n\t\n\tavg_pool = GlobalAveragePooling2D()(input_feature)    \n\tavg_pool = Reshape((1,1,channel))(avg_pool)\n\tassert avg_pool._keras_shape[1:] == (1,1,channel)\n\tavg_pool = shared_layer_one(avg_pool)\n\tassert avg_pool._keras_shape[1:] == (1,1,channel//ratio)\n\tavg_pool = shared_layer_two(avg_pool)\n\tassert avg_pool._keras_shape[1:] == (1,1,channel)\n\t\n\tmax_pool = GlobalMaxPooling2D()(input_feature)\n\tmax_pool = Reshape((1,1,channel))(max_pool)\n\tassert max_pool._keras_shape[1:] == (1,1,channel)\n\tmax_pool = shared_layer_one(max_pool)\n\tassert max_pool._keras_shape[1:] == (1,1,channel//ratio)\n\tmax_pool = shared_layer_two(max_pool)\n\tassert max_pool._keras_shape[1:] == (1,1,channel)\n\t\n\tcbam_feature = Add()([avg_pool,max_pool])\n\tcbam_feature = Activation('hard_sigmoid')(cbam_feature)\n\t\n\tif K.image_data_format() == \"channels_first\":\n\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n\t\n\treturn multiply([input_feature, cbam_feature])\n\n\ndef spatial_attention(input_feature):\n\tkernel_size = 7\n\tif K.image_data_format() == \"channels_first\":\n\t\tchannel = input_feature._keras_shape[1]\n\t\tcbam_feature = Permute((2,3,1))(input_feature)\n\telse:\n\t\tchannel = input_feature._keras_shape[-1]\n\t\tcbam_feature = input_feature\n\t\n\tavg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n\tassert avg_pool._keras_shape[-1] == 1\n\tmax_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n\tassert max_pool._keras_shape[-1] == 1\n\tconcat = Concatenate(axis=3)([avg_pool, max_pool])\n\tassert concat._keras_shape[-1] == 2\n\tcbam_feature = Conv2D(filters = 1,\n\t\t\t\t\tkernel_size=kernel_size,\n\t\t\t\t\tactivation = 'hard_sigmoid',\n\t\t\t\t\tstrides=1,\n\t\t\t\t\tpadding='same',\n\t\t\t\t\tkernel_initializer='he_normal',\n\t\t\t\t\tuse_bias=False)(concat)\n\tassert cbam_feature._keras_shape[-1] == 1\n\t\n\tif K.image_data_format() == \"channels_first\":\n\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n\t\t\n\treturn multiply([input_feature, cbam_feature])\n\n\ndef cbam_block(cbam_feature,ratio=8):\n\tcbam_feature = channel_attention(cbam_feature, ratio)\n\tcbam_feature = spatial_attention(cbam_feature, )\n\treturn cbam_feature\n\n\nIMG_SHAPE=(img_x, img_x, 3)\n\nbase_model = keras.applications.MobileNetV2(input_shape=IMG_SHAPE,include_top=False, weights='imagenet')\n\n#weights='../working/cjd/01_rice_dete/obj_reco/checkpoint/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_img_x_no_top.h5'\nbase_model_layers_count=0\nfor layer in base_model.layers:\n    layer.trainable = False\n    base_model_layers_count=base_model_layers_count+1\nprint(\"MobileNetV2_base_model summary:\")\nprint(\"Number of layers in base_model:\")\nprint(base_model_layers_count)\nbase_model.summary()\n    \nbase_out = base_model.output\n\n#--------------------Soft attention module-------------------------------------------------------------- \nipts = base_out\nresidual = layers.Conv2D(1280, kernel_size = (1, 1), strides = (1, 1), padding = 'same')(ipts)\nresidual = layers.BatchNormalization(axis = -1)(residual)\ncbam = cbam_block(residual)\nbase_out = layers.add([base_out, residual, cbam])\n#------------------------------------------------------------------------------------------------------------ \nx = GlobalAveragePooling2D()(base_out)\n'''\nx = Dropout(0.2)(x)\nx = Dense(4096,activation=\"relu\")(x)\nx = Dense(4096,activation=\"relu\")(x)\nx = Dropout(0.2)(x)\nx = Dense(2096,activation=\"relu\")(x)\n'''\n\n# softmax\n#predictions = Dense(len(ont_hot_labels[0]), activation='softmax', kernel_regularizer =regularizers.l2(0.01) )(x)  #l1_reg\nclasses=['idc-','idc+']\n#predictions = Dense(len(classes), activation='softmax', kernel_regularizer =regularizers.l2(0.01) )(x)  #l1_reg\npredictions = Dense(len(classes), activation='sigmoid', kernel_regularizer =regularizers.l2(0.01) )(x)  #l1_reg\n\nfrom keras.models import Model\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\nprint(\"Whole model summary:\")\nmodel.summary()\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy',  metrics = ['accuracy'])  #rmsprop\n#model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adadelta(), metrics=['accuracy'])\n#model.compile(optimizer=optimizers.SGD(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy']) #loss='categorical_crossentropy',\n#model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adadelta(), metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2022-05-12T22:50:08.922002Z","iopub.execute_input":"2022-05-12T22:50:08.922308Z","iopub.status.idle":"2022-05-12T22:50:30.444077Z","shell.execute_reply.started":"2022-05-12T22:50:08.922281Z","shell.execute_reply":"2022-05-12T22:50:30.443340Z"},"trusted":true},"execution_count":101,"outputs":[{"name":"stdout","text":"MobileNetV2_base_model summary:\nNumber of layers in base_model:\n155\nModel: \"mobilenetv2_1.00_224\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_4 (InputLayer)            (None, 224, 224, 3)  0                                            \n__________________________________________________________________________________________________\nConv1_pad (ZeroPadding2D)       (None, 225, 225, 3)  0           input_4[0][0]                    \n__________________________________________________________________________________________________\nConv1 (Conv2D)                  (None, 112, 112, 32) 864         Conv1_pad[0][0]                  \n__________________________________________________________________________________________________\nbn_Conv1 (BatchNormalization)   (None, 112, 112, 32) 128         Conv1[0][0]                      \n__________________________________________________________________________________________________\nConv1_relu (ReLU)               (None, 112, 112, 32) 0           bn_Conv1[0][0]                   \n__________________________________________________________________________________________________\nexpanded_conv_depthwise (Depthw (None, 112, 112, 32) 288         Conv1_relu[0][0]                 \n__________________________________________________________________________________________________\nexpanded_conv_depthwise_BN (Bat (None, 112, 112, 32) 128         expanded_conv_depthwise[0][0]    \n__________________________________________________________________________________________________\nexpanded_conv_depthwise_relu (R (None, 112, 112, 32) 0           expanded_conv_depthwise_BN[0][0] \n__________________________________________________________________________________________________\nexpanded_conv_project (Conv2D)  (None, 112, 112, 16) 512         expanded_conv_depthwise_relu[0][0\n__________________________________________________________________________________________________\nexpanded_conv_project_BN (Batch (None, 112, 112, 16) 64          expanded_conv_project[0][0]      \n__________________________________________________________________________________________________\nblock_1_expand (Conv2D)         (None, 112, 112, 96) 1536        expanded_conv_project_BN[0][0]   \n__________________________________________________________________________________________________\nblock_1_expand_BN (BatchNormali (None, 112, 112, 96) 384         block_1_expand[0][0]             \n__________________________________________________________________________________________________\nblock_1_expand_relu (ReLU)      (None, 112, 112, 96) 0           block_1_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_1_pad (ZeroPadding2D)     (None, 113, 113, 96) 0           block_1_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_1_depthwise (DepthwiseCon (None, 56, 56, 96)   864         block_1_pad[0][0]                \n__________________________________________________________________________________________________\nblock_1_depthwise_BN (BatchNorm (None, 56, 56, 96)   384         block_1_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_1_depthwise_relu (ReLU)   (None, 56, 56, 96)   0           block_1_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_1_project (Conv2D)        (None, 56, 56, 24)   2304        block_1_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_1_project_BN (BatchNormal (None, 56, 56, 24)   96          block_1_project[0][0]            \n__________________________________________________________________________________________________\nblock_2_expand (Conv2D)         (None, 56, 56, 144)  3456        block_1_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_2_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_2_expand[0][0]             \n__________________________________________________________________________________________________\nblock_2_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_2_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_2_depthwise (DepthwiseCon (None, 56, 56, 144)  1296        block_2_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_2_depthwise_BN (BatchNorm (None, 56, 56, 144)  576         block_2_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_2_depthwise_relu (ReLU)   (None, 56, 56, 144)  0           block_2_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_2_project (Conv2D)        (None, 56, 56, 24)   3456        block_2_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_2_project_BN (BatchNormal (None, 56, 56, 24)   96          block_2_project[0][0]            \n__________________________________________________________________________________________________\nblock_2_add (Add)               (None, 56, 56, 24)   0           block_1_project_BN[0][0]         \n                                                                 block_2_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_3_expand (Conv2D)         (None, 56, 56, 144)  3456        block_2_add[0][0]                \n__________________________________________________________________________________________________\nblock_3_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_3_expand[0][0]             \n__________________________________________________________________________________________________\nblock_3_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_3_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_3_pad (ZeroPadding2D)     (None, 57, 57, 144)  0           block_3_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_3_depthwise (DepthwiseCon (None, 28, 28, 144)  1296        block_3_pad[0][0]                \n__________________________________________________________________________________________________\nblock_3_depthwise_BN (BatchNorm (None, 28, 28, 144)  576         block_3_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_3_depthwise_relu (ReLU)   (None, 28, 28, 144)  0           block_3_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_3_project (Conv2D)        (None, 28, 28, 32)   4608        block_3_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_3_project_BN (BatchNormal (None, 28, 28, 32)   128         block_3_project[0][0]            \n__________________________________________________________________________________________________\nblock_4_expand (Conv2D)         (None, 28, 28, 192)  6144        block_3_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_4_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_4_expand[0][0]             \n__________________________________________________________________________________________________\nblock_4_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_4_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_4_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_4_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_4_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_4_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_4_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_4_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_4_project (Conv2D)        (None, 28, 28, 32)   6144        block_4_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_4_project_BN (BatchNormal (None, 28, 28, 32)   128         block_4_project[0][0]            \n__________________________________________________________________________________________________\nblock_4_add (Add)               (None, 28, 28, 32)   0           block_3_project_BN[0][0]         \n                                                                 block_4_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_5_expand (Conv2D)         (None, 28, 28, 192)  6144        block_4_add[0][0]                \n__________________________________________________________________________________________________\nblock_5_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_5_expand[0][0]             \n__________________________________________________________________________________________________\nblock_5_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_5_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_5_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_5_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_5_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_5_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_5_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_5_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_5_project (Conv2D)        (None, 28, 28, 32)   6144        block_5_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_5_project_BN (BatchNormal (None, 28, 28, 32)   128         block_5_project[0][0]            \n__________________________________________________________________________________________________\nblock_5_add (Add)               (None, 28, 28, 32)   0           block_4_add[0][0]                \n                                                                 block_5_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_6_expand (Conv2D)         (None, 28, 28, 192)  6144        block_5_add[0][0]                \n__________________________________________________________________________________________________\nblock_6_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_6_expand[0][0]             \n__________________________________________________________________________________________________\nblock_6_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_6_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_6_pad (ZeroPadding2D)     (None, 29, 29, 192)  0           block_6_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_6_depthwise (DepthwiseCon (None, 14, 14, 192)  1728        block_6_pad[0][0]                \n__________________________________________________________________________________________________\nblock_6_depthwise_BN (BatchNorm (None, 14, 14, 192)  768         block_6_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_6_depthwise_relu (ReLU)   (None, 14, 14, 192)  0           block_6_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_6_project (Conv2D)        (None, 14, 14, 64)   12288       block_6_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_6_project_BN (BatchNormal (None, 14, 14, 64)   256         block_6_project[0][0]            \n__________________________________________________________________________________________________\nblock_7_expand (Conv2D)         (None, 14, 14, 384)  24576       block_6_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_7_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_7_expand[0][0]             \n__________________________________________________________________________________________________\nblock_7_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_7_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_7_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_7_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_7_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_7_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_7_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_7_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_7_project (Conv2D)        (None, 14, 14, 64)   24576       block_7_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_7_project_BN (BatchNormal (None, 14, 14, 64)   256         block_7_project[0][0]            \n__________________________________________________________________________________________________\nblock_7_add (Add)               (None, 14, 14, 64)   0           block_6_project_BN[0][0]         \n                                                                 block_7_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_8_expand (Conv2D)         (None, 14, 14, 384)  24576       block_7_add[0][0]                \n__________________________________________________________________________________________________\nblock_8_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_8_expand[0][0]             \n__________________________________________________________________________________________________\nblock_8_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_8_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_8_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_8_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_8_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_8_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_8_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_8_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_8_project (Conv2D)        (None, 14, 14, 64)   24576       block_8_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_8_project_BN (BatchNormal (None, 14, 14, 64)   256         block_8_project[0][0]            \n__________________________________________________________________________________________________\nblock_8_add (Add)               (None, 14, 14, 64)   0           block_7_add[0][0]                \n                                                                 block_8_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_9_expand (Conv2D)         (None, 14, 14, 384)  24576       block_8_add[0][0]                \n__________________________________________________________________________________________________\nblock_9_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_9_expand[0][0]             \n__________________________________________________________________________________________________\nblock_9_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_9_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_9_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_9_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_9_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_9_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_9_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_9_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_9_project (Conv2D)        (None, 14, 14, 64)   24576       block_9_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_9_project_BN (BatchNormal (None, 14, 14, 64)   256         block_9_project[0][0]            \n__________________________________________________________________________________________________\nblock_9_add (Add)               (None, 14, 14, 64)   0           block_8_add[0][0]                \n                                                                 block_9_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_10_expand (Conv2D)        (None, 14, 14, 384)  24576       block_9_add[0][0]                \n__________________________________________________________________________________________________\nblock_10_expand_BN (BatchNormal (None, 14, 14, 384)  1536        block_10_expand[0][0]            \n__________________________________________________________________________________________________\nblock_10_expand_relu (ReLU)     (None, 14, 14, 384)  0           block_10_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_10_depthwise (DepthwiseCo (None, 14, 14, 384)  3456        block_10_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_10_depthwise_BN (BatchNor (None, 14, 14, 384)  1536        block_10_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           block_10_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_10_project (Conv2D)       (None, 14, 14, 96)   36864       block_10_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_10_project_BN (BatchNorma (None, 14, 14, 96)   384         block_10_project[0][0]           \n__________________________________________________________________________________________________\nblock_11_expand (Conv2D)        (None, 14, 14, 576)  55296       block_10_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_11_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_11_expand[0][0]            \n__________________________________________________________________________________________________\nblock_11_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_11_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_11_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_11_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_11_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_11_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_11_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_11_project (Conv2D)       (None, 14, 14, 96)   55296       block_11_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_11_project_BN (BatchNorma (None, 14, 14, 96)   384         block_11_project[0][0]           \n__________________________________________________________________________________________________\nblock_11_add (Add)              (None, 14, 14, 96)   0           block_10_project_BN[0][0]        \n                                                                 block_11_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_12_expand (Conv2D)        (None, 14, 14, 576)  55296       block_11_add[0][0]               \n__________________________________________________________________________________________________\nblock_12_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_12_expand[0][0]            \n__________________________________________________________________________________________________\nblock_12_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_12_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_12_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_12_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_12_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_12_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_12_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_12_project (Conv2D)       (None, 14, 14, 96)   55296       block_12_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_12_project_BN (BatchNorma (None, 14, 14, 96)   384         block_12_project[0][0]           \n__________________________________________________________________________________________________\nblock_12_add (Add)              (None, 14, 14, 96)   0           block_11_add[0][0]               \n                                                                 block_12_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_13_expand (Conv2D)        (None, 14, 14, 576)  55296       block_12_add[0][0]               \n__________________________________________________________________________________________________\nblock_13_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_13_expand[0][0]            \n__________________________________________________________________________________________________\nblock_13_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_13_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_13_pad (ZeroPadding2D)    (None, 15, 15, 576)  0           block_13_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_13_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_13_pad[0][0]               \n__________________________________________________________________________________________________\nblock_13_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_13_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_13_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_13_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_13_project (Conv2D)       (None, 7, 7, 160)    92160       block_13_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_13_project_BN (BatchNorma (None, 7, 7, 160)    640         block_13_project[0][0]           \n__________________________________________________________________________________________________\nblock_14_expand (Conv2D)        (None, 7, 7, 960)    153600      block_13_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_14_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_14_expand[0][0]            \n__________________________________________________________________________________________________\nblock_14_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_14_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_14_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_14_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_14_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_14_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_14_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_14_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_14_project (Conv2D)       (None, 7, 7, 160)    153600      block_14_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_14_project_BN (BatchNorma (None, 7, 7, 160)    640         block_14_project[0][0]           \n__________________________________________________________________________________________________\nblock_14_add (Add)              (None, 7, 7, 160)    0           block_13_project_BN[0][0]        \n                                                                 block_14_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_15_expand (Conv2D)        (None, 7, 7, 960)    153600      block_14_add[0][0]               \n__________________________________________________________________________________________________\nblock_15_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_15_expand[0][0]            \n__________________________________________________________________________________________________\nblock_15_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_15_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_15_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_15_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_15_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_15_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_15_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_15_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_15_project (Conv2D)       (None, 7, 7, 160)    153600      block_15_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_15_project_BN (BatchNorma (None, 7, 7, 160)    640         block_15_project[0][0]           \n__________________________________________________________________________________________________\nblock_15_add (Add)              (None, 7, 7, 160)    0           block_14_add[0][0]               \n                                                                 block_15_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_16_expand (Conv2D)        (None, 7, 7, 960)    153600      block_15_add[0][0]               \n__________________________________________________________________________________________________\nblock_16_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_16_expand[0][0]            \n__________________________________________________________________________________________________\nblock_16_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_16_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_16_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_16_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_16_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_16_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_16_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_16_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_16_project (Conv2D)       (None, 7, 7, 320)    307200      block_16_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_16_project_BN (BatchNorma (None, 7, 7, 320)    1280        block_16_project[0][0]           \n__________________________________________________________________________________________________\nConv_1 (Conv2D)                 (None, 7, 7, 1280)   409600      block_16_project_BN[0][0]        \n__________________________________________________________________________________________________\nConv_1_bn (BatchNormalization)  (None, 7, 7, 1280)   5120        Conv_1[0][0]                     \n__________________________________________________________________________________________________\nout_relu (ReLU)                 (None, 7, 7, 1280)   0           Conv_1_bn[0][0]                  \n==================================================================================================\nTotal params: 2,257,984\nTrainable params: 0\nNon-trainable params: 2,257,984\n__________________________________________________________________________________________________\nWhole model summary:\nModel: \"model_3\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_4 (InputLayer)            (None, 224, 224, 3)  0                                            \n__________________________________________________________________________________________________\nConv1_pad (ZeroPadding2D)       (None, 225, 225, 3)  0           input_4[0][0]                    \n__________________________________________________________________________________________________\nConv1 (Conv2D)                  (None, 112, 112, 32) 864         Conv1_pad[0][0]                  \n__________________________________________________________________________________________________\nbn_Conv1 (BatchNormalization)   (None, 112, 112, 32) 128         Conv1[0][0]                      \n__________________________________________________________________________________________________\nConv1_relu (ReLU)               (None, 112, 112, 32) 0           bn_Conv1[0][0]                   \n__________________________________________________________________________________________________\nexpanded_conv_depthwise (Depthw (None, 112, 112, 32) 288         Conv1_relu[0][0]                 \n__________________________________________________________________________________________________\nexpanded_conv_depthwise_BN (Bat (None, 112, 112, 32) 128         expanded_conv_depthwise[0][0]    \n__________________________________________________________________________________________________\nexpanded_conv_depthwise_relu (R (None, 112, 112, 32) 0           expanded_conv_depthwise_BN[0][0] \n__________________________________________________________________________________________________\nexpanded_conv_project (Conv2D)  (None, 112, 112, 16) 512         expanded_conv_depthwise_relu[0][0\n__________________________________________________________________________________________________\nexpanded_conv_project_BN (Batch (None, 112, 112, 16) 64          expanded_conv_project[0][0]      \n__________________________________________________________________________________________________\nblock_1_expand (Conv2D)         (None, 112, 112, 96) 1536        expanded_conv_project_BN[0][0]   \n__________________________________________________________________________________________________\nblock_1_expand_BN (BatchNormali (None, 112, 112, 96) 384         block_1_expand[0][0]             \n__________________________________________________________________________________________________\nblock_1_expand_relu (ReLU)      (None, 112, 112, 96) 0           block_1_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_1_pad (ZeroPadding2D)     (None, 113, 113, 96) 0           block_1_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_1_depthwise (DepthwiseCon (None, 56, 56, 96)   864         block_1_pad[0][0]                \n__________________________________________________________________________________________________\nblock_1_depthwise_BN (BatchNorm (None, 56, 56, 96)   384         block_1_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_1_depthwise_relu (ReLU)   (None, 56, 56, 96)   0           block_1_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_1_project (Conv2D)        (None, 56, 56, 24)   2304        block_1_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_1_project_BN (BatchNormal (None, 56, 56, 24)   96          block_1_project[0][0]            \n__________________________________________________________________________________________________\nblock_2_expand (Conv2D)         (None, 56, 56, 144)  3456        block_1_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_2_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_2_expand[0][0]             \n__________________________________________________________________________________________________\nblock_2_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_2_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_2_depthwise (DepthwiseCon (None, 56, 56, 144)  1296        block_2_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_2_depthwise_BN (BatchNorm (None, 56, 56, 144)  576         block_2_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_2_depthwise_relu (ReLU)   (None, 56, 56, 144)  0           block_2_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_2_project (Conv2D)        (None, 56, 56, 24)   3456        block_2_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_2_project_BN (BatchNormal (None, 56, 56, 24)   96          block_2_project[0][0]            \n__________________________________________________________________________________________________\nblock_2_add (Add)               (None, 56, 56, 24)   0           block_1_project_BN[0][0]         \n                                                                 block_2_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_3_expand (Conv2D)         (None, 56, 56, 144)  3456        block_2_add[0][0]                \n__________________________________________________________________________________________________\nblock_3_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_3_expand[0][0]             \n__________________________________________________________________________________________________\nblock_3_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_3_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_3_pad (ZeroPadding2D)     (None, 57, 57, 144)  0           block_3_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_3_depthwise (DepthwiseCon (None, 28, 28, 144)  1296        block_3_pad[0][0]                \n__________________________________________________________________________________________________\nblock_3_depthwise_BN (BatchNorm (None, 28, 28, 144)  576         block_3_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_3_depthwise_relu (ReLU)   (None, 28, 28, 144)  0           block_3_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_3_project (Conv2D)        (None, 28, 28, 32)   4608        block_3_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_3_project_BN (BatchNormal (None, 28, 28, 32)   128         block_3_project[0][0]            \n__________________________________________________________________________________________________\nblock_4_expand (Conv2D)         (None, 28, 28, 192)  6144        block_3_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_4_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_4_expand[0][0]             \n__________________________________________________________________________________________________\nblock_4_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_4_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_4_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_4_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_4_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_4_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_4_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_4_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_4_project (Conv2D)        (None, 28, 28, 32)   6144        block_4_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_4_project_BN (BatchNormal (None, 28, 28, 32)   128         block_4_project[0][0]            \n__________________________________________________________________________________________________\nblock_4_add (Add)               (None, 28, 28, 32)   0           block_3_project_BN[0][0]         \n                                                                 block_4_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_5_expand (Conv2D)         (None, 28, 28, 192)  6144        block_4_add[0][0]                \n__________________________________________________________________________________________________\nblock_5_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_5_expand[0][0]             \n__________________________________________________________________________________________________\nblock_5_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_5_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_5_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_5_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_5_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_5_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_5_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_5_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_5_project (Conv2D)        (None, 28, 28, 32)   6144        block_5_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_5_project_BN (BatchNormal (None, 28, 28, 32)   128         block_5_project[0][0]            \n__________________________________________________________________________________________________\nblock_5_add (Add)               (None, 28, 28, 32)   0           block_4_add[0][0]                \n                                                                 block_5_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_6_expand (Conv2D)         (None, 28, 28, 192)  6144        block_5_add[0][0]                \n__________________________________________________________________________________________________\nblock_6_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_6_expand[0][0]             \n__________________________________________________________________________________________________\nblock_6_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_6_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_6_pad (ZeroPadding2D)     (None, 29, 29, 192)  0           block_6_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_6_depthwise (DepthwiseCon (None, 14, 14, 192)  1728        block_6_pad[0][0]                \n__________________________________________________________________________________________________\nblock_6_depthwise_BN (BatchNorm (None, 14, 14, 192)  768         block_6_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_6_depthwise_relu (ReLU)   (None, 14, 14, 192)  0           block_6_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_6_project (Conv2D)        (None, 14, 14, 64)   12288       block_6_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_6_project_BN (BatchNormal (None, 14, 14, 64)   256         block_6_project[0][0]            \n__________________________________________________________________________________________________\nblock_7_expand (Conv2D)         (None, 14, 14, 384)  24576       block_6_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_7_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_7_expand[0][0]             \n__________________________________________________________________________________________________\nblock_7_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_7_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_7_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_7_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_7_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_7_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_7_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_7_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_7_project (Conv2D)        (None, 14, 14, 64)   24576       block_7_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_7_project_BN (BatchNormal (None, 14, 14, 64)   256         block_7_project[0][0]            \n__________________________________________________________________________________________________\nblock_7_add (Add)               (None, 14, 14, 64)   0           block_6_project_BN[0][0]         \n                                                                 block_7_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_8_expand (Conv2D)         (None, 14, 14, 384)  24576       block_7_add[0][0]                \n__________________________________________________________________________________________________\nblock_8_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_8_expand[0][0]             \n__________________________________________________________________________________________________\nblock_8_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_8_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_8_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_8_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_8_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_8_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_8_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_8_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_8_project (Conv2D)        (None, 14, 14, 64)   24576       block_8_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_8_project_BN (BatchNormal (None, 14, 14, 64)   256         block_8_project[0][0]            \n__________________________________________________________________________________________________\nblock_8_add (Add)               (None, 14, 14, 64)   0           block_7_add[0][0]                \n                                                                 block_8_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_9_expand (Conv2D)         (None, 14, 14, 384)  24576       block_8_add[0][0]                \n__________________________________________________________________________________________________\nblock_9_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_9_expand[0][0]             \n__________________________________________________________________________________________________\nblock_9_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_9_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_9_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_9_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_9_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_9_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_9_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_9_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_9_project (Conv2D)        (None, 14, 14, 64)   24576       block_9_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_9_project_BN (BatchNormal (None, 14, 14, 64)   256         block_9_project[0][0]            \n__________________________________________________________________________________________________\nblock_9_add (Add)               (None, 14, 14, 64)   0           block_8_add[0][0]                \n                                                                 block_9_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_10_expand (Conv2D)        (None, 14, 14, 384)  24576       block_9_add[0][0]                \n__________________________________________________________________________________________________\nblock_10_expand_BN (BatchNormal (None, 14, 14, 384)  1536        block_10_expand[0][0]            \n__________________________________________________________________________________________________\nblock_10_expand_relu (ReLU)     (None, 14, 14, 384)  0           block_10_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_10_depthwise (DepthwiseCo (None, 14, 14, 384)  3456        block_10_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_10_depthwise_BN (BatchNor (None, 14, 14, 384)  1536        block_10_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           block_10_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_10_project (Conv2D)       (None, 14, 14, 96)   36864       block_10_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_10_project_BN (BatchNorma (None, 14, 14, 96)   384         block_10_project[0][0]           \n__________________________________________________________________________________________________\nblock_11_expand (Conv2D)        (None, 14, 14, 576)  55296       block_10_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_11_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_11_expand[0][0]            \n__________________________________________________________________________________________________\nblock_11_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_11_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_11_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_11_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_11_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_11_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_11_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_11_project (Conv2D)       (None, 14, 14, 96)   55296       block_11_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_11_project_BN (BatchNorma (None, 14, 14, 96)   384         block_11_project[0][0]           \n__________________________________________________________________________________________________\nblock_11_add (Add)              (None, 14, 14, 96)   0           block_10_project_BN[0][0]        \n                                                                 block_11_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_12_expand (Conv2D)        (None, 14, 14, 576)  55296       block_11_add[0][0]               \n__________________________________________________________________________________________________\nblock_12_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_12_expand[0][0]            \n__________________________________________________________________________________________________\nblock_12_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_12_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_12_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_12_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_12_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_12_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_12_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_12_project (Conv2D)       (None, 14, 14, 96)   55296       block_12_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_12_project_BN (BatchNorma (None, 14, 14, 96)   384         block_12_project[0][0]           \n__________________________________________________________________________________________________\nblock_12_add (Add)              (None, 14, 14, 96)   0           block_11_add[0][0]               \n                                                                 block_12_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_13_expand (Conv2D)        (None, 14, 14, 576)  55296       block_12_add[0][0]               \n__________________________________________________________________________________________________\nblock_13_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_13_expand[0][0]            \n__________________________________________________________________________________________________\nblock_13_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_13_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_13_pad (ZeroPadding2D)    (None, 15, 15, 576)  0           block_13_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_13_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_13_pad[0][0]               \n__________________________________________________________________________________________________\nblock_13_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_13_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_13_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_13_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_13_project (Conv2D)       (None, 7, 7, 160)    92160       block_13_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_13_project_BN (BatchNorma (None, 7, 7, 160)    640         block_13_project[0][0]           \n__________________________________________________________________________________________________\nblock_14_expand (Conv2D)        (None, 7, 7, 960)    153600      block_13_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_14_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_14_expand[0][0]            \n__________________________________________________________________________________________________\nblock_14_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_14_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_14_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_14_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_14_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_14_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_14_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_14_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_14_project (Conv2D)       (None, 7, 7, 160)    153600      block_14_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_14_project_BN (BatchNorma (None, 7, 7, 160)    640         block_14_project[0][0]           \n__________________________________________________________________________________________________\nblock_14_add (Add)              (None, 7, 7, 160)    0           block_13_project_BN[0][0]        \n                                                                 block_14_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_15_expand (Conv2D)        (None, 7, 7, 960)    153600      block_14_add[0][0]               \n__________________________________________________________________________________________________\nblock_15_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_15_expand[0][0]            \n__________________________________________________________________________________________________\nblock_15_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_15_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_15_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_15_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_15_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_15_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_15_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_15_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_15_project (Conv2D)       (None, 7, 7, 160)    153600      block_15_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_15_project_BN (BatchNorma (None, 7, 7, 160)    640         block_15_project[0][0]           \n__________________________________________________________________________________________________\nblock_15_add (Add)              (None, 7, 7, 160)    0           block_14_add[0][0]               \n                                                                 block_15_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_16_expand (Conv2D)        (None, 7, 7, 960)    153600      block_15_add[0][0]               \n__________________________________________________________________________________________________\nblock_16_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_16_expand[0][0]            \n__________________________________________________________________________________________________\nblock_16_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_16_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_16_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_16_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_16_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_16_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_16_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_16_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_16_project (Conv2D)       (None, 7, 7, 320)    307200      block_16_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_16_project_BN (BatchNorma (None, 7, 7, 320)    1280        block_16_project[0][0]           \n__________________________________________________________________________________________________\nConv_1 (Conv2D)                 (None, 7, 7, 1280)   409600      block_16_project_BN[0][0]        \n__________________________________________________________________________________________________\nConv_1_bn (BatchNormalization)  (None, 7, 7, 1280)   5120        Conv_1[0][0]                     \n__________________________________________________________________________________________________\nout_relu (ReLU)                 (None, 7, 7, 1280)   0           Conv_1_bn[0][0]                  \n__________________________________________________________________________________________________\nconv2d_5 (Conv2D)               (None, 7, 7, 1280)   1639680     out_relu[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 7, 7, 1280)   5120        conv2d_5[0][0]                   \n__________________________________________________________________________________________________\nglobal_average_pooling2d_5 (Glo (None, 1280)         0           batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\nglobal_max_pooling2d_3 (GlobalM (None, 1280)         0           batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\nreshape_5 (Reshape)             (None, 1, 1, 1280)   0           global_average_pooling2d_5[0][0] \n__________________________________________________________________________________________________\nreshape_6 (Reshape)             (None, 1, 1, 1280)   0           global_max_pooling2d_3[0][0]     \n__________________________________________________________________________________________________\ndense_7 (Dense)                 (None, 1, 1, 160)    204960      reshape_5[0][0]                  \n                                                                 reshape_6[0][0]                  \n__________________________________________________________________________________________________\ndense_8 (Dense)                 (None, 1, 1, 1280)   206080      dense_7[0][0]                    \n                                                                 dense_7[1][0]                    \n__________________________________________________________________________________________________\nadd_5 (Add)                     (None, 1, 1, 1280)   0           dense_8[0][0]                    \n                                                                 dense_8[1][0]                    \n__________________________________________________________________________________________________\nactivation_3 (Activation)       (None, 1, 1, 1280)   0           add_5[0][0]                      \n__________________________________________________________________________________________________\nmultiply_5 (Multiply)           (None, 7, 7, 1280)   0           batch_normalization_3[0][0]      \n                                                                 activation_3[0][0]               \n__________________________________________________________________________________________________\nlambda_5 (Lambda)               (None, 7, 7, 1)      0           multiply_5[0][0]                 \n__________________________________________________________________________________________________\nlambda_6 (Lambda)               (None, 7, 7, 1)      0           multiply_5[0][0]                 \n__________________________________________________________________________________________________\nconcatenate_3 (Concatenate)     (None, 7, 7, 2)      0           lambda_5[0][0]                   \n                                                                 lambda_6[0][0]                   \n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 7, 7, 1)      98          concatenate_3[0][0]              \n__________________________________________________________________________________________________\nmultiply_6 (Multiply)           (None, 7, 7, 1280)   0           multiply_5[0][0]                 \n                                                                 conv2d_6[0][0]                   \n__________________________________________________________________________________________________\nadd_6 (Add)                     (None, 7, 7, 1280)   0           out_relu[0][0]                   \n                                                                 batch_normalization_3[0][0]      \n                                                                 multiply_6[0][0]                 \n__________________________________________________________________________________________________\nglobal_average_pooling2d_6 (Glo (None, 1280)         0           add_6[0][0]                      \n__________________________________________________________________________________________________\ndense_9 (Dense)                 (None, 2)            2562        global_average_pooling2d_6[0][0] \n==================================================================================================\nTotal params: 4,316,484\nTrainable params: 2,055,940\nNon-trainable params: 2,260,544\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport keras\nprint(keras.__version__)\nimport tensorflow\nprint(keras.__version__)\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n!pip install Livelossplot\nfrom livelossplot import PlotLossesKeras\n\nfrom glob import glob\nimport os\nimport shutil\n\nimport numpy as np\nimport pandas as pd\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2022-05-12T22:50:30.446816Z","iopub.execute_input":"2022-05-12T22:50:30.447022Z","iopub.status.idle":"2022-05-12T22:50:39.176462Z","shell.execute_reply.started":"2022-05-12T22:50:30.446997Z","shell.execute_reply":"2022-05-12T22:50:39.175502Z"},"trusted":true},"execution_count":102,"outputs":[{"name":"stdout","text":"2.2.5\n2.2.5\nRequirement already satisfied: Livelossplot in /opt/conda/lib/python3.7/site-packages (0.5.5)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from Livelossplot) (3.5.1)\nRequirement already satisfied: numpy<1.22 in /opt/conda/lib/python3.7/site-packages (from Livelossplot) (1.21.6)\nRequirement already satisfied: ipython==7.* in /opt/conda/lib/python3.7/site-packages (from Livelossplot) (7.32.0)\nRequirement already satisfied: bokeh in /opt/conda/lib/python3.7/site-packages (from Livelossplot) (2.4.2)\nRequirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython==7.*->Livelossplot) (2.11.2)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython==7.*->Livelossplot) (5.1.1)\nRequirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipython==7.*->Livelossplot) (5.1.1)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython==7.*->Livelossplot) (0.18.1)\nRequirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython==7.*->Livelossplot) (59.8.0)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython==7.*->Livelossplot) (4.8.0)\nRequirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython==7.*->Livelossplot) (0.7.5)\nRequirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.7/site-packages (from ipython==7.*->Livelossplot) (0.1.3)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython==7.*->Livelossplot) (3.0.27)\nRequirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython==7.*->Livelossplot) (0.2.0)\nRequirement already satisfied: Jinja2>=2.9 in /opt/conda/lib/python3.7/site-packages (from bokeh->Livelossplot) (3.1.1)\nRequirement already satisfied: packaging>=16.8 in /opt/conda/lib/python3.7/site-packages (from bokeh->Livelossplot) (21.3)\nRequirement already satisfied: pillow>=7.1.0 in /opt/conda/lib/python3.7/site-packages (from bokeh->Livelossplot) (9.0.1)\nRequirement already satisfied: tornado>=5.1 in /opt/conda/lib/python3.7/site-packages (from bokeh->Livelossplot) (6.1)\nRequirement already satisfied: PyYAML>=3.10 in /opt/conda/lib/python3.7/site-packages (from bokeh->Livelossplot) (6.0)\nRequirement already satisfied: typing-extensions>=3.10.0 in /opt/conda/lib/python3.7/site-packages (from bokeh->Livelossplot) (4.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->Livelossplot) (0.11.0)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->Livelossplot) (2.8.2)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->Livelossplot) (1.4.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->Livelossplot) (4.30.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->Livelossplot) (3.0.7)\nRequirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython==7.*->Livelossplot) (0.8.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from Jinja2>=2.9->bokeh->Livelossplot) (2.0.1)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3->ipython==7.*->Livelossplot) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.*->Livelossplot) (0.2.5)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->Livelossplot) (1.16.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom PIL import Image\nimport scipy\n\n#import tensorflow as tf\nprint(keras.__version__)\n#print(tf.__version__)\nfrom keras.applications import *\nfrom keras.optimizers import *\nfrom keras.losses import *\nfrom keras.layers import *\nfrom keras.models import *\nfrom keras.callbacks import *\nfrom keras.preprocessing.image import *\nfrom keras.utils import *\n# import pydot\n\nfrom sklearn.metrics import *\nfrom sklearn.model_selection import *\nimport tensorflow.keras.backend as K\n\nfrom tqdm import tqdm, tqdm_notebook\nfrom colorama import Fore\nimport json\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom glob import glob\nfrom skimage.io import *\n%config Completer.use_jedi = False\nimport time\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nimport lightgbm as lgb\nimport xgboost as xgb\n\nprint(\"All modules have been imported\")","metadata":{"execution":{"iopub.status.busy":"2022-05-12T22:50:39.179702Z","iopub.execute_input":"2022-05-12T22:50:39.179939Z","iopub.status.idle":"2022-05-12T22:50:39.206058Z","shell.execute_reply.started":"2022-05-12T22:50:39.179912Z","shell.execute_reply":"2022-05-12T22:50:39.205405Z"},"trusted":true},"execution_count":103,"outputs":[{"name":"stdout","text":"2.2.5\nAll modules have been imported\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nfrom sklearn.model_selection import train_test_split\n\nimport shutil\nfrom glob import glob \n#make directory for labelling\n\ntrain_dir='../working/data/train_seg/'\nvalidation_dir='../working/data/val_seg/'\n#train_dir='../working/data/train_seg/'  \n#test_dir = '../working/data/test_seg/normal'  \ntest_dir = '../working/data/test_seg/'  \n\nclass0 = [] # 0 = idc+\nclass1 = [] # 1 = idc-\nimagePatches = glob('../input/breast-histopathology-images/IDC_regular_ps50_idx5/**/*.png', recursive=True)\nfor filename in imagePatches:\n    if filename.endswith(\"class0.png\"):\n         class0.append(filename)\n    else:\n        class1.append(filename)\n\nprint(class0[0:10])\n\n#sampling 10000 images from class 0 and class 1 to train the model\n\nrandom.seed(sampling_seed)\nclass0sample=random.sample(class0,size_4_training)\nclass0label=np.zeros(size_4_training)\nclass1sample=random.sample(class1,size_4_training)\nclass1label=np.ones(size_4_training)\n\nclass0sample_train, class0sample_test1, class0label_train, class0label_test1 = train_test_split(class0sample, class0label, test_size=0.3, random_state=42)\nclass0sample_test,class0sample_val,  class0label_test, class0label_val = train_test_split(class0sample_test1, class0label_test1, test_size=0.3, random_state=42)\nprint(len(class0sample_train))\nprint(len(class0sample_test))\nprint(len(class0sample_val))\nclass1sample_train, class1sample_test1, class1label_train, class1label_test1 = train_test_split(class1sample, class1label, test_size=0.3, random_state=42)\nclass1sample_test, class1sample_val, class1label_test, class1label_val = train_test_split(class1sample_test1, class1label_test1, test_size=0.3, random_state=42)\nprint(len(class1sample_train))\nprint(len(class1sample_test))\nprint(len(class1sample_val))\ndef read_and_save_data(path, file_name_array):\n    j=0\n    for i in file_name_array:\n        if i.endswith('.png'):\n          \n            \n            #second copy method\n            head, tail = os.path.split(i)\n            outputname=str(path+tail)\n            #outputname=str(path+str(j)+'.png')\n            print(outputname)\n            shutil.copy(i, outputname)\n   \n            #print(status2)\n            \n            j=j+1\n            if j==120000:\n                break\n            \n   \nclass0train_path='../working/data/train_seg/idc-minus/'\nclass1train_path='../working/data/train_seg/idc-plus/'\nclass0test_path='../working/data/test_seg/idc-minus/'\nclass1test_path='../working/data/test_seg/idc-plus/'\nclass0val_path='../working/data/val_seg/idc-minus/'\nclass1val_path='../working/data/val_seg/idc-plus/'\n\nread_and_save_data(class0train_path,class0sample_train)\nread_and_save_data(class1train_path,class1sample_train)\n\n\nread_and_save_data(class0test_path,class0sample_test)\nread_and_save_data(class1test_path,class1sample_test)\n\n\nread_and_save_data(class0val_path,class0sample_val)\nread_and_save_data(class1val_path,class1sample_val)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T22:50:39.209640Z","iopub.execute_input":"2022-05-12T22:50:39.209864Z","iopub.status.idle":"2022-05-12T22:52:13.131152Z","shell.execute_reply.started":"2022-05-12T22:50:39.209832Z","shell.execute_reply":"2022-05-12T22:52:13.130441Z"},"trusted":true},"execution_count":104,"outputs":[{"name":"stdout","text":"['../input/breast-histopathology-images/IDC_regular_ps50_idx5/10295/0/10295_idx5_x1351_y1101_class0.png', '../input/breast-histopathology-images/IDC_regular_ps50_idx5/10295/0/10295_idx5_x1501_y501_class0.png', '../input/breast-histopathology-images/IDC_regular_ps50_idx5/10295/0/10295_idx5_x1501_y1101_class0.png', '../input/breast-histopathology-images/IDC_regular_ps50_idx5/10295/0/10295_idx5_x451_y901_class0.png', '../input/breast-histopathology-images/IDC_regular_ps50_idx5/10295/0/10295_idx5_x801_y451_class0.png', '../input/breast-histopathology-images/IDC_regular_ps50_idx5/10295/0/10295_idx5_x151_y1051_class0.png', '../input/breast-histopathology-images/IDC_regular_ps50_idx5/10295/0/10295_idx5_x1351_y901_class0.png', '../input/breast-histopathology-images/IDC_regular_ps50_idx5/10295/0/10295_idx5_x701_y651_class0.png', '../input/breast-histopathology-images/IDC_regular_ps50_idx5/10295/0/10295_idx5_x951_y1401_class0.png', '../input/breast-histopathology-images/IDC_regular_ps50_idx5/10295/0/10295_idx5_x601_y501_class0.png']\n140\n42\n18\n140\n42\n18\n../working/data/train_seg/idc-minus/9075_idx5_x1501_y1551_class0.png\n../working/data/train_seg/idc-minus/8975_idx5_x2601_y2501_class0.png\n../working/data/train_seg/idc-minus/16551_idx5_x2851_y2151_class0.png\n../working/data/train_seg/idc-minus/12810_idx5_x3351_y1351_class0.png\n../working/data/train_seg/idc-minus/9322_idx5_x1751_y651_class0.png\n../working/data/train_seg/idc-minus/13591_idx5_x2051_y1651_class0.png\n../working/data/train_seg/idc-minus/15634_idx5_x2351_y651_class0.png\n../working/data/train_seg/idc-minus/9323_idx5_x701_y651_class0.png\n../working/data/train_seg/idc-minus/10259_idx5_x1851_y2001_class0.png\n../working/data/train_seg/idc-minus/10272_idx5_x2551_y1901_class0.png\n../working/data/train_seg/idc-minus/9178_idx5_x601_y1601_class0.png\n../working/data/train_seg/idc-minus/13591_idx5_x3401_y801_class0.png\n../working/data/train_seg/idc-minus/9029_idx5_x1751_y351_class0.png\n../working/data/train_seg/idc-minus/13613_idx5_x1851_y351_class0.png\n../working/data/train_seg/idc-minus/16533_idx5_x351_y1201_class0.png\n../working/data/train_seg/idc-minus/13018_idx5_x1251_y951_class0.png\n../working/data/train_seg/idc-minus/16550_idx5_x1851_y1851_class0.png\n../working/data/train_seg/idc-minus/10305_idx5_x1851_y351_class0.png\n../working/data/train_seg/idc-minus/9176_idx5_x1801_y1101_class0.png\n../working/data/train_seg/idc-minus/10299_idx5_x2251_y2051_class0.png\n../working/data/train_seg/idc-minus/9177_idx5_x3001_y2001_class0.png\n../working/data/train_seg/idc-minus/15515_idx5_x1151_y1201_class0.png\n../working/data/train_seg/idc-minus/15515_idx5_x2751_y451_class0.png\n../working/data/train_seg/idc-minus/10262_idx5_x1301_y2251_class0.png\n../working/data/train_seg/idc-minus/9181_idx5_x1651_y351_class0.png\n../working/data/train_seg/idc-minus/16531_idx5_x1051_y551_class0.png\n../working/data/train_seg/idc-minus/8918_idx5_x51_y601_class0.png\n../working/data/train_seg/idc-minus/14154_idx5_x3501_y1401_class0.png\n../working/data/train_seg/idc-minus/10275_idx5_x951_y501_class0.png\n../working/data/train_seg/idc-minus/12951_idx5_x1701_y501_class0.png\n../working/data/train_seg/idc-minus/12951_idx5_x1601_y1001_class0.png\n../working/data/train_seg/idc-minus/16568_idx5_x2401_y601_class0.png\n../working/data/train_seg/idc-minus/10272_idx5_x2201_y2201_class0.png\n../working/data/train_seg/idc-minus/16550_idx5_x3351_y2201_class0.png\n../working/data/train_seg/idc-minus/12890_idx5_x1351_y2401_class0.png\n../working/data/train_seg/idc-minus/12880_idx5_x2201_y2151_class0.png\n../working/data/train_seg/idc-minus/12935_idx5_x1301_y2101_class0.png\n../working/data/train_seg/idc-minus/16085_idx5_x1651_y1351_class0.png\n../working/data/train_seg/idc-minus/9254_idx5_x1151_y851_class0.png\n../working/data/train_seg/idc-minus/10278_idx5_x2951_y701_class0.png\n../working/data/train_seg/idc-minus/12880_idx5_x1051_y351_class0.png\n../working/data/train_seg/idc-minus/12897_idx5_x3501_y851_class0.png\n../working/data/train_seg/idc-minus/13025_idx5_x1001_y1251_class0.png\n../working/data/train_seg/idc-minus/9254_idx5_x2651_y1901_class0.png\n../working/data/train_seg/idc-minus/13403_idx5_x1051_y301_class0.png\n../working/data/train_seg/idc-minus/12869_idx5_x2501_y251_class0.png\n../working/data/train_seg/idc-minus/16532_idx5_x2301_y701_class0.png\n../working/data/train_seg/idc-minus/10262_idx5_x2551_y1001_class0.png\n../working/data/train_seg/idc-minus/10300_idx5_x1751_y1801_class0.png\n../working/data/train_seg/idc-minus/13693_idx5_x2101_y2051_class0.png\n../working/data/train_seg/idc-minus/10291_idx5_x1751_y551_class0.png\n../working/data/train_seg/idc-minus/14210_idx5_x1601_y1251_class0.png\n../working/data/train_seg/idc-minus/12242_idx5_x2001_y1351_class0.png\n../working/data/train_seg/idc-minus/9181_idx5_x1701_y1201_class0.png\n../working/data/train_seg/idc-minus/10259_idx5_x1101_y1551_class0.png\n../working/data/train_seg/idc-minus/9290_idx5_x2451_y551_class0.png\n../working/data/train_seg/idc-minus/12905_idx5_x1401_y751_class0.png\n../working/data/train_seg/idc-minus/12880_idx5_x2351_y1351_class0.png\n../working/data/train_seg/idc-minus/14153_idx5_x401_y2851_class0.png\n../working/data/train_seg/idc-minus/12910_idx5_x2151_y801_class0.png\n../working/data/train_seg/idc-minus/9173_idx5_x1451_y2051_class0.png\n../working/data/train_seg/idc-minus/9037_idx5_x451_y1151_class0.png\n../working/data/train_seg/idc-minus/16550_idx5_x3601_y851_class0.png\n../working/data/train_seg/idc-minus/10254_idx5_x301_y551_class0.png\n../working/data/train_seg/idc-minus/9226_idx5_x1001_y651_class0.png\n../working/data/train_seg/idc-minus/14153_idx5_x2651_y2201_class0.png\n../working/data/train_seg/idc-minus/16085_idx5_x1851_y1951_class0.png\n../working/data/train_seg/idc-minus/10258_idx5_x551_y751_class0.png\n../working/data/train_seg/idc-minus/9250_idx5_x2301_y551_class0.png\n../working/data/train_seg/idc-minus/12879_idx5_x1151_y751_class0.png\n../working/data/train_seg/idc-minus/8918_idx5_x1351_y1651_class0.png\n../working/data/train_seg/idc-minus/14190_idx5_x601_y1501_class0.png\n../working/data/train_seg/idc-minus/12934_idx5_x2751_y2701_class0.png\n../working/data/train_seg/idc-minus/10262_idx5_x2201_y901_class0.png\n../working/data/train_seg/idc-minus/10278_idx5_x1701_y1051_class0.png\n../working/data/train_seg/idc-minus/16534_idx5_x451_y1151_class0.png\n../working/data/train_seg/idc-minus/10299_idx5_x901_y501_class0.png\n../working/data/train_seg/idc-minus/16896_idx5_x151_y751_class0.png\n../working/data/train_seg/idc-minus/16014_idx5_x1501_y851_class0.png\n../working/data/train_seg/idc-minus/16532_idx5_x1201_y851_class0.png\n../working/data/train_seg/idc-minus/13021_idx5_x2851_y851_class0.png\n../working/data/train_seg/idc-minus/12820_idx5_x1301_y451_class0.png\n../working/data/train_seg/idc-minus/9325_idx5_x1251_y1901_class0.png\n../working/data/train_seg/idc-minus/10303_idx5_x1001_y2001_class0.png\n../working/data/train_seg/idc-minus/10268_idx5_x2851_y1301_class0.png\n../working/data/train_seg/idc-minus/9023_idx5_x2101_y1251_class0.png\n../working/data/train_seg/idc-minus/13400_idx5_x1601_y1851_class0.png\n../working/data/train_seg/idc-minus/13616_idx5_x1301_y1651_class0.png\n../working/data/train_seg/idc-minus/12883_idx5_x2301_y401_class0.png\n../working/data/train_seg/idc-minus/12626_idx5_x801_y1851_class0.png\n../working/data/train_seg/idc-minus/10258_idx5_x1751_y451_class0.png\n../working/data/train_seg/idc-minus/9075_idx5_x851_y1051_class0.png\n../working/data/train_seg/idc-minus/10286_idx5_x951_y151_class0.png\n../working/data/train_seg/idc-minus/9123_idx5_x1951_y2251_class0.png\n../working/data/train_seg/idc-minus/10264_idx5_x1201_y501_class0.png\n../working/data/train_seg/idc-minus/9254_idx5_x1701_y351_class0.png\n../working/data/train_seg/idc-minus/12934_idx5_x2201_y1151_class0.png\n../working/data/train_seg/idc-minus/15510_idx5_x2551_y1651_class0.png\n../working/data/train_seg/idc-minus/9037_idx5_x51_y1151_class0.png\n../working/data/train_seg/idc-minus/15472_idx5_x2451_y351_class0.png\n../working/data/train_seg/idc-minus/9265_idx5_x2301_y1301_class0.png\n../working/data/train_seg/idc-minus/10300_idx5_x2201_y901_class0.png\n../working/data/train_seg/idc-minus/10268_idx5_x3401_y1101_class0.png\n../working/data/train_seg/idc-minus/10268_idx5_x701_y1451_class0.png\n../working/data/train_seg/idc-minus/13025_idx5_x751_y501_class0.png\n../working/data/train_seg/idc-minus/10295_idx5_x1501_y551_class0.png\n../working/data/train_seg/idc-minus/9290_idx5_x451_y851_class0.png\n../working/data/train_seg/idc-minus/10269_idx5_x701_y701_class0.png\n../working/data/train_seg/idc-minus/8864_idx5_x2651_y2901_class0.png\n../working/data/train_seg/idc-minus/16166_idx5_x2751_y1201_class0.png\n../working/data/train_seg/idc-minus/10259_idx5_x1801_y1201_class0.png\n../working/data/train_seg/idc-minus/10306_idx5_x2151_y651_class0.png\n../working/data/train_seg/idc-minus/9029_idx5_x2501_y1351_class0.png\n../working/data/train_seg/idc-minus/14191_idx5_x1701_y501_class0.png\n../working/data/train_seg/idc-minus/12934_idx5_x1651_y2651_class0.png\n../working/data/train_seg/idc-minus/9382_idx5_x301_y1301_class0.png\n../working/data/train_seg/idc-minus/13691_idx5_x3351_y2201_class0.png\n../working/data/train_seg/idc-minus/10272_idx5_x851_y1551_class0.png\n../working/data/train_seg/idc-minus/8913_idx5_x451_y801_class0.png\n../working/data/train_seg/idc-minus/16550_idx5_x2151_y751_class0.png\n../working/data/train_seg/idc-minus/12873_idx5_x1451_y151_class0.png\n../working/data/train_seg/idc-minus/14157_idx5_x2651_y1101_class0.png\n../working/data/train_seg/idc-minus/8864_idx5_x901_y2901_class0.png\n../working/data/train_seg/idc-minus/9078_idx5_x501_y601_class0.png\n../working/data/train_seg/idc-minus/12749_idx5_x151_y1151_class0.png\n../working/data/train_seg/idc-minus/12880_idx5_x1801_y2551_class0.png\n../working/data/train_seg/idc-minus/9075_idx5_x2001_y1051_class0.png\n../working/data/train_seg/idc-minus/10276_idx5_x1751_y1151_class0.png\n../working/data/train_seg/idc-minus/10305_idx5_x1551_y1101_class0.png\n../working/data/train_seg/idc-minus/14212_idx5_x3851_y2451_class0.png\n../working/data/train_seg/idc-minus/14189_idx5_x751_y1801_class0.png\n../working/data/train_seg/idc-minus/9123_idx5_x2001_y1001_class0.png\n../working/data/train_seg/idc-minus/10290_idx5_x951_y1101_class0.png\n../working/data/train_seg/idc-minus/9290_idx5_x1351_y1351_class0.png\n../working/data/train_seg/idc-minus/10300_idx5_x1901_y601_class0.png\n../working/data/train_seg/idc-minus/10259_idx5_x2601_y1151_class0.png\n../working/data/train_seg/idc-minus/12911_idx5_x1301_y1651_class0.png\n../working/data/train_seg/idc-minus/14210_idx5_x551_y1601_class0.png\n../working/data/train_seg/idc-minus/9323_idx5_x1701_y2401_class0.png\n../working/data/train_seg/idc-minus/10273_idx5_x2501_y2451_class0.png\n../working/data/train_seg/idc-plus/10279_idx5_x2651_y1001_class1.png\n../working/data/train_seg/idc-plus/9126_idx5_x2401_y1351_class1.png\n../working/data/train_seg/idc-plus/10273_idx5_x2101_y1901_class1.png\n../working/data/train_seg/idc-plus/16165_idx5_x2251_y2251_class1.png\n../working/data/train_seg/idc-plus/15903_idx5_x1101_y1151_class1.png\n../working/data/train_seg/idc-plus/9043_idx5_x2701_y701_class1.png\n../working/data/train_seg/idc-plus/9344_idx5_x2401_y1151_class1.png\n../working/data/train_seg/idc-plus/12626_idx5_x701_y2151_class1.png\n../working/data/train_seg/idc-plus/16166_idx5_x951_y1851_class1.png\n../working/data/train_seg/idc-plus/9250_idx5_x1851_y1051_class1.png\n../working/data/train_seg/idc-plus/9077_idx5_x2051_y851_class1.png\n../working/data/train_seg/idc-plus/10299_idx5_x1151_y2151_class1.png\n../working/data/train_seg/idc-plus/12947_idx5_x801_y2101_class1.png\n../working/data/train_seg/idc-plus/12751_idx5_x1701_y1201_class1.png\n../working/data/train_seg/idc-plus/13020_idx5_x2051_y1151_class1.png\n../working/data/train_seg/idc-plus/9076_idx5_x2201_y1451_class1.png\n../working/data/train_seg/idc-plus/13022_idx5_x2251_y2051_class1.png\n../working/data/train_seg/idc-plus/12932_idx5_x1751_y1151_class1.png\n../working/data/train_seg/idc-plus/14190_idx5_x1201_y851_class1.png\n../working/data/train_seg/idc-plus/16014_idx5_x551_y551_class1.png\n../working/data/train_seg/idc-plus/14189_idx5_x1451_y1101_class1.png\n../working/data/train_seg/idc-plus/9073_idx5_x1151_y801_class1.png\n../working/data/train_seg/idc-plus/10260_idx5_x1401_y1301_class1.png\n../working/data/train_seg/idc-plus/10257_idx5_x1701_y1751_class1.png\n../working/data/train_seg/idc-plus/10302_idx5_x1201_y851_class1.png\n../working/data/train_seg/idc-plus/12900_idx5_x2651_y2201_class1.png\n../working/data/train_seg/idc-plus/10264_idx5_x1551_y601_class1.png\n../working/data/train_seg/idc-plus/15902_idx5_x2801_y1401_class1.png\n../working/data/train_seg/idc-plus/10299_idx5_x1001_y1101_class1.png\n../working/data/train_seg/idc-plus/15514_idx5_x2401_y651_class1.png\n../working/data/train_seg/idc-plus/15903_idx5_x1051_y451_class1.png\n../working/data/train_seg/idc-plus/13613_idx5_x2101_y1851_class1.png\n../working/data/train_seg/idc-plus/12868_idx5_x1251_y1851_class1.png\n../working/data/train_seg/idc-plus/16165_idx5_x2551_y1151_class1.png\n../working/data/train_seg/idc-plus/14191_idx5_x2851_y1701_class1.png\n../working/data/train_seg/idc-plus/8864_idx5_x2151_y2501_class1.png\n../working/data/train_seg/idc-plus/14082_idx5_x1101_y1751_class1.png\n../working/data/train_seg/idc-plus/10299_idx5_x2251_y851_class1.png\n../working/data/train_seg/idc-plus/12818_idx5_x1701_y851_class1.png\n../working/data/train_seg/idc-plus/10282_idx5_x1751_y1901_class1.png\n../working/data/train_seg/idc-plus/9324_idx5_x951_y851_class1.png\n../working/data/train_seg/idc-plus/10269_idx5_x1951_y451_class1.png\n../working/data/train_seg/idc-plus/9077_idx5_x2051_y701_class1.png\n../working/data/train_seg/idc-plus/8975_idx5_x2151_y1201_class1.png\n../working/data/train_seg/idc-plus/8867_idx5_x1151_y1201_class1.png\n../working/data/train_seg/idc-plus/12818_idx5_x2351_y751_class1.png\n../working/data/train_seg/idc-plus/12880_idx5_x1251_y1301_class1.png\n../working/data/train_seg/idc-plus/14304_idx5_x1801_y1001_class1.png\n../working/data/train_seg/idc-plus/12750_idx5_x501_y201_class1.png\n../working/data/train_seg/idc-plus/15902_idx5_x2401_y1101_class1.png\n../working/data/train_seg/idc-plus/13462_idx5_x1551_y1401_class1.png\n../working/data/train_seg/idc-plus/10308_idx5_x1051_y1551_class1.png\n../working/data/train_seg/idc-plus/9346_idx5_x1401_y1451_class1.png\n../working/data/train_seg/idc-plus/10299_idx5_x1401_y1401_class1.png\n../working/data/train_seg/idc-plus/9347_idx5_x701_y1051_class1.png\n../working/data/train_seg/idc-plus/13692_idx5_x2551_y1001_class1.png\n../working/data/train_seg/idc-plus/12897_idx5_x2001_y801_class1.png\n../working/data/train_seg/idc-plus/12867_idx5_x2151_y1801_class1.png\n../working/data/train_seg/idc-plus/9043_idx5_x3201_y1151_class1.png\n../working/data/train_seg/idc-plus/10256_idx5_x1901_y951_class1.png\n../working/data/train_seg/idc-plus/13401_idx5_x1651_y1301_class1.png\n../working/data/train_seg/idc-plus/12867_idx5_x2451_y2301_class1.png\n../working/data/train_seg/idc-plus/13459_idx5_x801_y551_class1.png\n../working/data/train_seg/idc-plus/12810_idx5_x1851_y851_class1.png\n../working/data/train_seg/idc-plus/12895_idx5_x2301_y2101_class1.png\n../working/data/train_seg/idc-plus/10257_idx5_x1901_y1551_class1.png\n../working/data/train_seg/idc-plus/14213_idx5_x1901_y1351_class1.png\n../working/data/train_seg/idc-plus/8956_idx5_x2001_y601_class1.png\n../working/data/train_seg/idc-plus/12886_idx5_x301_y451_class1.png\n../working/data/train_seg/idc-plus/12934_idx5_x2551_y2001_class1.png\n../working/data/train_seg/idc-plus/12935_idx5_x1351_y851_class1.png\n../working/data/train_seg/idc-plus/13462_idx5_x1151_y1901_class1.png\n../working/data/train_seg/idc-plus/14190_idx5_x1151_y1301_class1.png\n../working/data/train_seg/idc-plus/10299_idx5_x1001_y1051_class1.png\n../working/data/train_seg/idc-plus/12898_idx5_x1901_y351_class1.png\n../working/data/train_seg/idc-plus/8913_idx5_x851_y1401_class1.png\n../working/data/train_seg/idc-plus/9346_idx5_x1051_y1901_class1.png\n../working/data/train_seg/idc-plus/9320_idx5_x1101_y1551_class1.png\n../working/data/train_seg/idc-plus/12876_idx5_x801_y651_class1.png\n../working/data/train_seg/idc-plus/10299_idx5_x1251_y1151_class1.png\n../working/data/train_seg/idc-plus/12886_idx5_x351_y551_class1.png\n../working/data/train_seg/idc-plus/13616_idx5_x1601_y1801_class1.png\n../working/data/train_seg/idc-plus/14078_idx5_x851_y951_class1.png\n../working/data/train_seg/idc-plus/9255_idx5_x2651_y1101_class1.png\n../working/data/train_seg/idc-plus/12817_idx5_x1101_y1551_class1.png\n../working/data/train_seg/idc-plus/13916_idx5_x2451_y1251_class1.png\n../working/data/train_seg/idc-plus/10292_idx5_x2201_y1551_class1.png\n../working/data/train_seg/idc-plus/9260_idx5_x751_y251_class1.png\n../working/data/train_seg/idc-plus/12947_idx5_x1901_y1851_class1.png\n../working/data/train_seg/idc-plus/10299_idx5_x751_y1851_class1.png\n../working/data/train_seg/idc-plus/10302_idx5_x2251_y951_class1.png\n../working/data/train_seg/idc-plus/13462_idx5_x1151_y2251_class1.png\n../working/data/train_seg/idc-plus/12893_idx5_x701_y1401_class1.png\n../working/data/train_seg/idc-plus/9260_idx5_x701_y201_class1.png\n../working/data/train_seg/idc-plus/9382_idx5_x1601_y951_class1.png\n../working/data/train_seg/idc-plus/15840_idx5_x401_y1051_class1.png\n../working/data/train_seg/idc-plus/9290_idx5_x1451_y751_class1.png\n../working/data/train_seg/idc-plus/12748_idx5_x651_y901_class1.png\n../working/data/train_seg/idc-plus/12909_idx5_x1051_y751_class1.png\n../working/data/train_seg/idc-plus/12935_idx5_x1701_y1651_class1.png\n../working/data/train_seg/idc-plus/9257_idx5_x1601_y801_class1.png\n../working/data/train_seg/idc-plus/15510_idx5_x2201_y1151_class1.png\n../working/data/train_seg/idc-plus/10260_idx5_x1001_y1151_class1.png\n../working/data/train_seg/idc-plus/12751_idx5_x2251_y901_class1.png\n../working/data/train_seg/idc-plus/9345_idx5_x2801_y801_class1.png\n../working/data/train_seg/idc-plus/13916_idx5_x951_y1451_class1.png\n../working/data/train_seg/idc-plus/12822_idx5_x1751_y301_class1.png\n../working/data/train_seg/idc-plus/16165_idx5_x1351_y1701_class1.png\n../working/data/train_seg/idc-plus/13613_idx5_x2651_y1451_class1.png\n../working/data/train_seg/idc-plus/10292_idx5_x1501_y2151_class1.png\n../working/data/train_seg/idc-plus/10308_idx5_x1001_y1401_class1.png\n../working/data/train_seg/idc-plus/12935_idx5_x2001_y1601_class1.png\n../working/data/train_seg/idc-plus/13694_idx5_x501_y2101_class1.png\n../working/data/train_seg/idc-plus/10304_idx5_x751_y501_class1.png\n../working/data/train_seg/idc-plus/16165_idx5_x1301_y2451_class1.png\n../working/data/train_seg/idc-plus/12751_idx5_x1801_y1801_class1.png\n../working/data/train_seg/idc-plus/14191_idx5_x1851_y2201_class1.png\n../working/data/train_seg/idc-plus/12886_idx5_x701_y851_class1.png\n../working/data/train_seg/idc-plus/16552_idx5_x901_y951_class1.png\n../working/data/train_seg/idc-plus/13692_idx5_x2451_y1101_class1.png\n../working/data/train_seg/idc-plus/9250_idx5_x1401_y1101_class1.png\n../working/data/train_seg/idc-plus/9043_idx5_x2251_y801_class1.png\n../working/data/train_seg/idc-plus/12751_idx5_x2851_y551_class1.png\n../working/data/train_seg/idc-plus/10303_idx5_x2301_y1851_class1.png\n../working/data/train_seg/idc-plus/9261_idx5_x1001_y701_class1.png\n../working/data/train_seg/idc-plus/12955_idx5_x2051_y351_class1.png\n../working/data/train_seg/idc-plus/15516_idx5_x2151_y1851_class1.png\n../working/data/train_seg/idc-plus/15633_idx5_x1101_y601_class1.png\n../working/data/train_seg/idc-plus/12820_idx5_x1851_y651_class1.png\n../working/data/train_seg/idc-plus/12895_idx5_x1251_y1551_class1.png\n../working/data/train_seg/idc-plus/9256_idx5_x2551_y1651_class1.png\n../working/data/train_seg/idc-plus/13402_idx5_x2051_y651_class1.png\n../working/data/train_seg/idc-plus/10286_idx5_x1401_y301_class1.png\n../working/data/train_seg/idc-plus/12242_idx5_x2251_y1201_class1.png\n../working/data/train_seg/idc-plus/9125_idx5_x1251_y1601_class1.png\n../working/data/train_seg/idc-plus/12880_idx5_x1251_y901_class1.png\n../working/data/train_seg/idc-plus/10301_idx5_x1301_y1351_class1.png\n../working/data/train_seg/idc-plus/9124_idx5_x651_y851_class1.png\n../working/data/train_seg/idc-plus/13023_idx5_x1951_y1151_class1.png\n../working/data/train_seg/idc-plus/13694_idx5_x1451_y901_class1.png\n../working/data/test_seg/idc-minus/12898_idx5_x351_y651_class0.png\n../working/data/test_seg/idc-minus/10308_idx5_x201_y1201_class0.png\n../working/data/test_seg/idc-minus/10254_idx5_x2351_y751_class0.png\n../working/data/test_seg/idc-minus/12626_idx5_x1851_y1551_class0.png\n../working/data/test_seg/idc-minus/9265_idx5_x701_y1801_class0.png\n../working/data/test_seg/idc-minus/13023_idx5_x751_y351_class0.png\n../working/data/test_seg/idc-minus/15903_idx5_x2101_y1151_class0.png\n../working/data/test_seg/idc-minus/14079_idx5_x1451_y1201_class0.png\n../working/data/test_seg/idc-minus/8984_idx5_x2701_y901_class0.png\n../working/data/test_seg/idc-minus/12911_idx5_x1001_y1401_class0.png\n../working/data/test_seg/idc-minus/10262_idx5_x701_y751_class0.png\n../working/data/test_seg/idc-minus/13613_idx5_x3201_y751_class0.png\n../working/data/test_seg/idc-minus/13692_idx5_x2601_y2551_class0.png\n../working/data/test_seg/idc-minus/13691_idx5_x2901_y101_class0.png\n../working/data/test_seg/idc-minus/8864_idx5_x951_y1801_class0.png\n../working/data/test_seg/idc-minus/12884_idx5_x1501_y1401_class0.png\n../working/data/test_seg/idc-minus/10303_idx5_x701_y1501_class0.png\n../working/data/test_seg/idc-minus/10272_idx5_x701_y851_class0.png\n../working/data/test_seg/idc-minus/12890_idx5_x2251_y551_class0.png\n../working/data/test_seg/idc-minus/12910_idx5_x1901_y851_class0.png\n../working/data/test_seg/idc-minus/12955_idx5_x601_y1601_class0.png\n../working/data/test_seg/idc-minus/12821_idx5_x451_y1351_class0.png\n../working/data/test_seg/idc-minus/10277_idx5_x1751_y1101_class0.png\n../working/data/test_seg/idc-minus/14192_idx5_x301_y751_class0.png\n../working/data/test_seg/idc-minus/12911_idx5_x2251_y151_class0.png\n../working/data/test_seg/idc-minus/13020_idx5_x1751_y1651_class0.png\n../working/data/test_seg/idc-minus/9382_idx5_x501_y1551_class0.png\n../working/data/test_seg/idc-minus/9123_idx5_x2751_y1501_class0.png\n../working/data/test_seg/idc-minus/13613_idx5_x2401_y651_class0.png\n../working/data/test_seg/idc-minus/14154_idx5_x3451_y1251_class0.png\n../working/data/test_seg/idc-minus/9250_idx5_x1951_y1301_class0.png\n../working/data/test_seg/idc-minus/8867_idx5_x3001_y1701_class0.png\n../working/data/test_seg/idc-minus/12951_idx5_x1451_y1351_class0.png\n../working/data/test_seg/idc-minus/14191_idx5_x1851_y801_class0.png\n../working/data/test_seg/idc-minus/9345_idx5_x2601_y1751_class0.png\n../working/data/test_seg/idc-minus/10305_idx5_x901_y651_class0.png\n../working/data/test_seg/idc-minus/12820_idx5_x1351_y351_class0.png\n../working/data/test_seg/idc-minus/15510_idx5_x2501_y2001_class0.png\n../working/data/test_seg/idc-minus/10301_idx5_x2251_y501_class0.png\n../working/data/test_seg/idc-minus/9177_idx5_x2301_y1301_class0.png\n../working/data/test_seg/idc-minus/10276_idx5_x1151_y551_class0.png\n../working/data/test_seg/idc-minus/9290_idx5_x1101_y1601_class0.png\n../working/data/test_seg/idc-plus/13694_idx5_x1251_y1551_class1.png\n../working/data/test_seg/idc-plus/12908_idx5_x2101_y1051_class1.png\n../working/data/test_seg/idc-plus/10292_idx5_x1501_y1151_class1.png\n../working/data/test_seg/idc-plus/8984_idx5_x2151_y1651_class1.png\n../working/data/test_seg/idc-plus/12823_idx5_x2951_y1151_class1.png\n../working/data/test_seg/idc-plus/10262_idx5_x1551_y1701_class1.png\n../working/data/test_seg/idc-plus/12751_idx5_x2801_y801_class1.png\n../working/data/test_seg/idc-plus/13693_idx5_x551_y1601_class1.png\n../working/data/test_seg/idc-plus/12893_idx5_x401_y1451_class1.png\n../working/data/test_seg/idc-plus/12893_idx5_x751_y1451_class1.png\n../working/data/test_seg/idc-plus/9041_idx5_x2451_y1251_class1.png\n../working/data/test_seg/idc-plus/10264_idx5_x351_y1251_class1.png\n../working/data/test_seg/idc-plus/15510_idx5_x1801_y1251_class1.png\n../working/data/test_seg/idc-plus/10300_idx5_x2151_y651_class1.png\n../working/data/test_seg/idc-plus/14188_idx5_x1351_y1551_class1.png\n../working/data/test_seg/idc-plus/8864_idx5_x1901_y2301_class1.png\n../working/data/test_seg/idc-plus/9258_idx5_x951_y1901_class1.png\n../working/data/test_seg/idc-plus/12893_idx5_x651_y1751_class1.png\n../working/data/test_seg/idc-plus/10299_idx5_x851_y2201_class1.png\n../working/data/test_seg/idc-plus/13402_idx5_x2051_y451_class1.png\n../working/data/test_seg/idc-plus/13613_idx5_x2201_y1851_class1.png\n../working/data/test_seg/idc-plus/12823_idx5_x2601_y1701_class1.png\n../working/data/test_seg/idc-plus/9135_idx5_x1701_y1851_class1.png\n../working/data/test_seg/idc-plus/8917_idx5_x751_y901_class1.png\n../working/data/test_seg/idc-plus/12880_idx5_x1901_y701_class1.png\n../working/data/test_seg/idc-plus/10301_idx5_x1651_y1201_class1.png\n../working/data/test_seg/idc-plus/9325_idx5_x2151_y451_class1.png\n../working/data/test_seg/idc-plus/14191_idx5_x2301_y2451_class1.png\n../working/data/test_seg/idc-plus/9083_idx5_x2101_y351_class1.png\n../working/data/test_seg/idc-plus/9043_idx5_x2551_y701_class1.png\n../working/data/test_seg/idc-plus/10269_idx5_x1551_y801_class1.png\n../working/data/test_seg/idc-plus/10301_idx5_x851_y1501_class1.png\n../working/data/test_seg/idc-plus/12751_idx5_x2251_y1951_class1.png\n../working/data/test_seg/idc-plus/10295_idx5_x1551_y1551_class1.png\n../working/data/test_seg/idc-plus/9125_idx5_x1251_y1051_class1.png\n../working/data/test_seg/idc-plus/12819_idx5_x1501_y2001_class1.png\n../working/data/test_seg/idc-plus/14189_idx5_x2501_y1301_class1.png\n../working/data/test_seg/idc-plus/12818_idx5_x2101_y1451_class1.png\n../working/data/test_seg/idc-plus/13462_idx5_x1451_y1301_class1.png\n../working/data/test_seg/idc-plus/9323_idx5_x901_y1801_class1.png\n../working/data/test_seg/idc-plus/12822_idx5_x501_y301_class1.png\n../working/data/test_seg/idc-plus/10302_idx5_x2551_y601_class1.png\n../working/data/val_seg/idc-minus/8867_idx5_x1301_y701_class0.png\n../working/data/val_seg/idc-minus/9321_idx5_x2001_y1801_class0.png\n../working/data/val_seg/idc-minus/15903_idx5_x1351_y1701_class0.png\n../working/data/val_seg/idc-minus/12910_idx5_x251_y501_class0.png\n../working/data/val_seg/idc-minus/14156_idx5_x2801_y1901_class0.png\n../working/data/val_seg/idc-minus/12951_idx5_x2801_y851_class0.png\n../working/data/val_seg/idc-minus/9261_idx5_x1001_y2551_class0.png\n../working/data/val_seg/idc-minus/16166_idx5_x3251_y1801_class0.png\n../working/data/val_seg/idc-minus/12910_idx5_x2151_y51_class0.png\n../working/data/val_seg/idc-minus/9075_idx5_x2401_y1351_class0.png\n../working/data/val_seg/idc-minus/8950_idx5_x851_y551_class0.png\n../working/data/val_seg/idc-minus/12626_idx5_x1901_y1801_class0.png\n../working/data/val_seg/idc-minus/13402_idx5_x1151_y1201_class0.png\n../working/data/val_seg/idc-minus/12810_idx5_x2901_y2301_class0.png\n../working/data/val_seg/idc-minus/12750_idx5_x951_y1451_class0.png\n../working/data/val_seg/idc-minus/14191_idx5_x2151_y501_class0.png\n../working/data/val_seg/idc-minus/10259_idx5_x2701_y1401_class0.png\n../working/data/val_seg/idc-minus/9256_idx5_x1701_y651_class0.png\n../working/data/val_seg/idc-plus/15473_idx5_x1801_y1401_class1.png\n../working/data/val_seg/idc-plus/9023_idx5_x1901_y1801_class1.png\n../working/data/val_seg/idc-plus/12934_idx5_x2851_y2551_class1.png\n../working/data/val_seg/idc-plus/12752_idx5_x2951_y851_class1.png\n../working/data/val_seg/idc-plus/12895_idx5_x2301_y1901_class1.png\n../working/data/val_seg/idc-plus/9135_idx5_x951_y1801_class1.png\n../working/data/val_seg/idc-plus/9346_idx5_x2051_y1951_class1.png\n../working/data/val_seg/idc-plus/9383_idx5_x1751_y1001_class1.png\n../working/data/val_seg/idc-plus/8974_idx5_x1201_y1351_class1.png\n../working/data/val_seg/idc-plus/12868_idx5_x1301_y1301_class1.png\n../working/data/val_seg/idc-plus/10278_idx5_x1501_y901_class1.png\n../working/data/val_seg/idc-plus/12906_idx5_x2501_y1751_class1.png\n../working/data/val_seg/idc-plus/15514_idx5_x1051_y1551_class1.png\n../working/data/val_seg/idc-plus/14155_idx5_x3501_y1351_class1.png\n../working/data/val_seg/idc-plus/12820_idx5_x1851_y851_class1.png\n../working/data/val_seg/idc-plus/9081_idx5_x2451_y1401_class1.png\n../working/data/val_seg/idc-plus/15473_idx5_x1001_y1251_class1.png\n../working/data/val_seg/idc-plus/15473_idx5_x1551_y1851_class1.png\n","output_type":"stream"}]},{"cell_type":"code","source":"#shutil.rmtree('./data')","metadata":{"execution":{"iopub.status.busy":"2022-05-12T22:52:13.132731Z","iopub.execute_input":"2022-05-12T22:52:13.132996Z","iopub.status.idle":"2022-05-12T22:52:13.138892Z","shell.execute_reply.started":"2022-05-12T22:52:13.132962Z","shell.execute_reply":"2022-05-12T22:52:13.138118Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**load gen**","metadata":{}},{"cell_type":"code","source":"\nimport os #Operating System\nimport sys #System\n# train_generator = train_datagen.flow(x_train, y_train, batch_size =)\n# val_generator = val_datagen.flow(x_val, y_val, batch_size = 64)\n# test_generator=test_datagen.flow(x_test,y_test,batch_size = 64)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T22:52:13.140341Z","iopub.execute_input":"2022-05-12T22:52:13.140605Z","iopub.status.idle":"2022-05-12T22:52:13.146785Z","shell.execute_reply.started":"2022-05-12T22:52:13.140569Z","shell.execute_reply":"2022-05-12T22:52:13.145961Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\ndef readImage(path, tag):\n    j=0\n    image_data = []\n    label=[]\n    for i in os.listdir(path):\n        imgname=path+i\n        #print(imgname)\n        img = cv2.imread(imgname, cv2.IMREAD_COLOR)\n        img_resized = cv2.resize(img, (img_x,img_x), interpolation=cv2.INTER_LINEAR)\n        image_data.append(img_resized)\n        label.append(tag)\n        #print(img[1])\n        j=j+1\n        #if j==10:\n        #    break\n        \n    return image_data, label\n\nimport numpy as np\nfrom tensorflow.keras.utils import *\nfrom sklearn.utils import shuffle\n\nclass0_train, train0_label = readImage(class0train_path, 0)\nclass1_train, train1_label  = readImage(class1train_path, 1)\nclass0_test, test0_label = readImage(class0test_path, 0)\nclass1_test, test1_label = readImage(class1test_path, 1)\nclass0_val, val0_label = readImage(class0val_path, 0)\nclass1_val, val1_label = readImage(class1val_path, 1)\n\ndef Image_array_process(class0array,label0, class1array, label1):\n    class0_array=np.array(class0array)\n    class1_array=np.array(class1array)\n    combined_data = np.concatenate((class0_array, class1_array))\n    combined_label= np.concatenate((label0,label1), axis=0)\n    assert len(combined_data) == len(combined_label)\n    combined_data, combined_label = shuffle(combined_data, combined_label, random_state=0)\n    print(combined_data.shape)\n    length=len(combined_data)\n    combined_label=to_categorical(combined_label,num_classes=2)\n    i=0\n    for i in range(length):\n        print(combined_label[i])\n\n    print\n\n    #print(class0_array.shape)\n    #print(combined_data.shape)\n    '''\n    training_reshape=(img_x,img_x,3)\n    length=len(combined_data)\n    print(length)\n    x =[None]*length\n    #print(img_data.type)\n    y =np.zeros(length)\n    i=0\n   \n    for features,label in combined_data:\n        x[i]=features\n        #print(x.shape)\n        y[i]=label\n        #print(y[i])\n        i=i+1\n    \n            #x = np.array(x).reshape(training_reshape)\n    x = np.array(x)    \n    #print(x.shape)\n    #y=np.array(y)\n    y=y.astype(int)\n    y = to_categorical(y)\n    print(y)\n    '''  \n    return combined_data, combined_label\n\n\nX_train, y_train=Image_array_process(class0_train, train0_label, class1_train, train1_label)\nX_test, y_test=Image_array_process(class0_test, test0_label, class1_test, test1_label)\nX_val, y_val=Image_array_process(class0_val, val0_label, class1_val, val1_label)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-12T22:52:13.147995Z","iopub.execute_input":"2022-05-12T22:52:13.148363Z","iopub.status.idle":"2022-05-12T22:52:13.454932Z","shell.execute_reply.started":"2022-05-12T22:52:13.148328Z","shell.execute_reply":"2022-05-12T22:52:13.454159Z"},"trusted":true},"execution_count":107,"outputs":[{"name":"stdout","text":"(280, 224, 224, 3)\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n(84, 224, 224, 3)\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n(36, 224, 224, 3)\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[0. 1.]\n[0. 1.]\n[1. 0.]\n[0. 1.]\n[1. 0.]\n[1. 0.]\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data=X_train\ntrain_label=y_train\n\ntest_data=X_test\ntest_label=y_test\n\nval_data=X_val\nval_label=y_val","metadata":{"execution":{"iopub.status.busy":"2022-05-12T22:52:13.457334Z","iopub.execute_input":"2022-05-12T22:52:13.457908Z","iopub.status.idle":"2022-05-12T22:52:13.463764Z","shell.execute_reply.started":"2022-05-12T22:52:13.457865Z","shell.execute_reply":"2022-05-12T22:52:13.462824Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"\n\ntrain_dir='../working/data/train_seg/'  \n#test_dir = '../working/data/test_seg/idc-minus'  \ntest_minus_dir = '../working/data/test_seg/idc-minus' \nimg_size = (img_x, img_x)  \nepochs = epoch_4_test\nMODEL_PATH = '../working/log/tst_model.h5'\nboard_name1 = '../working/log/stage1/' + now + '/'\nboard_name2 = '../working/log/stage2/' + now + '/'\n\n#MODEL_PATH = '../working/log/tst_model.h5'\n#model.load_weights(MODEL_PATH)\n# --------------- test ----------------\ndirs = os.listdir(test_minus_dir)\n\nprob_list = []\nfor d in dirs:\n    img = image.load_img(test_minus_dir + os.sep + d, target_size=img_size)\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    y = model.predict(x)\n#    print(y)\n    #print(classes[np.argmax(y)])\n#    print(classes)\n\n    prob_list.append(str(y))   \n    file=open('../working/pred_prob.txt','w') \n    file.write('\\n'.join(prob_list))\n    file.close()\n    \n#import tensorflow as tf\n#config = tf.ConfigProto()\n#config.gpu_options.allow_growth = True\n#keras.backend.set_session(tf.Session(config=config))","metadata":{"execution":{"iopub.status.busy":"2022-05-12T22:52:13.465282Z","iopub.execute_input":"2022-05-12T22:52:13.465748Z","iopub.status.idle":"2022-05-12T22:52:32.157045Z","shell.execute_reply.started":"2022-05-12T22:52:13.465707Z","shell.execute_reply":"2022-05-12T22:52:32.156269Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"markdown","source":"PLTv3","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Sun Jun 16 22:23:24 2020\n\n@author: HP\n\"\"\"\n'''\n\nfrom keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, multiply, Permute, Concatenate, Conv2D, Add, Activation, Lambda\nfrom keras import backend as K\nfrom keras.activations import sigmoid\n\n\nfrom keras import backend as K\nfrom keras import optimizers\nfrom tensorflow.keras.optimizers import Adam\nimport keras.backend.tensorflow_backend as KTF\n#import tensorflow.python.keras.backend as KTF\nimport glob\nfrom keras.layers import Input,Dense,Dropout,BatchNormalization,Conv2D,MaxPooling2D,AveragePooling2D,concatenate,Activation,ZeroPadding2D\nimport tensorflow as tf\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport keras\nfrom keras.models import load_model\nfrom keras.layers import Activation, Dense\nfrom matplotlib import pyplot as plt\nfrom skimage import io,data\nimport time\nfrom keras import layers\nfrom keras.callbacks import ModelCheckpoint, TensorBoard\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn import svm\nfrom sklearn.ensemble import RandomForestClassifier\nnow = time.strftime(\"%Y-%m-%d_%H-%M-%S\", time.localtime())\n\nimport os,sys\nos.getcwd()\n#os.chdir(\"../working/cjd/31_CNN_Attention\")\n\n#import tensorflow as tf\nfrom keras.preprocessing import image\nfrom keras.models import Model\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras import backend as K\nfrom keras import regularizers\n'''","metadata":{"execution":{"iopub.status.busy":"2022-05-12T22:52:32.161644Z","iopub.execute_input":"2022-05-12T22:52:32.163298Z","iopub.status.idle":"2022-05-12T22:52:32.171359Z","shell.execute_reply.started":"2022-05-12T22:52:32.163264Z","shell.execute_reply":"2022-05-12T22:52:32.170654Z"},"trusted":true},"execution_count":110,"outputs":[{"execution_count":110,"output_type":"execute_result","data":{"text/plain":"'\\n\\nfrom keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, multiply, Permute, Concatenate, Conv2D, Add, Activation, Lambda\\nfrom keras import backend as K\\nfrom keras.activations import sigmoid\\n\\n\\nfrom keras import backend as K\\nfrom keras import optimizers\\nfrom tensorflow.keras.optimizers import Adam\\nimport keras.backend.tensorflow_backend as KTF\\n#import tensorflow.python.keras.backend as KTF\\nimport glob\\nfrom keras.layers import Input,Dense,Dropout,BatchNormalization,Conv2D,MaxPooling2D,AveragePooling2D,concatenate,Activation,ZeroPadding2D\\nimport tensorflow as tf\\nimport cv2\\nimport numpy as np\\nimport pandas as pd\\nimport keras\\nfrom keras.models import load_model\\nfrom keras.layers import Activation, Dense\\nfrom matplotlib import pyplot as plt\\nfrom skimage import io,data\\nimport time\\nfrom keras import layers\\nfrom keras.callbacks import ModelCheckpoint, TensorBoard\\nfrom keras.preprocessing.image import ImageDataGenerator\\n\\nfrom sklearn import svm\\nfrom sklearn.ensemble import RandomForestClassifier\\nnow = time.strftime(\"%Y-%m-%d_%H-%M-%S\", time.localtime())\\n\\nimport os,sys\\nos.getcwd()\\n#os.chdir(\"../working/cjd/31_CNN_Attention\")\\n\\n#import tensorflow as tf\\nfrom keras.preprocessing import image\\nfrom keras.models import Model\\nfrom keras.layers import Dense, GlobalAveragePooling2D\\nfrom keras import backend as K\\nfrom keras import regularizers\\n'"},"metadata":{}}]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import load_model\nfrom keras.callbacks import *\n\nprint(os.getcwd())\nprint (sys.version)\n#os.makedirs('../working/log/')    \n\n#import os\n# \nos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,5\"\n\n#import tensorflow as tf   \n#config = tf.ConfigProto()\n#config.gpu_options.allow_growth = True\n#keras.backend.tensorflow_backend.set_session(tf.Session(config=config))\n\n\n     \ndef focal_loss(gamma=2.):            \n    def focal_loss_fixed(y_true, y_pred):\n        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n        return -K.sum( K.pow(1. - pt_1, gamma) * K.log(pt_1)) \n    return focal_loss_fixed\n\n\ndef Conv2d_BN(x, nb_filter,kernel_size, strides=(1,1), padding='same',name=None):  \n    if name is not None:  \n        bn_name = name + '_bn'  \n        conv_name = name + '_conv'  \n    else:  \n        bn_name = None  \n        conv_name = None  \n  \n    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,activation='relu',name=conv_name)(x)  \n    x = BatchNormalization(axis=3,name=bn_name)(x)  \n    return x  \n\ndef Conv_Block(inpt,nb_filter,kernel_size,strides=(1,1), with_conv_shortcut=False):  \n    x = Conv2d_BN(inpt,nb_filter=nb_filter[0],kernel_size=(1,1),strides=strides,padding='same')  \n    x = Conv2d_BN(x, nb_filter=nb_filter[1], kernel_size=(3,3), padding='same')  \n    x = Conv2d_BN(x, nb_filter=nb_filter[2], kernel_size=(1,1), padding='same')  \n    if with_conv_shortcut:  \n        shortcut = Conv2d_BN(inpt,nb_filter=nb_filter[2],strides=strides,kernel_size=kernel_size)  \n        x = add([x,shortcut])  \n        return x  \n    else:  \n        x = add([x,inpt])  \n        return x  \n\n\ndef channel_attention(input_feature, ratio=8):\n\t\n\tchannel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n\tchannel = input_feature.shape[channel_axis]\n\t\n\tshared_layer_one = Dense(channel//ratio,\n\t\t\t\t\t\t\t kernel_initializer='he_normal',\n\t\t\t\t\t\t\t activation = 'relu',\n\t\t\t\t\t\t\t use_bias=True,\n\t\t\t\t\t\t\t bias_initializer='zeros')\n\n\tshared_layer_two = Dense(channel,\n\t\t\t\t\t\t\t kernel_initializer='he_normal',\n\t\t\t\t\t\t\t use_bias=True,\n\t\t\t\t\t\t\t bias_initializer='zeros')\n\t\n\tavg_pool = GlobalAveragePooling2D()(input_feature)    \n\tavg_pool = Reshape((1,1,channel))(avg_pool)\n\tassert avg_pool.shape[1:] == (1,1,channel)\n\tavg_pool = shared_layer_one(avg_pool)\n\tassert avg_pool.shape[1:] == (1,1,channel//ratio)\n\tavg_pool = shared_layer_two(avg_pool)\n\tassert avg_pool.shape[1:] == (1,1,channel)\n\t\n\tmax_pool = GlobalMaxPooling2D()(input_feature)\n\tmax_pool = Reshape((1,1,channel))(max_pool)\n\tassert max_pool.shape[1:] == (1,1,channel)\n\tmax_pool = shared_layer_one(max_pool)\n\tassert max_pool.shape[1:] == (1,1,channel//ratio)\n\tmax_pool = shared_layer_two(max_pool)\n\tassert max_pool.shape[1:] == (1,1,channel)\n\t\n\tcbam_feature = Add()([avg_pool,max_pool])\n\tcbam_feature = Activation('hard_sigmoid')(cbam_feature)\n\t\n\tif K.image_data_format() == \"channels_first\":\n\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n\t\n\treturn multiply([input_feature, cbam_feature])\n\n\ndef spatial_attention(input_feature):\n\tkernel_size = 7\n\tif K.image_data_format() == \"channels_first\":\n\t\tchannel = input_feature.shape[1]\n\t\tcbam_feature = Permute((2,3,1))(input_feature)\n\telse:\n\t\tchannel = input_feature.shape[-1]\n\t\tcbam_feature = input_feature\n\t\n\tavg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n\tassert avg_pool.shape[-1] == 1\n\tmax_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n\tassert max_pool.shape[-1] == 1\n\tconcat = Concatenate(axis=3)([avg_pool, max_pool])\n\tassert concat.shape[-1] == 2\n\tcbam_feature = Conv2D(filters = 1,\n\t\t\t\t\tkernel_size=kernel_size,\n\t\t\t\t\tactivation = 'hard_sigmoid',\n\t\t\t\t\tstrides=1,\n\t\t\t\t\tpadding='same',\n\t\t\t\t\tkernel_initializer='he_normal',\n\t\t\t\t\tuse_bias=False)(concat)\n\tassert cbam_feature.shape[-1] == 1\n\t\n\tif K.image_data_format() == \"channels_first\":\n\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n\t\t\n\treturn multiply([input_feature, cbam_feature])\n\n\ndef cbam_block(cbam_feature,ratio=8):\n\tcbam_feature = channel_attention(cbam_feature, ratio)\n\tcbam_feature = spatial_attention(cbam_feature, )\n\treturn cbam_feature\n\n\nbatch_size = 64 \nepochs = epoch_4_test\n\nboard_name1 = '../working/log/stage1/' + now + '/'\nboard_name2 = '../working/log/stage2/' + now + '/'\n\nimg_size = (img_x, img_x)  \n#classes=list(range(1,5))\n#classes=['1','2','3','4']\nimport os\nimport glob\nnb_train_samples = len(glob.glob(train_dir + '/*/*.*'))  \nnb_validation_samples = len(glob.glob(validation_dir + '/*/*.*'))  \n\nclasses = sorted([o for o in os.listdir('../working/data/train_seg')])  \nprint(classes)\n\n\n#---------Attention embedded MobileNetV2--------------------------------------------------------------\n\n\nIMG_SHAPE=(img_x, img_x, 3)\n\n#base_model = keras.applications.MobileNetV2(input_shape=IMG_SHAPE,include_top=False, weights='imagenet')\n#weights='../working/cjd/01_rice_dete/obj_reco/checkpoint/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_img_x_no_top.h5')\n\n\n\n#for layer in base_model.layers:\n#    layer.trainable = False\n    \n\n#base_out = base_model.output\n\n#--------------------Soft attention module-------------------------------------------------------------- \n#ipts = base_out\n#residual = layers.Conv2D(1280, kernel_size = (1, 1), strides = (1, 1), padding = 'same')(ipts)\n#residual = layers.BatchNormalization(axis = -1)(residual)\n#cbam = cbam_block(residual)\n#base_out = layers.add([base_out, residual, cbam])\n#------------------------------------------------------------------------------------------------------------ \n\n#x = GlobalAveragePooling2D()(base_out)\n# \n\n# softmax\n#predictions = Dense(len(ont_hot_labels[0]), activation='softmax', kernel_regularizer =regularizers.l2(0.01) )(x)  #l1_reg\n#predictions = Dense(len(classes), activation='softmax', kernel_regularizer =regularizers.l2(0.01) )(x)  #l1_reg\n\n#model = Model(inputs=base_model.input, outputs=predictions)\n\n#model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics = ['accuracy'])  #rmsprop\n#model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adadelta(), metrics=['accuracy'])\n\n\n\n#train_datagen = ImageDataGenerator(validation_split=0.2)\ntrain_datagen = ImageDataGenerator()\n\ntrain_datagen.mean = np.array([103.939, 116.779, 123.68], dtype=np.float32).reshape((3, 1, 1))  # remove imagenet BGR mean value\n#train_generator = train_datagen.flow(train_data, train_label, target_size=img_size, classes=classes)\ntrain_generator = train_datagen.flow(train_data, train_label)\n\nvalidation_datagen = ImageDataGenerator()\nvalidation_datagen.mean = np.array([103.939, 116.779, 123.68], dtype=np.float32).reshape((3, 1, 1))\ntest_dir = '../working/data/test_seg/'  \n#val_generator = validation_datagen.flow(test_data, test_label, target_size=img_size, classes=classes)\nval_generator = validation_datagen.flow(test_data, test_label)\n\nval2_datagen = ImageDataGenerator()\nval2_datagen.mean = np.array([103.939, 116.779, 123.68], dtype=np.float32).reshape((3, 1, 1))\ntest_dir = '../working/data/test_seg/'  \n#val2_generator = val2_datagen.flow(val_data, val_label, target_size=img_size, classes=classes)\nval2_generator = val2_datagen.flow(val_data, val_label)\n\n\n#model_checkpoint1 = ModelCheckpoint(filepath=MODEL_INIT, save_best_only=True, monitor='val_accuracy', mode='max')\n#model_checkpoint1 = ModelCheckpoint(filepath=MODEL_INIT, monitor='val_accuracy', save_best_only=True, monitor='val_accuracy', mode='max')\n#model_checkpoint1 = ModelCheckpoint(filepath=MODEL_INIT, monitor='val_accuracy', save_best_only=True, mode='max')\nboard1 = TensorBoard(log_dir=board_name1,\n                     histogram_freq=0,\n                     write_graph=True,\n                     write_images=True)\n#callback_list1 = [model_checkpoint1, board1] \n\n\n#MODEL_INIT = '../working/log/init_model.h5'\n#MODEL_PATH = '../working/log/tst_model.h5'\n#callbacks1 = [ModelCheckpoint('init_model.hdf5', save_best_only=True), TensorBoard(log_dir=board_name1, histogram_freq=0,write_graph=True, write_images=True)]\ncallbacks2 = [ModelCheckpoint('init_model.h5', verbose=1, save_best_only=True, mode='min'), TensorBoard(log_dir=board_name1, histogram_freq=0,write_graph=True, write_images=True)]\n\n'''\nmodel.fit_generator(train_generator, steps_per_epoch=nb_train_samples / float(batch_size),\n                           epochs = epochs,\n                           validation_steps=nb_validation_samples / float(batch_size),\n                           validation_data=val_generator,\n                           callbacks=callbacks1, verbose=1)\n\n\n                           \nmodel.fit(x=train_generator, steps_per_epoch=nb_train_samples / float(batch_size),\n                           epochs = epochs,\n                           validation_steps=nb_validation_samples / float(batch_size),\n                           validation_data=val_generator,\n                           callbacks=[ModelCheckpoint(filepath=MODEL_INIT, monitor='val_accuracy', save_best_only=True, mode='max')], verbose=2)\n\n'''\n","metadata":{"execution":{"iopub.status.busy":"2022-05-12T22:52:32.172975Z","iopub.execute_input":"2022-05-12T22:52:32.173260Z","iopub.status.idle":"2022-05-12T22:52:32.298472Z","shell.execute_reply.started":"2022-05-12T22:52:32.173217Z","shell.execute_reply":"2022-05-12T22:52:32.297780Z"},"trusted":true},"execution_count":111,"outputs":[{"name":"stdout","text":"/kaggle/working\n3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \n[GCC 9.4.0]\n['idc-minus', 'idc-plus']\n","output_type":"stream"},{"execution_count":111,"output_type":"execute_result","data":{"text/plain":"\"\\nmodel.fit_generator(train_generator, steps_per_epoch=nb_train_samples / float(batch_size),\\n                           epochs = epochs,\\n                           validation_steps=nb_validation_samples / float(batch_size),\\n                           validation_data=val_generator,\\n                           callbacks=callbacks1, verbose=1)\\n\\n\\n                           \\nmodel.fit(x=train_generator, steps_per_epoch=nb_train_samples / float(batch_size),\\n                           epochs = epochs,\\n                           validation_steps=nb_validation_samples / float(batch_size),\\n                           validation_data=val_generator,\\n                           callbacks=[ModelCheckpoint(filepath=MODEL_INIT, monitor='val_accuracy', save_best_only=True, mode='max')], verbose=2)\\n\\n\""},"metadata":{}}]},{"cell_type":"code","source":"#---------------1-st stage---------------------------------------------\n#model_checkpoint2 = ModelCheckpoint(filepath=MODEL_PATH,  monitor='val_accuracy')\n#model_checkpoint2 = ModelCheckpoint('tst_model.h5',  monitor='val_accuracy', save_best_only=True, mode='max')\n#board2 = TensorBoard(log_dir=board_name2, histogram_freq=0, write_graph=True, write_images=True)\n#callback_list2 = [model_checkpoint2, board2]\n#callbacks2 = [EarlyStopping(monitor='val_loss', patience=5, verbose=2), ModelCheckpoint('test_model.hdf5', save_best_only=True), TensorBoard(log_dir=board_name2,\n#                     histogram_freq=0,\n#                     write_graph=True,\n#                     write_images=True)]\ncallbacks1 = [ModelCheckpoint('init_model1.h5', verbose=1, save_best_only=True, mode='min'), TensorBoard(log_dir=board_name2,\n                     histogram_freq=0,\n                     write_graph=True,\n                     write_images=True)]\n\n#model.load_weights(MODEL_INIT)\nfor model1 in model.layers:\n    model1.trainable = True\n#fine_tune_at = 50\n#for layer in model.layers[:fine_tune_at]:\n#    layer.trainable = False\n\n\n#model.compile(optimizer=optimizers.Adam(), loss =[focal_loss(gamma=2)], metrics=['accuracy']) #loss='categorical_crossentropy',\nmodel.compile(optimizer=optimizers.SGD(lr=0.0001), loss = [focal_loss(gamma=2)], metrics=['accuracy']) #loss='categorical_crossentropy',\n#model.compile(optimizer=optimizers.Adadelta(), loss = [focal_loss(gamma=2)], metrics=['accuracy']) #loss='categorical_crossentropy',\n\nhistory1=model.fit_generator(train_generator, steps_per_epoch=nb_train_samples / float(batch_size), epochs=epochs, validation_data=val_generator, validation_steps=nb_validation_samples / float(batch_size), callbacks=callbacks1, verbose=2)\n\n\n\nfrom contextlib import redirect_stdout   \nwith open('./model_summary.txt', 'w') as f:\n    with redirect_stdout(f):\n        model.summary(line_length=200,positions=[0.30,0.60,0.7,1.0])\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-12T22:52:32.299911Z","iopub.execute_input":"2022-05-12T22:52:32.300233Z","iopub.status.idle":"2022-05-12T23:21:59.886526Z","shell.execute_reply.started":"2022-05-12T22:52:32.300198Z","shell.execute_reply":"2022-05-12T23:21:59.885653Z"},"trusted":true},"execution_count":112,"outputs":[{"name":"stdout","text":"Epoch 1/30\n - 61s - loss: 11.5266 - acc: 0.5375 - val_loss: 10.0946 - val_acc: 0.5312\n\nEpoch 00001: val_loss improved from inf to 10.09464, saving model to init_model1.h5\nEpoch 2/30\n - 50s - loss: 3.9990 - acc: 0.5630 - val_loss: 4.2758 - val_acc: 0.6875\n\nEpoch 00002: val_loss improved from 10.09464 to 4.27582, saving model to init_model1.h5\nEpoch 3/30\n - 51s - loss: 2.3323 - acc: 0.6000 - val_loss: 2.8517 - val_acc: 0.4000\n\nEpoch 00003: val_loss improved from 4.27582 to 2.85174, saving model to init_model1.h5\nEpoch 4/30\n - 50s - loss: 0.8286 - acc: 0.7735 - val_loss: 2.1247 - val_acc: 0.7500\n\nEpoch 00004: val_loss improved from 2.85174 to 2.12474, saving model to init_model1.h5\nEpoch 5/30\n - 49s - loss: 0.6924 - acc: 0.7150 - val_loss: 5.1797 - val_acc: 0.6562\n\nEpoch 00005: val_loss did not improve from 2.12474\nEpoch 6/30\n - 52s - loss: 0.6890 - acc: 0.7750 - val_loss: 1.1566 - val_acc: 0.5000\n\nEpoch 00006: val_loss improved from 2.12474 to 1.15662, saving model to init_model1.h5\nEpoch 7/30\n - 51s - loss: 0.6526 - acc: 0.7815 - val_loss: 2.2259 - val_acc: 0.4062\n\nEpoch 00007: val_loss did not improve from 1.15662\nEpoch 8/30\n - 49s - loss: 0.3813 - acc: 0.7689 - val_loss: 2.4826 - val_acc: 0.6562\n\nEpoch 00008: val_loss did not improve from 1.15662\nEpoch 9/30\n - 51s - loss: 0.3332 - acc: 0.7500 - val_loss: 2.9904 - val_acc: 0.7500\n\nEpoch 00009: val_loss did not improve from 1.15662\nEpoch 10/30\n - 52s - loss: 0.4310 - acc: 0.7313 - val_loss: 2.0880 - val_acc: 0.5938\n\nEpoch 00010: val_loss did not improve from 1.15662\nEpoch 11/30\n - 50s - loss: 0.3235 - acc: 0.7959 - val_loss: 4.6027 - val_acc: 0.5938\n\nEpoch 00011: val_loss did not improve from 1.15662\nEpoch 12/30\n - 52s - loss: 0.3260 - acc: 0.7750 - val_loss: 0.9424 - val_acc: 0.6000\n\nEpoch 00012: val_loss improved from 1.15662 to 0.94241, saving model to init_model1.h5\nEpoch 13/30\n - 51s - loss: 0.2579 - acc: 0.7454 - val_loss: 3.6379 - val_acc: 0.5000\n\nEpoch 00013: val_loss did not improve from 0.94241\nEpoch 14/30\n - 53s - loss: 0.2452 - acc: 0.8063 - val_loss: 2.8391 - val_acc: 0.6875\n\nEpoch 00014: val_loss did not improve from 0.94241\nEpoch 15/30\n - 49s - loss: 0.2274 - acc: 0.8102 - val_loss: 0.8977 - val_acc: 0.6000\n\nEpoch 00015: val_loss improved from 0.94241 to 0.89773, saving model to init_model1.h5\nEpoch 16/30\n - 50s - loss: 0.2514 - acc: 0.7683 - val_loss: 1.6281 - val_acc: 0.7188\n\nEpoch 00016: val_loss did not improve from 0.89773\nEpoch 17/30\n - 50s - loss: 0.2635 - acc: 0.7976 - val_loss: 2.8367 - val_acc: 0.5625\n\nEpoch 00017: val_loss did not improve from 0.89773\nEpoch 18/30\n - 52s - loss: 0.1929 - acc: 0.8125 - val_loss: 1.0163 - val_acc: 0.6000\n\nEpoch 00018: val_loss did not improve from 0.89773\nEpoch 19/30\n - 49s - loss: 0.1499 - acc: 0.8354 - val_loss: 1.4557 - val_acc: 0.7188\n\nEpoch 00019: val_loss did not improve from 0.89773\nEpoch 20/30\n - 54s - loss: 0.1870 - acc: 0.8125 - val_loss: 3.4502 - val_acc: 0.5938\n\nEpoch 00020: val_loss did not improve from 0.89773\nEpoch 21/30\n - 49s - loss: 0.1651 - acc: 0.8354 - val_loss: 0.7552 - val_acc: 0.7000\n\nEpoch 00021: val_loss improved from 0.89773 to 0.75518, saving model to init_model1.h5\nEpoch 22/30\n - 53s - loss: 0.1721 - acc: 0.7875 - val_loss: 2.7205 - val_acc: 0.6250\n\nEpoch 00022: val_loss did not improve from 0.75518\nEpoch 23/30\n - 49s - loss: 0.1297 - acc: 0.8039 - val_loss: 1.1279 - val_acc: 0.7188\n\nEpoch 00023: val_loss did not improve from 0.75518\nEpoch 24/30\n - 49s - loss: 0.1442 - acc: 0.7930 - val_loss: 0.8272 - val_acc: 0.6500\n\nEpoch 00024: val_loss did not improve from 0.75518\nEpoch 25/30\n - 53s - loss: 0.1365 - acc: 0.8250 - val_loss: 3.6253 - val_acc: 0.7188\n\nEpoch 00025: val_loss did not improve from 0.75518\nEpoch 26/30\n - 52s - loss: 0.1199 - acc: 0.8000 - val_loss: 1.3164 - val_acc: 0.6562\n\nEpoch 00026: val_loss did not improve from 0.75518\nEpoch 27/30\n - 49s - loss: 0.1161 - acc: 0.8354 - val_loss: 0.5950 - val_acc: 0.7000\n\nEpoch 00027: val_loss improved from 0.75518 to 0.59501, saving model to init_model1.h5\nEpoch 28/30\n - 49s - loss: 0.1254 - acc: 0.7913 - val_loss: 1.4957 - val_acc: 0.6562\n\nEpoch 00028: val_loss did not improve from 0.59501\nEpoch 29/30\n - 53s - loss: 0.1195 - acc: 0.8750 - val_loss: 3.6966 - val_acc: 0.7188\n\nEpoch 00029: val_loss did not improve from 0.59501\nEpoch 30/30\n - 49s - loss: 0.0973 - acc: 0.8165 - val_loss: 0.9127 - val_acc: 0.5500\n\nEpoch 00030: val_loss did not improve from 0.59501\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-------------2nd stage------------------------------------------------------------\nhistory2=model.fit_generator(train_generator, steps_per_epoch=nb_train_samples / float(batch_size),\n                           epochs = epochs,\n                           validation_steps=nb_validation_samples / float(batch_size),\n                           validation_data=val_generator,\n                           callbacks=callbacks2, verbose=1)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-12T23:21:59.890947Z","iopub.execute_input":"2022-05-12T23:21:59.891700Z","iopub.status.idle":"2022-05-12T23:47:37.178333Z","shell.execute_reply.started":"2022-05-12T23:21:59.891664Z","shell.execute_reply":"2022-05-12T23:47:37.176465Z"},"trusted":true},"execution_count":113,"outputs":[{"name":"stdout","text":"Epoch 1/30\n5/4 [==================================] - 51s 10s/step - loss: 0.1057 - acc: 0.8056 - val_loss: 5.1908 - val_acc: 0.6562\n\nEpoch 00001: val_loss improved from inf to 5.19081, saving model to init_model.h5\nEpoch 2/30\n5/4 [==================================] - 50s 10s/step - loss: 0.1125 - acc: 0.8165 - val_loss: 0.9384 - val_acc: 0.7188\n\nEpoch 00002: val_loss improved from 5.19081 to 0.93842, saving model to init_model.h5\nEpoch 3/30\n5/4 [==================================] - 52s 10s/step - loss: 0.1473 - acc: 0.8063 - val_loss: 0.2867 - val_acc: 0.7500\n\nEpoch 00003: val_loss improved from 0.93842 to 0.28671, saving model to init_model.h5\nEpoch 4/30\n5/4 [==================================] - 52s 10s/step - loss: 0.0952 - acc: 0.8438 - val_loss: 1.4449 - val_acc: 0.6875\n\nEpoch 00004: val_loss did not improve from 0.28671\nEpoch 5/30\n5/4 [==================================] - 53s 11s/step - loss: 0.1235 - acc: 0.8125 - val_loss: 1.1767 - val_acc: 0.7188\n\nEpoch 00005: val_loss did not improve from 0.28671\nEpoch 6/30\n5/4 [==================================] - 49s 10s/step - loss: 0.0941 - acc: 0.8607 - val_loss: 3.2649 - val_acc: 0.7000\n\nEpoch 00006: val_loss did not improve from 0.28671\nEpoch 7/30\n5/4 [==================================] - 50s 10s/step - loss: 0.1328 - acc: 0.8480 - val_loss: 0.5296 - val_acc: 0.7812\n\nEpoch 00007: val_loss did not improve from 0.28671\nEpoch 8/30\n5/4 [==================================] - 52s 10s/step - loss: 0.1382 - acc: 0.8438 - val_loss: 2.4874 - val_acc: 0.7188\n\nEpoch 00008: val_loss did not improve from 0.28671\nEpoch 9/30\n5/4 [==================================] - 49s 10s/step - loss: 0.1604 - acc: 0.8337 - val_loss: 0.4145 - val_acc: 0.7000\n\nEpoch 00009: val_loss did not improve from 0.28671\nEpoch 10/30\n5/4 [==================================] - 53s 11s/step - loss: 0.1168 - acc: 0.8312 - val_loss: 3.2541 - val_acc: 0.8125\n\nEpoch 00010: val_loss did not improve from 0.28671\nEpoch 11/30\n5/4 [==================================] - 47s 9s/step - loss: 0.1024 - acc: 0.8611 - val_loss: 0.6877 - val_acc: 0.6875\n\nEpoch 00011: val_loss did not improve from 0.28671\nEpoch 12/30\n5/4 [==================================] - 51s 10s/step - loss: 0.0991 - acc: 0.8187 - val_loss: 0.9837 - val_acc: 0.6000\n\nEpoch 00012: val_loss did not improve from 0.28671\nEpoch 13/30\n5/4 [==================================] - 53s 11s/step - loss: 0.0888 - acc: 0.8187 - val_loss: 1.0263 - val_acc: 0.8125\n\nEpoch 00013: val_loss did not improve from 0.28671\nEpoch 14/30\n5/4 [==================================] - 53s 11s/step - loss: 0.1069 - acc: 0.8000 - val_loss: 3.1446 - val_acc: 0.6250\n\nEpoch 00014: val_loss did not improve from 0.28671\nEpoch 15/30\n5/4 [==================================] - 46s 9s/step - loss: 0.1097 - acc: 0.8304 - val_loss: 0.3963 - val_acc: 0.6500\n\nEpoch 00015: val_loss did not improve from 0.28671\nEpoch 16/30\n5/4 [==================================] - 52s 10s/step - loss: 0.0808 - acc: 0.8750 - val_loss: 0.8796 - val_acc: 0.7812\n\nEpoch 00016: val_loss did not improve from 0.28671\nEpoch 17/30\n5/4 [==================================] - 52s 10s/step - loss: 0.0785 - acc: 0.8750 - val_loss: 2.9120 - val_acc: 0.6250\n\nEpoch 00017: val_loss did not improve from 0.28671\nEpoch 18/30\n5/4 [==================================] - 49s 10s/step - loss: 0.0763 - acc: 0.8687 - val_loss: 0.4999 - val_acc: 0.8000\n\nEpoch 00018: val_loss did not improve from 0.28671\nEpoch 19/30\n5/4 [==================================] - 52s 10s/step - loss: 0.1025 - acc: 0.7938 - val_loss: 1.1530 - val_acc: 0.7188\n\nEpoch 00019: val_loss did not improve from 0.28671\nEpoch 20/30\n5/4 [==================================] - 50s 10s/step - loss: 0.0786 - acc: 0.8211 - val_loss: 2.9819 - val_acc: 0.6562\n\nEpoch 00020: val_loss did not improve from 0.28671\nEpoch 21/30\n5/4 [==================================] - 48s 10s/step - loss: 0.0960 - acc: 0.8228 - val_loss: 0.3661 - val_acc: 0.8000\n\nEpoch 00021: val_loss did not improve from 0.28671\nEpoch 22/30\n5/4 [==================================] - 50s 10s/step - loss: 0.0871 - acc: 0.8480 - val_loss: 3.1908 - val_acc: 0.6875\n\nEpoch 00022: val_loss did not improve from 0.28671\nEpoch 23/30\n5/4 [==================================] - 52s 10s/step - loss: 0.0759 - acc: 0.8375 - val_loss: 0.5977 - val_acc: 0.6875\n\nEpoch 00023: val_loss did not improve from 0.28671\nEpoch 24/30\n5/4 [==================================] - 51s 10s/step - loss: 0.0799 - acc: 0.8375 - val_loss: 0.5992 - val_acc: 0.8500\n\nEpoch 00024: val_loss did not improve from 0.28671\nEpoch 25/30\n5/4 [==================================] - 49s 10s/step - loss: 0.0896 - acc: 0.8211 - val_loss: 3.9384 - val_acc: 0.6875\n\nEpoch 00025: val_loss did not improve from 0.28671\nEpoch 26/30\n5/4 [==================================] - 50s 10s/step - loss: 0.0808 - acc: 0.8750 - val_loss: 0.4334 - val_acc: 0.6875\n\nEpoch 00026: val_loss did not improve from 0.28671\nEpoch 27/30\n5/4 [==================================] - 51s 10s/step - loss: 0.1009 - acc: 0.8250 - val_loss: 0.2874 - val_acc: 0.8000\n\nEpoch 00027: val_loss did not improve from 0.28671\nEpoch 28/30\n5/4 [==================================] - 51s 10s/step - loss: 0.0747 - acc: 0.8389 - val_loss: 1.1074 - val_acc: 0.5938\n\nEpoch 00028: val_loss did not improve from 0.28671\nEpoch 29/30\n5/4 [==================================] - 53s 11s/step - loss: 0.0699 - acc: 0.9000 - val_loss: 2.1632 - val_acc: 0.7500\n\nEpoch 00029: val_loss did not improve from 0.28671\nEpoch 30/30\n5/4 [==================================] - 48s 10s/step - loss: 0.0763 - acc: 0.8939 - val_loss: 0.2616 - val_acc: 0.9000\n\nEpoch 00030: val_loss improved from 0.28671 to 0.26164, saving model to init_model.h5\n","output_type":"stream"},{"execution_count":113,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7efeaa92f350>"},"metadata":{}}]},{"cell_type":"code","source":"model.load_weights('./init_model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-05-12T23:47:37.179776Z","iopub.execute_input":"2022-05-12T23:47:37.180179Z","iopub.status.idle":"2022-05-12T23:47:43.291740Z","shell.execute_reply.started":"2022-05-12T23:47:37.180113Z","shell.execute_reply":"2022-05-12T23:47:43.290987Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"#---------------3-rd stage---------------------------------------------\n#model_checkpoint2 = ModelCheckpoint(filepath=MODEL_PATH,  monitor='val_accuracy')\n#model_checkpoint2 = ModelCheckpoint('tst_model.h5',  monitor='val_accuracy', save_best_only=True, mode='max')\n#board2 = TensorBoard(log_dir=board_name2, histogram_freq=0, write_graph=True, write_images=True)\n#callback_list2 = [model_checkpoint2, board2]\n#callbacks2 = [EarlyStopping(monitor='val_loss', patience=5, verbose=2), ModelCheckpoint('test_model.hdf5', save_best_only=True), TensorBoard(log_dir=board_name2,\n#                     histogram_freq=0,\n#                     write_graph=True,\n#                     write_images=True)]\ncallbacks3 = [ModelCheckpoint('test_model.h5', verbose=1, save_best_only=True, mode='min'), TensorBoard(log_dir=board_name2,\n                     histogram_freq=0,\n                     write_graph=True,\n                     write_images=True)]\n\n#model.load_weights(MODEL_INIT)\nfor model1 in model.layers:\n    model1.trainable = True\n#fine_tune_at = 50\n#for layer in model.layers[:fine_tune_at]:\n#    layer.trainable = False\n\n\n#model.compile(optimizer=optimizers.Adam(), loss =[focal_loss(gamma=2)], metrics=['accuracy']) #loss='categorical_crossentropy',\nmodel.compile(optimizer=optimizers.SGD(lr=0.0001), loss = [focal_loss(gamma=2)], metrics=['accuracy']) #loss='categorical_crossentropy',\n#model.compile(optimizer=optimizers.Adadelta(), loss = [focal_loss(gamma=2)], metrics=['accuracy']) #loss='categorical_crossentropy',\n\nhistory3=model.fit_generator(train_generator, steps_per_epoch=nb_train_samples / float(batch_size), epochs=epochs, validation_data=val_generator, validation_steps=nb_validation_samples / float(batch_size), callbacks=callbacks3, verbose=2)\n\n\n\nfrom contextlib import redirect_stdout   \nwith open('./model_summary.txt', 'w') as f:\n    with redirect_stdout(f):\n        model.summary(line_length=200,positions=[0.30,0.60,0.7,1.0])\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-12T23:47:43.293656Z","iopub.execute_input":"2022-05-12T23:47:43.293908Z","iopub.status.idle":"2022-05-13T00:13:37.259511Z","shell.execute_reply.started":"2022-05-12T23:47:43.293874Z","shell.execute_reply":"2022-05-13T00:13:37.258751Z"},"trusted":true},"execution_count":115,"outputs":[{"name":"stdout","text":"Epoch 1/30\n - 60s - loss: 0.0623 - acc: 0.9062 - val_loss: 1.8210 - val_acc: 0.7812\n\nEpoch 00001: val_loss improved from inf to 1.82096, saving model to test_model.h5\nEpoch 2/30\n - 50s - loss: 0.0757 - acc: 0.8561 - val_loss: 1.1693 - val_acc: 0.6562\n\nEpoch 00002: val_loss improved from 1.82096 to 1.16931, saving model to test_model.h5\nEpoch 3/30\n - 48s - loss: 0.0850 - acc: 0.8561 - val_loss: 0.2369 - val_acc: 0.6500\n\nEpoch 00003: val_loss improved from 1.16931 to 0.23685, saving model to test_model.h5\nEpoch 4/30\n - 52s - loss: 0.0696 - acc: 0.8750 - val_loss: 0.6913 - val_acc: 0.8125\n\nEpoch 00004: val_loss did not improve from 0.23685\nEpoch 5/30\n - 50s - loss: 0.0661 - acc: 0.8635 - val_loss: 0.5687 - val_acc: 0.6875\n\nEpoch 00005: val_loss did not improve from 0.23685\nEpoch 6/30\n - 51s - loss: 0.0677 - acc: 0.9125 - val_loss: 1.8344 - val_acc: 0.6500\n\nEpoch 00006: val_loss did not improve from 0.23685\nEpoch 7/30\n - 50s - loss: 0.0647 - acc: 0.8372 - val_loss: 0.7990 - val_acc: 0.8125\n\nEpoch 00007: val_loss did not improve from 0.23685\nEpoch 8/30\n - 50s - loss: 0.0764 - acc: 0.8618 - val_loss: 1.6730 - val_acc: 0.6250\n\nEpoch 00008: val_loss did not improve from 0.23685\nEpoch 9/30\n - 50s - loss: 0.0750 - acc: 0.8688 - val_loss: 0.5748 - val_acc: 0.7500\n\nEpoch 00009: val_loss did not improve from 0.23685\nEpoch 10/30\n - 50s - loss: 0.0687 - acc: 0.8435 - val_loss: 0.6751 - val_acc: 0.7500\n\nEpoch 00010: val_loss did not improve from 0.23685\nEpoch 11/30\n - 52s - loss: 0.0692 - acc: 0.8812 - val_loss: 2.1227 - val_acc: 0.5625\n\nEpoch 00011: val_loss did not improve from 0.23685\nEpoch 12/30\n - 48s - loss: 0.0732 - acc: 0.8554 - val_loss: 0.1631 - val_acc: 0.9500\n\nEpoch 00012: val_loss improved from 0.23685 to 0.16306, saving model to test_model.h5\nEpoch 13/30\n - 52s - loss: 0.0657 - acc: 0.8563 - val_loss: 0.8174 - val_acc: 0.6562\n\nEpoch 00013: val_loss did not improve from 0.16306\nEpoch 14/30\n - 49s - loss: 0.0662 - acc: 0.8670 - val_loss: 1.9806 - val_acc: 0.8125\n\nEpoch 00014: val_loss did not improve from 0.16306\nEpoch 15/30\n - 49s - loss: 0.0638 - acc: 0.8670 - val_loss: 0.2418 - val_acc: 0.6500\n\nEpoch 00015: val_loss did not improve from 0.16306\nEpoch 16/30\n - 52s - loss: 0.0695 - acc: 0.8250 - val_loss: 0.4662 - val_acc: 0.7500\n\nEpoch 00016: val_loss did not improve from 0.16306\nEpoch 17/30\n - 52s - loss: 0.0656 - acc: 0.8312 - val_loss: 2.2621 - val_acc: 0.7188\n\nEpoch 00017: val_loss did not improve from 0.16306\nEpoch 18/30\n - 47s - loss: 0.0672 - acc: 0.8974 - val_loss: 0.1800 - val_acc: 0.7500\n\nEpoch 00018: val_loss did not improve from 0.16306\nEpoch 19/30\n - 49s - loss: 0.0750 - acc: 0.8246 - val_loss: 2.3766 - val_acc: 0.6875\n\nEpoch 00019: val_loss did not improve from 0.16306\nEpoch 20/30\n - 51s - loss: 0.0602 - acc: 0.8875 - val_loss: 0.3541 - val_acc: 0.8438\n\nEpoch 00020: val_loss did not improve from 0.16306\nEpoch 21/30\n - 49s - loss: 0.0649 - acc: 0.8802 - val_loss: 0.2645 - val_acc: 0.6000\n\nEpoch 00021: val_loss did not improve from 0.16306\nEpoch 22/30\n - 51s - loss: 0.0755 - acc: 0.8812 - val_loss: 0.4304 - val_acc: 0.7812\n\nEpoch 00022: val_loss did not improve from 0.16306\nEpoch 23/30\n - 53s - loss: 0.0613 - acc: 0.9062 - val_loss: 1.0203 - val_acc: 0.6250\n\nEpoch 00023: val_loss did not improve from 0.16306\nEpoch 24/30\n - 48s - loss: 0.0854 - acc: 0.8354 - val_loss: 1.9327 - val_acc: 0.7500\n\nEpoch 00024: val_loss did not improve from 0.16306\nEpoch 25/30\n - 49s - loss: 0.1852 - acc: 0.8337 - val_loss: 0.4529 - val_acc: 0.7500\n\nEpoch 00025: val_loss did not improve from 0.16306\nEpoch 26/30\n - 49s - loss: 0.0697 - acc: 0.8463 - val_loss: 1.4587 - val_acc: 0.7500\n\nEpoch 00026: val_loss did not improve from 0.16306\nEpoch 27/30\n - 51s - loss: 0.0598 - acc: 0.8937 - val_loss: 2.8591 - val_acc: 0.6500\n\nEpoch 00027: val_loss did not improve from 0.16306\nEpoch 28/30\n - 50s - loss: 0.0610 - acc: 0.8572 - val_loss: 1.1801 - val_acc: 0.7500\n\nEpoch 00028: val_loss did not improve from 0.16306\nEpoch 29/30\n - 51s - loss: 0.0610 - acc: 0.8859 - val_loss: 0.3559 - val_acc: 0.8125\n\nEpoch 00029: val_loss did not improve from 0.16306\nEpoch 30/30\n - 51s - loss: 0.0693 - acc: 0.8563 - val_loss: 2.9566 - val_acc: 0.5500\n\nEpoch 00030: val_loss did not improve from 0.16306\n","output_type":"stream"}]},{"cell_type":"code","source":"\nimport seaborn as sns\nfrom sklearn.metrics import f1_score, roc_auc_score, cohen_kappa_score, precision_score, recall_score, accuracy_score, confusion_matrix\n\ndef test_2_final_model(model, train_generator, test_generator, val_generator, y_train, y_test, y_val, class_labels):\n    \n    # BS = 16\n    ##results = dict()\n    \n    # n = len(testy)// BS\n\n    # testX = testX[:BS*n]\n    # testy = testy[:BS*n]\n\n    ##print('Predicting test data')\n    ##test_start_time = datetime.now()\n    y_pred_test_original = model.predict_generator(test_generator,verbose=1)\n    # y_pred = (y_pred_test>0.5).astype('int')\n\n    y_pred_test = np.argmax(y_pred_test_original, axis = 1)\n \n    y_test = y_test.astype(int) # sparse form not categorical\n    y_train = y_train.astype(int) # sparse form not categorical\n    y_val = y_val.astype(int) # sparse form not categorical\n    # y_test = np.argmax(testy, axis= 1)\n    #y_test = np.argmax(testy, axis=-1)\n    \n    ##test_end_time = datetime.now()\n    ##print('Done \\n \\n')\n    ##results['testing_time'] = test_end_time - test_start_time\n    ##print('testing time(HH:MM:SS:ms) - {}\\n\\n'.format(results['testing_time']))\n    ##results['predicted'] = y_pred_test\n\n\n    # balanced_accuracy\n    from sklearn.metrics import balanced_accuracy_score\n    ##balanced_accuracy = balanced_accuracy_score(y_true=y_test, y_pred=y_pred_test)\n    ##print('---------------------')\n    ##print('| Balanced Accuracy  |')\n    ##print('---------------------')\n    ##print('\\n    {}\\n\\n'.format(balanced_accuracy))\n\n    \n    # calculate overall accuracty of the model\n    ##accuracy = metrics.accuracy_score(y_true=y_test, y_pred=y_pred_test)\n    # store accuracy in results\n    ##results['accuracy'] = accuracy\n    ##print('---------------------')\n    ##print('|      Accuracy      |')\n    ##print('---------------------')\n    ##print('\\n    {}\\n\\n'.format(accuracy))\n    \n\n    # get classification report\n    ##print('-------------------------')\n    ##print('| Classifiction Report |')\n    ##print('-------------------------')\n    ##classification_report = metrics.classification_report(y_test, y_pred_test)\n    # store report in results\n    ##results['classification_report'] = classification_report\n    ##print(classification_report)\n    \n    \n    \n    # confusion matrix\n    ##cm = metrics.confusion_matrix(y_test, y_pred_test)\n    ##results['confusion_matrix'] = cm\n    ##if print_cm: \n    ##    print('--------------------')\n    ##    print('| Confusion Matrix |')\n    ##    print('--------------------')\n    ##    print('\\n {}'.format(cm))\n        \n    # plot confusin matrix\n    ##plt.figure(figsize=(6,4))\n    ##plt.grid(b=False)\n    ##plot_confusion_matrix(cm, classes=class_labels, normalize=True, title='Normalized confusion matrix')\n    ##plt.show()\n    \n\n    \n    # add the trained  model to the results\n    ##results['model'] = model\n    ##print(\"calculate other score\")\n    ##print(\"predicting validation data\")\n\n    #calculate other score\n    y_pred_val_original = model.predict_generator(val_generator,verbose=1)\n    # y_pred = (y_pred_val>0.5).astype('int')\n\n    y_pred_val = np.argmax(y_pred_val_original, axis = 1)\n    # y_val = np.argmax(valy, axis= 1)\n    #y_val = np.argmax(valy, axis=-1)\n    print(\"predicting test data\")\n    y_pred_train_original = model.predict_generator(train_generator,verbose=1)\n    # y_pred = (y_pred_train>0.5).astype('int')\n\n    y_pred_train = np.argmax(y_pred_train_original, axis = 1)\n    # y_train = np.argmax(trainy, axis= 1)\n    #y_train = np.argmax(trainy, axis=-1)\n    \n    print(\"Train accuracy Score------------>\")\n    print (\"{0:.3f}\".format(accuracy_score(y_train, y_pred_train)*100), \"%\")\n    \n    print(\"Val accuracy Score--------->\")\n    \n    print(\"{0:.3f}\".format(accuracy_score(y_val, y_pred_val)*100), \"%\")\n    \n\n    \n  \n    print(\"Test accuracy Score--------->\")\n    print(\"{0:.3f}\".format(accuracy_score(y_test, y_pred_test)*100), \"%\")\n    \n    print(\"F1 Score--------------->\")\n    print(\"{0:.3f}\".format(f1_score(y_test, y_pred_test, average = 'weighted')*100), \"%\")\n    \n    print(\"Cohen Kappa Score------------->\")\n    print(\"{0:.3f}\".format(cohen_kappa_score(y_test, y_pred_test)*100), \"%\")\n    \n    print(\"Recall-------------->\")\n    print(\"{0:.3f}\".format(recall_score(y_test, y_pred_test, average = 'weighted')*100), \"%\")\n    \n    print(\"Precision-------------->\")\n    print(\"{0:.3f}\".format(precision_score(y_test, y_pred_test, average = 'weighted')*100), \"%\")\n    \n    cf_matrix_test = confusion_matrix(y_test, y_pred_test)\n    cf_matrix_val = confusion_matrix(y_val, y_pred_val)\n    \n    plt.figure(figsize = (12, 6))\n    plt.subplot(121)\n    sns.heatmap(cf_matrix_val, annot=True, cmap='Blues')\n    plt.title(\"Val Confusion matrix\")\n    \n    plt.subplot(122)\n    sns.heatmap(cf_matrix_test, annot=True, cmap='Blues')\n    plt.title(\"Test Confusion matrix\")\n    \n    plt.show()\n    \n    \n    return","metadata":{"execution":{"iopub.status.busy":"2022-05-13T00:13:37.262115Z","iopub.execute_input":"2022-05-13T00:13:37.262322Z","iopub.status.idle":"2022-05-13T00:13:37.278287Z","shell.execute_reply.started":"2022-05-13T00:13:37.262297Z","shell.execute_reply":"2022-05-13T00:13:37.277396Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"#MODEL_PATH = './test_model.hdf5'\nfrom keras.models import load_model\n#best_model = load_model('./test_model.h5')\nbest_model = load_model('./test_model.h5', compile=False)\n#best_model = load_model(\"./test_model.h5\", custom_objects={'focal_loss_fixed': focal_loss()})","metadata":{"execution":{"iopub.status.busy":"2022-05-13T00:13:37.279649Z","iopub.execute_input":"2022-05-13T00:13:37.279911Z","iopub.status.idle":"2022-05-13T00:14:01.988275Z","shell.execute_reply.started":"2022-05-13T00:13:37.279877Z","shell.execute_reply":"2022-05-13T00:14:01.987386Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"test_2_final_model(best_model, train_generator, \n               val_generator, val2_generator, \n               np.argmax(train_label, axis=1),\n               np.argmax(test_label, axis=1),\n               np.argmax(val_label, axis=1), \n               class_labels = ['idc-', 'idc+'])","metadata":{"execution":{"iopub.status.busy":"2022-05-13T00:14:01.989983Z","iopub.execute_input":"2022-05-13T00:14:01.990237Z","iopub.status.idle":"2022-05-13T00:14:52.508001Z","shell.execute_reply.started":"2022-05-13T00:14:01.990205Z","shell.execute_reply":"2022-05-13T00:14:52.507291Z"},"trusted":true},"execution_count":118,"outputs":[{"name":"stdout","text":"3/3 [==============================] - 16s 5s/step\n2/2 [==============================] - 4s 2s/step\npredicting test data\n9/9 [==============================] - 30s 3s/step\nTrain accuracy Score------------>\n54.286 %\nVal accuracy Score--------->\n55.556 %\nTest accuracy Score--------->\n51.190 %\nF1 Score--------------->\n50.624 %\nCohen Kappa Score------------->\n2.381 %\nRecall-------------->\n51.190 %\nPrecision-------------->\n51.248 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 864x432 with 4 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"#MODEL_PATH = './test_model.hdf5'\nfrom keras.models import load_model\n#best_model = load_model('./init_model.h5')\nbest_model = load_model('./init_model.h5',compile=False)\n#init_model = load_model(\"./init_model.h5\", custom_objects={'focal_loss_fixed': focal_loss()})","metadata":{"execution":{"iopub.status.busy":"2022-05-13T00:14:52.509298Z","iopub.execute_input":"2022-05-13T00:14:52.509961Z","iopub.status.idle":"2022-05-13T00:15:18.684227Z","shell.execute_reply.started":"2022-05-13T00:14:52.509923Z","shell.execute_reply":"2022-05-13T00:15:18.683479Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"test_2_final_model(init_model, train_generator, \n               val_generator, val2_generator, \n               np.argmax(train_label, axis=1),\n               np.argmax(test_label, axis=1),\n               np.argmax(val_label, axis=1), \n               class_labels = ['idc-', 'idc+'])","metadata":{"execution":{"iopub.status.busy":"2022-05-13T00:15:18.686121Z","iopub.execute_input":"2022-05-13T00:15:18.686367Z","iopub.status.idle":"2022-05-13T00:16:03.211771Z","shell.execute_reply.started":"2022-05-13T00:15:18.686334Z","shell.execute_reply":"2022-05-13T00:16:03.211083Z"},"trusted":true},"execution_count":120,"outputs":[{"name":"stdout","text":"3/3 [==============================] - 10s 3s/step\n2/2 [==============================] - 4s 2s/step\npredicting test data\n9/9 [==============================] - 31s 3s/step\nTrain accuracy Score------------>\n52.500 %\nVal accuracy Score--------->\n38.889 %\nTest accuracy Score--------->\n47.619 %\nF1 Score--------------->\n47.589 %\nCohen Kappa Score------------->\n-4.762 %\nRecall-------------->\n47.619 %\nPrecision-------------->\n47.614 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 864x432 with 4 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"#MODEL_PATH = './test_model.hdf5'\nfrom keras.models import load_model\n#best_model = load_model('./test_model.h5')\ninit_model = load_model('../input/cropnet-4-breast/cropnet_init_model_20220511.h5', compile=False)\n#best_model = load_model(\"./test_model.h5\", custom_objects={'focal_loss_fixed': focal_loss()})","metadata":{"execution":{"iopub.status.busy":"2022-05-13T00:16:03.213182Z","iopub.execute_input":"2022-05-13T00:16:03.213600Z","iopub.status.idle":"2022-05-13T00:16:32.653434Z","shell.execute_reply.started":"2022-05-13T00:16:03.213561Z","shell.execute_reply":"2022-05-13T00:16:32.652601Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"test_2_final_model(init_model, train_generator, \n               val_generator, val2_generator, \n               np.argmax(train_label, axis=1),\n               np.argmax(test_label, axis=1),\n               np.argmax(val_label, axis=1), \n               class_labels = ['idc-', 'idc+'])","metadata":{"execution":{"iopub.status.busy":"2022-05-13T00:16:32.655128Z","iopub.execute_input":"2022-05-13T00:16:32.655429Z","iopub.status.idle":"2022-05-13T00:17:25.040635Z","shell.execute_reply.started":"2022-05-13T00:16:32.655391Z","shell.execute_reply":"2022-05-13T00:17:25.039877Z"},"trusted":true},"execution_count":122,"outputs":[{"name":"stdout","text":"3/3 [==============================] - 17s 6s/step\n2/2 [==============================] - 4s 2s/step\npredicting test data\n9/9 [==============================] - 31s 3s/step\nTrain accuracy Score------------>\n47.500 %\nVal accuracy Score--------->\n44.444 %\nTest accuracy Score--------->\n45.238 %\nF1 Score--------------->\n45.207 %\nCohen Kappa Score------------->\n-9.524 %\nRecall-------------->\n45.238 %\nPrecision-------------->\n45.227 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 864x432 with 4 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAArMAAAF1CAYAAAD7vmIvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA2KUlEQVR4nO3deZwdVZn/8c8TQBbZQiAsYVVQQVZBQBABQbYB44IODCiyRRR+gjvqjCyOgsqg4+CIGUB2UFkUEFmGVUYTiBDWsCkIhECABMISkITn90dV4KbtpEO6uzqn6/PmVa/ce6pu3XM75NtPnTpVNzITSZIkqURDBroDkiRJ0vyymJUkSVKxLGYlSZJULItZSZIkFctiVpIkScWymJUkSVKxLGYXIBGREbH2ALxvRMQvImJqRNzci/1sExH39WXfBkpErB4RL0TEQgPdF0mam4h4Z0SMj4jnI+ILvdjPyRHxb33Zt4ESEd+MiFMGuh9qhsVsH4qIKyLi2G7aR0bEExGxcC/3v3NE3FgH1lMRcUNEfLg3+6y9H/gQsGpmbj6/O8nMP2TmO/ugP/0qIh6OiB3ntk1mPpKZS2bmzKb6JakZ9YHqrOW1iJje8Xyf+djf9RFxUA/bvCUijo6IByLixTqHTouINef7g7zha8B1mblUZv5kfneSmYdk5nf6oD/9JiK2i4jHetouM7+XmXP9O9HgYTHbt84A9o2I6NL+KeCczJwxvzuOiD2BXwNnAqsCKwLfBvaY3312WAN4ODNf7IN9Fa+3Bx2SFmz1geqSmbkk8AiwR0fbOf30thcAHwb+BVgG2Aj4M7BDH+x7DeDuPtjPoGCGt1BmuvTRAiwOPAd8oKNtKPAyVXBtDvwJeBaYBJwEvKVj2wTW7ma/QRW4X53Lew8B/hX4GzCZquhdpl63Zr3v/er9PA18q153YN2/mcALwDHAZ4Cbuuz/9b4BuwH3AM8DE4Gv1O3bAY91vGZd4Pr6894NfLhj3enAT4Hf1fsZC7x9Dp9tVv/3Bx4FpgKHAO8F7qj3f1LH9m8HrgWeqT/rOcCy9bqzgNeA6fXn/VrH/g+sfz43drQtDCwHPEb1Cw9gSeBB4NMD/f+ci4tL7xbgYWDH+vEQ4EjgL3V+/ApYrl63GHB23f4scAvVoMJ36/x8uc6Uk7p5jx3rzFltLv1YBbgEmFLny8Ed646u+3JmnZd3A5vV667t8v7vqHP3oI7Xv57pVL9PfkT1e2IacCewfr3udODfO153cN2XKXXfVulYl3UOP1D/PH4KxBw+29FUgzFn1/2/s+7nN+p+PArs1LH9/sCEetu/Ap+t299a/xxfqz/rC/XP7Wiqg4Wz6890UN12dv26fwYeApaun+8KPAGsMND//7n0zTLgHRhsC/A/wCkdzz8LjK8fbwpsSVUgrVn/Yz2iY9s5FbPvqtetNZf3PaAOnbdRFVsXAWfV69asX/8/VAX3RsArwLr1+teDrrvnXftGVYhvUz8eCrynfrwddTELLFL355vAW4AP1sH0znr96VS/FDavfx7nAOfP4bPN6v/JVL9QdqIK7t8Aw4ERdSBuW2+/NtW0iUWBFaiK0x937O9h6l9eXfZ/Zh2Wi3e0LVxvs1MdfsPrn+MFA/3/mouLS+8XZi9mDwfGUJ39WhT4OXBeve6zwKXAEsBCdZ7PKo6up6N47OY9jgdu6KEfNwL/XWfcxsBTwAfrdUfXmbdb/d7HAWM6Xjvb+3fz/PVMB3amGhFelqqwXRdYuV53OnUxW2f208B76p/FfwE3duwzgcvq/axe93eXOXy2Wf3fmSrvz6QqLr9F9bviYOChju3/iWpQIoBtgZfo5vdMl/2/CnyE6oBkcTqK2Xqbc+rPNwx4HNh9oP/fc+m7xWkGfe8MYM+IWKx+/um6jcz8c2aOycwZmfkwVVBuOw/7HFb/OWku2+wDnJiZf83MF6iOePfqcrrlmMycnpm3A7dTFbXz41VgvYhYOjOnZuat3WyzJVVRfXxm/j0zr6UKvr07trk4M2/OavrFOVQBPjffycyXM/Mq4EWqXzKTM3Mi8AdgE4DMfDAzr87MVzLzKeBE5u3nfHRmvpiZ07uuqN/z18A1VL9QPjsP+5NUlkOozlo9lpmvUBVEe9Y5+ipVFq+dmTPrPJ82j/sdxlzyOyJWA7YGvl5n3HjgFKrfH7PclJmXZzWP/yx6l99LUQ2SRGZOyMzu+rYPcFpm3lr/LL4BvK/LHN/jM/PZzHwEuI65Z/gfMvPKOu9/TTXQcHxmvgqcD6wZEcsCZObvMvMvWbkBuArYpofP9afM/E1mvtZdhgOHUhXo1wOXZuZlPexPBbGY7WOZeRPV0exHIuLtVCOP5wJExDsi4rL6YrBpwPeA5edht8/Uf648l21WoZpiMMvfqI6AV+xoe6Lj8UtUxeb8+DhVQfe3+iK0982hP49m5mtd+jSiF/15suPx9G6eLwkQEStGxPkRMbH+OZ/NvP2cH+1h/WhgfeD0zHymh20llWcN4OKIeDYinqU6ezaTKkfPAq4Ezo+IxyPiBxGxyDzu9xl6zu8pmfl8R1tPebnY/MwNrQcWTqKaFjA5IkZHxNJz6NPfOl73AtXnmN8M75rXT+cbF9jOKj5nZfiuETEmIqbUfw+70XOGzzW/M/NZqiJ6feA/etiXCmMx2z/OpDqi3he4MjNn/SP+GXAvsE5mLk11Cr7rxWLduY/qH+rH57LN41RBPMvqwAxmD5B59SLVqTQAImKlzpWZeUtmjqQ65f4bqrlc3fVntYjo/H9sdao5tv3te1SnwDaof877MvvPOefwujm1U9+iazTV3+3nB+IWapL63aPArpm5bMeyWGZOzMxXM/OYzFwP2ArYnTdGTueYHbX/BTaPiFXnsP5xYLmIWKqjrTd5OVuGA10z/CeZuSmwHtXc1a/OoU+v/06JiLdSjTD3a4ZHxKLAhcAJwIqZuSxwOW9k+JvO73q/G1NNxzsPmO87PmjBZDHbP86kmvB/MPUUg9pSVJPTX4iIdwGfm5edZWYCXwL+LSL2j4ilI2JIRLw/IkbXm50HfDEi1oqIJakKul/m/N1B4Xbg3RGxcT1d4uhZK+rby+wTEcvUp4emUU3G72os1ZH61yJikYjYjurOC+fPR3/erKWoLgx4LiJG8I9B/STV3OI345tUYXkA8EPgTO9BKw06JwPfjYg1ACJihYgYWT/ePiI2qP/dT6M6XT8r++aaKZn5v8DVVKO+m0bEwhGxVEQcEhEHZOajwB+B4yJisYjYkOqC1LPn83OMBz4WEUvUB94HzloREe+NiC3qUeUXqeaydpfh5wH7178HFqX6nTK2niLXn95CNUf3KWBGROxKdc3CLE8CwyJimXndYf177GyqHN8fGBERn++7LmugWcz2g/of+x+pLia6pGPVV6huy/I81UVEv3wT+7yA6orMA6iOmJ8E/h34bb3JaVSnwW6kmlj/MvD/5rP/9wPHUo0mPADc1GWTTwEP16fwD6GaW9V1H3+nKl53pZp28d9UV//fOz99epOOobpo4TmquyVc1GX9ccC/1qcSv9LTziJiU6qDiU/Xp8W+T1XYHtmnvZY00P6TKrOviojnqS4G26JetxLVFfPTqKYf3ECVubNet2dUXzwzp1G/PalGGH9JlU13AZtR5SxU1xOsSZXvFwNH1UXw/PgR8Heq3xNnUF2TMMvSVL9/plJNI3iG6gB9NvV7/xvVKOkkqguy9prP/syzeqrFF6jO+E2l+p15Scf6e6kK7b/WGb7KPOz2OKppbz+r5//uC/x7RKzT5x9AAyKqQT9JkiSpPI7MSpIkqVgWs5IGhfqrQSdHxF0dbctFxNX1V4heHRFD5/Da/eptHoiI/TraN42IOyPiwYj4STff7idJmg8RsVpEXBcR90TE3RFxeJf1X46IjIge70ZkMStpsDgd2KVL25HANZm5DtU9gv9hnnNELAccRTU3cnPgqI6i92dUF3KuUy9d9y9Jmj8zgC/XdwjZEjg0ItaD1++9vBPVt3L2yGJW0qCQmTdSfe1mp5G8cUeRM6i+IairnYGrM3NKZk6luup8l4hYmeobnsbUdxQ5cw6vlyS9SZk5adaXLtUX/k3gjfsY/4jq6+bn6cIui1lJg9mKHd9u9ASzf4nILCOY/Ybrj9VtI+rHXdslSX2o/ma5TYCx9e3wJtbfVjpP3vS3h7xZL8+Yt6paZRv63sMGugtqwPTbTprvOaOLb3JYr7Lg5fE//SwwqqNpdGaOntP2XWVmRoR51IMLbp/kz6gFTvj9/QPdBTVgzJHbLvCZXd8b/0LgCKqpB99k9nsL96jfi1lJAiB6dyKoDsF5Ll5rT0bEypk5qZ42MLmbbSYC23U8X5Xq+9sn1o8725v4BjtJGngNZHb95R0XAudk5kURsQGwFnB7fb3tqsCtEbF5Zj4xp/04zUBSMyJ6t8yfS4BZdyfYjze+ZKTTlcBOETG0vvBrJ6qvoZ4ETIuILeu7GHx6Dq+XpMGnnzO7ztVTgQmZeSJAZt6ZmcMzc83MXJNqetd75lbIgsWspKbEkN4tPe0+4jzgT8A7I+KxiDgQOB74UEQ8QPUV08fX224WEacAZOYU4DvALfVybN0G8HngFOBB4C/A7/vyRyJJC6x+zmxga6pvFP1gRIyvl93mp6tOM5A0KGTm3nNYtUM3244DDup4fhrVV0J3t936fdVHSVIlM28C5jqEW4/O9shiVlIz/L4BSSpHQZltMSupGb28mECS1KCCMttiVlIzCjrKl6TWKyizyym7JUmSpC4cmZXUjIJOWUlS6xWU2RazkppR0CkrSWq9gjLbYlZSMwo6ypek1isosy1mJTWjoKN8SWq9gjK7nLJbkiRJ6sKRWUnNKOiUlSS1XkGZbTErqRkFnbKSpNYrKLMtZiU1o6CjfElqvYIy22JWUjMKCkZJar2CMrucnkqSJEldODIrqRlDypl/JUmtV1BmW8xKakZBp6wkqfUKymyLWUnNKOjKWElqvYIyu5yyW5IkSerCkVlJzSjolJUktV5BmW0xK6kZBZ2ykqTWKyizLWYlNaOgo3xJar2CMttiVlIzCjrKl6TWKyizyym7JUmSpC4cmZXUjIJOWUlS6xWU2RazkppR0CkrSWq9gjLbYlZSMwo6ypek1isosy1mJTWjoKN8SWq9gjK7nLJbkiRJ6sKRWUnNKOiUlSS1XkGZbTErqRkFBaMktV5BmW0xK6kZBc2/kqTWKyizyym7JUmSpC4cmZXUjAZOWUXE4cDBQAD/k5k/7rL+q8A+9dOFgXWBFTJzSkQ8DDwPzARmZOZm/d5hSVpQOc1Akrro51NWEbE+VSG7OfB34IqIuCwzH5y1TWb+EPhhvf0ewBczc0rHbrbPzKf7taOSVAKnGUhSFzGkd0vP1gXGZuZLmTkDuAH42Fy23xs4rw8+mSQNPv2f2X3GYlZSMyJ6tUTEqIgY17GM6vIOdwHbRMSwiFgC2A1YrfuuxBLALsCFHc0JXBURf+5m35LULr3M7CY5zUBSETJzNDB6LusnRMT3gauAF4HxVPNfu7MH8H9dphi8PzMnRsRw4OqIuDczb+yb3kuS+osjs5IaEdXo6nwv8yIzT83MTTPzA8BU4P45bLoXXaYYZObE+s/JwMVUc28lqZWayOy+4sispEY0EW4RMTwzJ0fE6lTzZbfsZptlgG2BfTva3goMyczn68c7Acf2e4claQHVdEHaGxazkprRTC5eGBHDgFeBQzPz2Yg4BCAzT663+ShwVWa+2PG6FYGL6/BeGDg3M69opMeStCAqp5a1mJU0eGTmNt20ndzl+enA6V3a/gps1J99kyT1D4tZSY0o6ZSVJLVdSZltMSupESUFoyS1XUmZbTErqRElBaMktV1JmW0xK6kRJQWjJLVdSZntfWYlSZJULItZSc2IXi6SpOb0c2ZHxGoRcV1E3BMRd0fE4XX7dyLijogYHxFXRcQqPe3LYlZSI0r6NhlJarsGMnsG8OXMXI/qC24OjYj1gB9m5oaZuTFwGfDtnnbknFlJjbAglaRy9HdmZ+YkYFL9+PmImACMyMx7OjZ7K5A97ctiVlIjLGYlqRy9zeyIGAWM6mganZmj57DtmsAmwNj6+XeBTwPPAdv39F5OM5AkSVKfyszRmblZxzKnQnZJ4ELgiMycVr/2W5m5GnAOcFhP72UxK6kRzpmVpHI0kdkRsQhVIXtOZl7UzSbnAB/vaT8Ws5Ka4d0MJKkc/X83gwBOBSZk5okd7et0bDYSuLenfTlnVlIjHF2VpHI0kNlbA58C7oyI8XXbN4EDI+KdwGvA34BDetqRxawkSZIalZk30f0Y7uVvdl8Ws5Ia4cisJJWjpMy2mJXUiJKCUZLarqTMtpiV1IxyclGSVFBmW8xKakRJR/mS1HYlZba35pIkSVKxHJmV1IiSjvIlqe1KymyLWUmNKCkYJantSspsi1lJjSgpGCWp7UrKbItZSc0oJxclSQVltheASZIkqViOzEpqREmnrCSp7UrKbItZSY0oKRglqe1KymyLWUmNKCkYJantSsps58xKkiSpWI7MSmpGOQf5kqSCMttiVlIjSjplJUltV1JmW8xKakRJwShJbVdSZlvM9rGzzjidiy78NRHBOuu8g2O/exyLLrroQHdLvXTyUfuw6wfW56kpz7PZJ74HwNCll+Cs7x/AGqssx98en8K+XzuVZ5+fPsA9XXCVFIwavJ59ejIX/PR7vPDsVCKC9+64O1vtticvvTCN8390DM8+9QTLrrASe3/xaBZfcqmB7q7mw/ClFuWo3d/Fcm9dhEz4ze2T+NW4iRy2/dt4/9rDmDHzNR579mX+/Xf38sIrMwe6uwuskjLbC8D60JNPPsm555zJeb+6kIt+exmvvTaTKy7/3UB3S33grEvHMPLQn87W9pX9P8T1N9/HBiOP5fqb7+Mr++80QL3TLBFxeETcFRF3R8QR3azfLiKei4jx9fLtjnW7RMR9EfFgRBzZaMfVmCELLcSun/o8R/zoDA757n8z5srfMPmxh7nxN+fy9g3ew5d+cg5v3+A93PCbcwe6q5pPM19LfnLtX9j7lHEcdNZt7PmeVVhz2BLc/NBU9jnlFvY97c88OuUl9nvf6gPdVfURi9k+NnPmTF55+WVmzJjB9JdfZoXhwwe6S+oD/3frX5jy3Euzte2+3YacfelYAM6+dCx7bL/hQHStGBHRq2Ue9r8+cDCwObARsHtErN3Npn/IzI3r5dj6tQsBPwV2BdYD9o6I9frqs2vBsfTQYYx42zsAWHTxJVhhxBpMm/I0E275PzbZdhcANtl2FybcctNAdlO98MyLf+e+J18A4KW/z+ThZ15i+FKLcvPDU5mZ1TZ3PT6N4Ut51nRu+juz+1KP0wwi4l3ASGBE3TQRuCQzJ/Rnx0q04oorst9nDmDnHbdnscUW5X1bbc1WW79/oLulfjJ82FI88fQ0AJ54ehrDh3lKcq76P9vWBcZm5ksAEXED8DHgB/Pw2s2BBzPzr/Vrz6fKvXv6qa/9xsyed1MnT2LSQw+w6trr8sJzU1h66DAAllp2OV54bsoA9059YeVlFuUdw5fkrsenzda+x4Yr878TJg9QrwpRziyDuY/MRsTXgfOpPtLN9RLAeXM7DRcRoyJiXESMO/V/Rvdlfxdo0557juuuvYbLr7qGq6/7A9OnT+eyS3870N1SQzIHugcLtt4e5XfmSr2M6vIWdwHbRMSwiFgC2A1YrZuuvC8ibo+I30fEu+u2EcCjHds8xhvFYDH6IrOvvuDsZjo7wF55+SXO/Y+j+KfPHMZiS7x1tnURAQXNF1T3Fl9kCMd99N38+Jq/8NLf35gb+5n3rc6M15Ir7raYnZvBNDJ7IPDuzHy1szEiTgTuBo7v7kWZORoYDfDyDFrzK37MmD8yYtVVWW655QDYYceduP2229h9j5ED3DP1h8nPPM9Kyy/NE09PY6Xll+apKc8PdJcWaL0Nt85cmcP6CRHxfeAq4EVgPND16o5bgTUy84WI2A34DbBOrzq2YOl1Zl9w+6RBn9kzZ8zg3P84io222ZF3b/EBAJZcZjmmTX2GpYcOY9rUZ1hy6aED3Ev1xkJDguM++m6uvHsy19//9Ovt/7TBimy99jAOO+/2AexdGQbTBWCvAat0075yvU4dVlp5Fe64/XamT59OZjJ2zJ9Y6+1vH+huqZ/87oY72XePLQDYd48tuOz6Owa4R8rMUzNz08z8ADAVuL/L+mmZ+UL9+HJgkYhYnupUfOco7qp1W2nM7B5kJhed/AOGj1id9+/+ydfb37XZVtx2wxUA3HbDFaz73q0HqovqA9/a7R08/MxLnHfLY6+3bbnWUPbdYjW+esFdvDLDfw6DSU8js0cA10TEA7xxCm51YG3gsH7sV5E23HAjPrTTzuz1iY+y0EIL865112XPT/zzQHdLfeCM4z7DNpuuw/LLLsmDV3yH75x8OSf84mrO/v4B7PeR9/HIpCns+7XTBrqbC7QmDvIjYnhmTo6I1anmy27ZZf1KwJOZmRGxOdUB/TPAs8A6EbEWVRG7F/Av/d/jPncEZvZc/e2+Oxl/41WsuPrb+K+vHgjATnsfzLYf+RfO+9Ex/Pnay1l2hRXZ64tHD2xHNd82WnVpdlt/JR6c/AJn7r8pAD+74SG+9KG1ectCwU/2qi7WvevxafzgygcGsqsLtIIGZonsYaJfRAyhujii82KCWzJznm7O1qZpBm029L3+nmyD6bedNN/xts5Xr+hVFjzww116fO+I+AMwDHgV+FJmXhMRhwBk5skRcRjwOWAGML3e5o/1a3cDfgwsBJyWmd/tTX8HSm8zuw3TDAQn/P7+njdS8cYcue0Cndl9pce7GWTma8CYBvoiaRBr4ig/M7fppu3kjscnASfN4bWXA5f3X++aYWZL6gsljcx6n1lJkiQVy6+zldSIkq6MlaS2KymzLWYlNaKgXJSk1ispsy1mJTViyJCCklGSWq6kzLaYldSIko7yJantSspsLwCTJElSsRyZldSIki4mkKS2KymzLWYlNaKgXJSk1ispsy1mJTWipKN8SWq7kjLbYlZSI0oKRklqu5Iy2wvAJEmSVCxHZiU1oqCDfElqvZIy22JWUiNKOmUlSW1XUmZbzEpqREG5KEmtV1JmO2dWkiRJxXJkVlIjSjplJUltV1JmW8xKakRBuShJrVdSZlvMSmpESUf5ktR2JWW2c2YlNSKid4skqTn9ndkRsVpEXBcR90TE3RFxeN3+w4i4NyLuiIiLI2LZnvZlMStJkqSmzQC+nJnrAVsCh0bEesDVwPqZuSFwP/CNnnbkNANJjSjplJUktV1/Z3ZmTgIm1Y+fj4gJwIjMvKpjszHAnj3ty2JWUiOsZSWpHL3N7IgYBYzqaBqdmaPnsO2awCbA2C6rDgB+2dN7WcxKaoQjs5JUjt5mdl24dlu8dnmfJYELgSMyc1pH+7eopiKc09M+LGYlNcJaVpLK0URmR8QiVIXsOZl5UUf7Z4DdgR0yM3vaj8WsJEmSGhXV0O+pwITMPLGjfRfga8C2mfnSvOzLYlZSI5xmIEnlaCCztwY+BdwZEePrtm8CPwEWBa6u+zAmMw+Z244sZiU1wlpWksrR35mdmTcB3b3L5W92XxazkhrhyKwklaOkzPZLEyRJklQsR2YlNaKko3xJaruSMttiVlIjCspFSWq9kjLbYlZSI0o6ypektisps50zK6kREb1b5u094vCIuCsi7o6II7pZv09E3BERd0bEHyNio451D9ft4yNiXJ99cEkqUBOZ3VccmZU0KETE+sDBwObA34ErIuKyzHywY7OHqG7EPTUidqX6qsUtOtZvn5lPN9ZpSVKvOTIrqRER0atlHqwLjM3MlzJzBnAD8LHODTLzj5k5tX46Bli1Tz+kJA0SDWR2n7GYldSI3p6yiohRETGuYxnV5S3uAraJiGERsQSwG7DaXLp0IPD7jucJXBURf+5m35LUKk4zkKQuhvQy3TJzNNW0gDmtnxAR3weuAl4ExgMzu9s2IranKmbf39H8/sycGBHDqb5G8d7MvLFXnZakQvU2s5vkyKykRjRxlJ+Zp2bmppn5AWAqcP8/9iM2BE4BRmbmMx2vnVj/ORm4mGrurSS1UkkjsxazkgaNelSViFidar7suV3Wrw5cBHwqM+/vaH9rRCw16zGwE9W0BUnSAs5pBpIa0dAFARdGxDDgVeDQzHw2Ig4ByMyTgW8Dw4D/rvszIzM3A1YELq7bFgbOzcwrmuiwJC2ISrrPrMWspEYMaSAXM3ObbtpO7nh8EHBQN9v8Fdioa7sktVUTmd1XLGYlNaKko3xJaruSMts5s5IkSSqWI7OSGlHQQb4ktV5JmW0xK6kRQUHJKEktV1JmW8xKakRJFxNIUtuVlNkWs5IaUdLFBJLUdiVltheASZIkqViOzEpqREEH+ZLUeiVltsWspEYMKSkZJanlSspsi1lJjSgoFyWp9UrKbOfMSpIkqViOzEpqRElXxkpS25WU2RazkhpRUC5KUuuVlNkWs5IaUdLFBJLUdiVltsWspEaUE4uSpJIy2wvAJEmSVCxHZiU1oqSLCSSp7UrKbItZSY0YUk4uSlLrlZTZFrOSGlHSUb4ktV1JmW0xK6kRBeWiJLVeSZntBWCSJEkqliOzkhpR0ikrSWq7kjLbYlZSI0q6mECS2q6kzLaYldSIko7yJantSsps58xKkiSpWI7MSmpEOcf4kqSSMttiVlIjhhR0ykqS2q6kzLaYldSIgnJRklqvpMy2mJXUiJIuJpCktisps70ATJIkScVyZFZSIwo6yJek1ispsx2ZldSIIRG9WuZFRBweEXdFxN0RcUQ36yMifhIRD0bEHRHxno51+0XEA/WyX999ckkqT39ndkSsFhHXRcQ9dWYfXrd/on7+WkRsNi99dWRWUiP6+yg/ItYHDgY2B/4OXBERl2Xmgx2b7QqsUy9bAD8DtoiI5YCjgM2ABP4cEZdk5tT+7bUkLZgaGJmdAXw5M2+NiKWocvdq4C7gY8DP53VHjsxKakRE9GqZB+sCYzPzpcycAdxAFYidRgJnZmUMsGxErAzsDFydmVPqAvZqYJe++/SSVJb+zuzMnJSZt9aPnwcmACMyc0Jm3vdm+moxK2mwuAvYJiKGRcQSwG7Aal22GQE82vH8sbptTu2SpH4WEWsCmwBj5+f1/T7NYOh7D+vvt9ACYOotJw10F7SA6+2Rc0SMAkZ1NI3OzNGznmTmhIj4PnAV8CIwHpjZy7dtnU995rsD3QU1wMxWT/o7szu2WxK4EDgiM6fNz3s5Z1ZSI3p7z8I6BP8hCLtscypwav1+36MaYe00kdlHa1et2yYC23Vpv75XHZakgjWR2RGxCFUhe05mXjS/7+U0A0mNGBK9W+ZFRAyv/1ydar7suV02uQT4dH1Xgy2B5zJzEnAlsFNEDI2IocBOdZsktVJ/Z3ZU1fKpwITMPLE3fXVkVtJgcmFEDANeBQ7NzGcj4hCAzDwZuJxqLu2DwEvA/vW6KRHxHeCWej/HZuaUxnsvSe2xNfAp4M6IGF+3fRNYFPgvYAXgdxExPjN3ntuOLGYlNWJeR1d7IzO36abt5I7HCRw6h9eeBpzWf72TpHL0d2Zn5k3AnN7l4jezL4tZSY0o6Xu+JantSspsi1lJjWhiZFaS1DdKymyLWUmNKOggX5Jar6TM9m4GkiRJKpYjs5IaMaSkw3xJarmSMttiVlIjPA0kSeUoKbMtZiU1oqCDfElqvZIy22JWUiNKOmUlSW1XUmaXNIosSZIkzcaRWUmNKOggX5Jar6TMtpiV1IiSbsAtSW1XUmZbzEpqREnzrySp7UrKbOfMSpIkqViOzEpqREEH+ZLUeiVltsWspEaUNP9KktqupMy2mJXUiKCgZJSklispsy1mJTWipKN8SWq7kjLbC8AkSZJULEdmJTWipKN8SWq7kjLbYlZSI6KkS2MlqeVKymyLWUmNKOkoX5LarqTMtpiV1IiCDvIlqfVKymwvAJMkSVKxHJmV1IiSvudbktqupMy2mJXUiJLmX0lS25WU2RazkhpR0EG+JLVeSZntnFlJkiQVy5FZSY0YUtD3fEtS25WU2RazkhpR0ikrSWq7kjLbYlZSI0q6mECS2q6kzLaYldSIkm7zIkltV1JmewGYJEmSiuXIrKRGNHGQHxFfBA4CErgT2D8zX+5Y/yNg+/rpEsDwzFy2Xjezfg3AI5n54f7vsSQtmAoamLWYldSM/j5lFREjgC8A62Xm9Ij4FbAXcPqsbTLzix3b/z9gk45dTM/Mjfu1k5JUiJKmGVjMSmpEQ7m4MLB4RLxKNfL6+Fy23Rs4qpFeSVJhCqplnTMrqRlDerlExKiIGNexjOrcf2ZOBE4AHgEmAc9l5lXd9SUi1gDWAq7taF6s3u+YiPhI33xqSSpTbzO7SY7MSipCZo4GRs9pfUQMBUZSFanPAr+OiH0z8+xuNt8LuCAzZ3a0rZGZEyPibcC1EXFnZv6l7z6BJKk/ODIrqRER0atlHuwIPJSZT2Xmq8BFwFZz2HYv4LzOhnpkl8z8K3A9s8+nlaRWaSCz+4zFrKRGRC+XefAIsGVELBFVku4ATPiHfkS8CxgK/KmjbWhELFo/Xh7YGrjnzX9KSRocGsjsPuM0A0mN6O8rYzNzbERcANwKzABuA0ZHxLHAuMy8pN50L+D8zMyOl68L/DwiXqM6yD8+My1mJbWWdzOQpAGQmUfxj3co+HaXbY7u5nV/BDbov55JkvqLxaykRpRzjC9JKimzLWYlNaKgM1aS1HolZbbFrKRGNH11qyRp/pWU2RazkhrhrVMkqRwlZXZJfZUkSZJmYzErqREl3YBbktquvzM7IlaLiOsi4p6IuDsiDq/bl4uIqyPigfrPoT3ty2JWUiNKugG3JLVdA5k9A/hyZq4HbAkcGhHrAUcC12TmOsA19fO5cs6spEY4uipJ5ejvzM7MScCk+vHzETEBGAGMBLarNzuD6uvFvz63fTkyK0mSpD4VEaMiYlzHMmou264JbAKMBVasC12AJ4AVe3ovR2YlNcIjZ0kqR28zOzNHA6N72i4ilgQuBI7IzGmdI8KZmRGRc3xxzWJWUiOcZiBJ5WgisyNiEapC9pzMvKhufjIiVs7MSRGxMjC5p/04WCKpEV4AJknl6O/MjqpaPhWYkJkndqy6BNivfrwf8Nue9uXIrKRGODArSeVoILO3Bj4F3BkR4+u2bwLHA7+KiAOBvwGf7GlHFrOSJElqVGbexJwHcXd4M/uymJXUiCFOFpCkYpSU2RazkhrhNANJKkdJmW0xK6kRUdBRviS1XUmZbTErqRElHeVLUtuVlNnemkuSJEnFcmRWUiNKuphAktqupMy2mJXUiJJOWUlS25WU2RazkhpRUjBKUtuVlNnOmZUkSVKxHJmV1IiSbvMiSW1XUmZbzEpqxJByclGSWq+kzLaYldSIko7yJantSspsi1lJjSjpYgJJaruSMtsLwCRJklQsR2YlNaKkU1aS1HYlZbbFrKRGlHQxgSS1XUmZbTErqRElHeVLUtuVlNnOme2lk4/ah79dcxzjfv3N19uGLr0El/3sMO787be57GeHsexSiw9gD9XXzjrjdD764X/iYyN35+tf+RKvvPLKQHepCBG9W6S+sOqKy3LF6C9w64Xf4s8XfItD995utvWHf+qDTL/tJIYt+9aB6aD6xLf/9Rtst837+NjI3V9vu3fCBPbd+5N88mMj2fuTH+POO+4YwB4u+ErKbIvZXjrr0jGMPPSns7V9Zf8Pcf3N97HByGO5/ub7+Mr+Ow1Q79TXnnzySc4950zO+9WFXPTby3jttZlccfnvBrpbqkXEFyPi7oi4KyLOi4jFuqz/TEQ8FRHj6+WgjnX7RcQD9bJf871XE2bMfI0jT7yI93z8u2z76RP47D9/gHe9bSWgKnR32HJdHpk0ZYB7qd4a+ZGP8bOfnzJb249O/CGHfP5QfnXRb/n8YYfz4xN/OEC9U1+zmO2l/7v1L0x57qXZ2nbfbkPOvnQsAGdfOpY9tt9wILqmfjJz5kxeefllZsyYwfSXX2aF4cMHuktFiF4uPe4/YgTwBWCzzFwfWAjYq5tNf5mZG9fLKfVrlwOOArYANgeOioih8/lRtQB74ulpjL/3MQBeeOkV7n3oCVZZYVkAfvCVj/Ot//wNmTmAPVRf2HSz97L0MsvM1hYEL7zwIgAvPP88K6xgds9Nf2d2X3LObD8YPmwpnnh6GlAF5/BhSw1wj9RXVlxxRfb7zAHsvOP2LLbYorxvq63Zauv3D3S3ijCkmfNOCwOLR8SrwBLA4/P4up2BqzNzCkBEXA3sApzXL73UAmH1lZdj43euyi13Pczu223A45Of5c77Jw50t9RPvnbkN/ncqAM58YTv89prr3HmOecPdJcWaA1ldp+Y75HZiNh/LutGRcS4iBg34+m75/ctBg0P8gePac89x3XXXsPlV13D1df9genTp3PZpb8d6G4VobdH+Z25Ui+jOvefmROBE4BHgEnAc5l5VTdd+XhE3BERF0TEanXbCODRjm0eq9sGlTnldhsz+62Lv4XzTjiIr55wITNmzuRrB+zMsT9zytBg9qtfnsdXv/4NrrrmBr769W9w9L99a6C7tEAraWS2N9MMjpnTiswcnZmbZeZmCy//7l68RZkmP/M8Ky2/NAArLb80T015foB7pL4yZswfGbHqqiy33HIsssgi7LDjTtx+220D3a1W6MyVehndub6eFjASWAtYBXhrROzbZTeXAmtm5obA1cAZTfR9AdJtbrctsxdeeAjnnXAwv/z9OH577e28bdUVWGPEMG7+5Te493fHMGL4svzp3K+zomfVBpVLf3sxO3youoZlp5135a47vQBssJjrNIOImNPfdAAr9n13Boff3XAn++6xBSf84mr23WMLLrvefzCDxUorr8Idt9/O9OnTWWyxxRg75k+st/76A92tMvT/ofqOwEOZ+RRARFwEbAWcPWuDzHymY/tTgB/UjycC23WsWxW4vh/72m/M7Z6dfNQ+3PfQE/zk7GsBuPvBx1ljh2+8vv7e3x3D1vv8gGeefXGguqh+sMLw4Yy75Wbeu/kW3Dx2DKuvseZAd2nBVs4sgx7nzK5INZdsapf2AP7YLz0qzBnHfYZtNl2H5Zddkgev+A7fOflyTvjF1Zz9/QPY7yPv45FJU9j3a6cNdDfVRzbccCM+tNPO7PWJj7LQQgvzrnXXZc9P/PNAd6sIDdyz8BFgy4hYApgO7ACMm60PEStn5qT66YeBCfXjK4HvdVz0tRPwDcpkbs/FVhu/jX1234I775/ImPOPBOCoky7hypvuGeCeqS99/StfYtwtN/Pss1P50Ac/wOcO/X98++jv8IPjv8fMGTN4y6KL8u2jjx3obi7QSrrPbMztqs2IOBX4RWbe1M26czPzX3p6g8U3OcwZoy0w9ZaTBroLasBiC89/ut381+d6lQWbv22ZHt87Io4B/hmYAdwGHAR8CxiXmZdExHFURewMYArwucy8t37tAcCsG0Z/NzN/0Zv+DpTe5raZ3Q5mdjss6JndV+ZazPYFg7EdDMZ26E0w3tLLYHxvg8HYZmZ2O5jZ7dCWzPY+s5IkSSqW95mV1AzHVSWpHAVltsWspEaUdDGBJLVdSZltMSupEQV9mYwktV5JmW0xK6kRBeWiJLVeSZntBWCSJEkqliOzkppR0mG+JLVdQZltMSupESVdTCBJbVdSZlvMSmpESRcTSFLblZTZzpmVJElSsRyZldSIgg7yJan1Sspsi1lJzSgpGSWp7QrKbItZSY0o6WICSWq7kjLbYlZSI0q6mECS2q6kzPYCMEmSJBXLkVlJjSjoIF+SWq+kzLaYldSMkpJRktquoMy2mJXUiJIuJpCktisps50zK6kREb1bJEnNaSKzI+K0iJgcEXd1tG0UEX+KiDsj4tKIWLqn/VjMSpIkaSCcDuzSpe0U4MjM3AC4GPhqTzuxmJXUiOjlIklqThOZnZk3AlO6NL8DuLF+fDXw8Z72YzErqRlWs5JUjl5mdkSMiohxHcuoeXznu4GR9eNPAKv19AIvAJPUiJIuJpCktuttZmfmaGD0fLz0AOAnEfFvwCXA33t6gcWsJEmSFgiZeS+wE0BEvAP4p55eYzErqRHekUCSyjFQmR0RwzNzckQMAf4VOLmn11jMSmqEtawklaOJzI6I84DtgOUj4jHgKGDJiDi03uQi4Bc97cdiVlIzrGYlqRwNZHZm7j2HVf/5ZvZjMSupEV4AJknlKCmzvTWXJEmSiuXIrKRGeAGYJJWjpMy2mJXUiIJyUZJar6TMtpiV1IySklGS2q6gzHbOrKRGRC//m6f3iPhiRNwdEXdFxHkRsViX9V+KiHsi4o6IuCYi1uhYNzMixtfLJX388SWpKE1kdl+xmJU0KETECOALwGaZuT6wELBXl81uq9dvCFwA/KBj3fTM3LhePtxIpyVJveY0A0mNaOhigoWBxSPiVWAJ4PHOlZl5XcfTMcC+jfRKkgpT0gVgjsxKakT0dokYFRHjOpZRnfvPzInACcAjwCTgucy8ai5dOhD4fcfzxer9jomIj/T280pSyXqb2U1yZFZSM3qZbpk5Ghg9x91HDAVGAmsBzwK/joh9M/PsbrbdF9gM2LajeY3MnBgRbwOujYg7M/Mvveu1JBXKkVlJatyOwEOZ+VRmvkr1nd5bdd0oInYEvgV8ODNfmdVej+ySmX8Frgc2aaLTkqTesZiV1IgGrox9BNgyIpaIiAB2ACbM1oeITYCfUxWykzvah0bEovXj5YGtgXv66KNLUnFKupuB0wwkNaK/LybIzLERcQFwKzCD6s4FoyPiWGBcZl4C/BBYkmoKAsAj9Z0L1gV+HhGvUR3kH5+ZFrOSWqukC8AsZiU1oolczMyjgKO6NH+7Y/2Oc3jdH4EN+rFrklSUgmpZi1lJzSjpKF+S2q6kzHbOrCRJkorlyKykhhR0mC9JrVdOZlvMSmpESaesJKntSspsi1lJjSgoFyWp9UrKbItZSY0o6ShfktqupMz2AjBJkiQVy5FZSY1o+hthJEnzr6TMtpiV1IxyclGSVFBmW8xKakRBuShJrVdSZjtnVpIkScVyZFZSI0q6MlaS2q6kzLaYldSIki4mkKS2KymzLWYlNaOcXJQkFZTZFrOSGlFQLkpS65WU2V4AJkmSpGI5MiupESVdTCBJbVdSZlvMSmpESRcTSFLblZTZFrOSGlHSUb4ktV1Jme2cWUmSJBXLYlaSJEnFcpqBpEaUdMpKktqupMy2mJXUiJIuJpCktispsy1mJTWipKN8SWq7kjLbObOSJEkqliOzkhpR0EG+JLVeSZltMSupGSUloyS1XUGZbTErqRElXUwgSW1XUmZbzEpqREkXE0hS25WU2V4AJkmSpGI5MiupEQUd5EtS65WU2Y7MSmpG9HKZl7eI+GJE3B0Rd0XEeRGxWJf1i0bELyPiwYgYGxFrdqz7Rt1+X0Ts3LsPK0mFayazT4uIyRFxV0fbxhExJiLGR8S4iNi8p/1YzEpqRPTyvx73HzEC+AKwWWauDywE7NVlswOBqZm5NvAj4Pv1a9ert303sAvw3xGxUJ99eEkqTH9ndu10qszt9APgmMzcGPh2/XyuLGYlDSYLA4tHxMLAEsDjXdaPBM6oH18A7BARUbefn5mvZOZDwINAj6MBkqT5l5k3AlO6NgNL14+X4R9z/B84Z1ZSI/r7ytjMnBgRJwCPANOBqzLzqi6bjQAerbefERHPAcPq9jEd2z1Wt0lSKw3g3QyOAK6s83wIsFVPL+j3Ynb6bSeVNIe4T0TEqMwcPdD9UP/y7/nNWWzh3l1PEBGjgFEdTaM7f/4RMZRqhHUt4Fng1xGxb2ae3Zv3bRszW4OVf89vTn9n9lx8DvhiZl4YEZ8ETgV2nNsLnGbQP0b1vIkGAf+eG5SZozNzs46layjuCDyUmU9l5qvARfzjEf1EYDWAeirCMsAzne21Ves2tYP/ltvBv+cGzUNmz8l+VPkN8GvmYcqXxaykweIRYMuIWKKeB7sDMKHLNpdQBSXAnsC1mZl1+1713Q7WAtYBbm6o35KkNzwObFs//iDwQE8vcM6spEEhM8dGxAXArcAM4DZgdEQcC4zLzEuoTledFREPUl10sFf92rsj4lfAPfVrD83MmQPxOSSpLSLiPGA7YPmIeAw4CjgY+M/67NnLzMOIelSDEupLzstpB/+epcHBf8vt4N/z4GUxK0mSpGI5Z1aSJEnFspjtYxGxS/11mA9GxJED3R/1ve6+fk9Smczswc/MHvwsZvtQ/fWXPwV2BdYD9q6/JlODy+n849fvSSqMmd0ap2NmD2oWs31rc+DBzPxrZv4dOJ/qJu4aRObw9XuSymNmt4CZPfhZzPat178qs+ZXYkrSgsvMlgYBi1lJkiQVy2K2b/mVmJJUDjNbGgQsZvvWLcA6EbFWRLyF6tuFLhngPkmSumdmS4OAxWwfyswZwGHAlVTfCf+rzLx7YHulvlZ//d6fgHdGxGMRceBA90nSm2dmt4OZPfj5DWCSJEkqliOzkiRJKpbFrCRJkoplMStJkqRiWcxKkiSpWBazkiRJKpbFrCRJkoplMStJkqRiWcxKkiSpWP8fBahfl+G557wAAAAASUVORK5CYII=\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"#MODEL_PATH = './test_model.hdf5'\nfrom keras.models import load_model\n#best_model = load_model('./init_model.h5')\nbest_model = load_model('../input/cropnet-4-breast/cropnet_test_model_20220511.h5',compile=False)\n#init_model = load_model(\"./init_model.h5\", custom_objects={'focal_loss_fixed': focal_loss()})","metadata":{"execution":{"iopub.status.busy":"2022-05-13T00:17:25.041884Z","iopub.execute_input":"2022-05-13T00:17:25.043643Z","iopub.status.idle":"2022-05-13T00:17:53.874872Z","shell.execute_reply.started":"2022-05-13T00:17:25.043599Z","shell.execute_reply":"2022-05-13T00:17:53.874035Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"test_2_final_model(best_model, train_generator, \n               val_generator, val2_generator, \n               np.argmax(train_label, axis=1),\n               np.argmax(test_label, axis=1),\n               np.argmax(val_label, axis=1), \n               class_labels = ['idc-', 'idc+'])","metadata":{"execution":{"iopub.status.busy":"2022-05-13T00:17:53.877202Z","iopub.execute_input":"2022-05-13T00:17:53.877451Z","iopub.status.idle":"2022-05-13T00:18:45.632296Z","shell.execute_reply.started":"2022-05-13T00:17:53.877418Z","shell.execute_reply":"2022-05-13T00:18:45.631634Z"},"trusted":true},"execution_count":124,"outputs":[{"name":"stdout","text":"3/3 [==============================] - 17s 6s/step\n2/2 [==============================] - 4s 2s/step\npredicting test data\n9/9 [==============================] - 30s 3s/step\nTrain accuracy Score------------>\n51.429 %\nVal accuracy Score--------->\n38.889 %\nTest accuracy Score--------->\n55.952 %\nF1 Score--------------->\n54.871 %\nCohen Kappa Score------------->\n11.905 %\nRecall-------------->\n55.952 %\nPrecision-------------->\n56.583 %\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 864x432 with 4 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}